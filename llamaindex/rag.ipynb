{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f198b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "import nest_asyncio, os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from llama_index.core.evaluation import FaithfulnessEvaluator, AnswerRelevancyEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7286d829",
   "metadata": {},
   "source": [
    "#### Read Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51953689",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87a50ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(input_dir=INPUT_DIR)\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bce6244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list,\n",
       " 10,\n",
       " [Document(id_='7bd775d9-9277-4e61-bb67-e7992afddcea', embedding=None, metadata={'page_label': '1', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='FAKE NEWS DETECTION IN SPANISH USING DEEP LEARNING\\nTECHNIQUES\\nKevin Martínez-Gallego\\nIntelligent Information Systems Lab\\nUniversidad de Antioquia\\nCalle 67 No. 53 - 108, 050010, Medellín, Colombia.\\nkevin.martinez@udea.edu.co\\nAndrés M. Álvarez-Ortiz\\nIntelligent Information Systems Lab\\nUniversidad de Antioquia\\nCalle 67 No. 53 - 108, 050010, Medellín, Colombia.\\namauricio.alvarez@udea.edu.co\\nJulián D. Arias-Londoño\\nIntelligent Information Systems Lab\\nDpt. of Systems Engineering and Computer Science\\nUniversidad de Antioquia\\nCalle 67 No. 53 - 108, 050010, Medellín, Colombia.\\njulian.ariasl@udea.edu.co\\nABSTRACT\\nThis paper addresses the problem of fake news detection in Spanish using Machine Learning\\ntechniques. It is fundamentally the same problem tackled for the English language; however, there\\nis not a signiﬁcant amount of publicly available and adequately labeled fake news in Spanish to\\neffectively train a Machine Learning model, similarly to those proposed for the English language.\\nTherefore, this work explores different training strategies and architectures to establish a baseline for\\nfurther research in this area. Four datasets were used, two in English and two in Spanish, and four\\nexperimental schemes were tested, including a baseline with classical Machine Learning models,\\ntrained and validated using a small dataset in Spanish. The remaining schemes include state-of-the-art\\nDeep Learning models trained (or ﬁne-tuned) and validated in English, trained and validated in\\nSpanish, and ﬁtted in English and validated with automatic translated Spanish sentences. The Deep\\nLearning architectures were built on top of different pre-trained Word Embedding representations,\\nincluding GloVe, ELMo, BERT, and BETO (a BERT version trained on a large corpus in Spanish).\\nAccording to the results, the best strategy was a combination of a pre-trained BETO model and a\\nRecurrent Neural Network based on LSTM layers, yielding an accuracy of up to 80%; nonetheless,\\na baseline model using a Random Forest estimator obtained similar outcomes. Additionally, the\\ntranslation strategy did not yield acceptable results because of the propagation error; there was also\\nobserved a signiﬁcant difference in models performance when trained in English or Spanish, mainly\\nattributable to the number of samples available for each language.\\nKeywords Deep Learning · Fake News Detection · Spanish · Supervised Learning · Word Embeddings · Transfer\\nLearning\\n1 Introduction\\nIn social networks, the proliferation of fake news is a strategy used to manipulate public opinion. For example, it is\\nwell-known the case of Cambridge Analytica, where the “private data of millions of people was used to psychologically\\nmanipulate voters in the 2016 US elections, where Donald Trump was elected president. The company not only sent\\ntailored advertising but developed fake news that it then replicated across social networks, blogs and media\" [1]. One of\\nthe strategies that have begun to be explored to prevent the proliferation of fake news, is the use of Artiﬁcial Intelligence\\narXiv:2110.06461v1  [cs.CL]  13 Oct 2021', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       "  Document(id_='e521fc4e-0309-48e4-8171-819132848abb', embedding=None, metadata={'page_label': '2', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='(AI) techniques and, more precisely, Deep Learning (DL) for their detection and subsequent removal. Most of the\\nwork that has been done in this ﬁeld uses datasets of news written in English as a source of information, which are\\ncomposed of properly labeled sentences publicly available. Although fake news is a common problem across different\\nlanguages, including Spanish, there is not a signiﬁcant amount of properly labeled fake news in Spanish to effectively\\ntrain a DL model for fake news detection, similar to those proposed for the English language. Indeed, to the best of our\\nknowledge, recently in 2019 the ﬁrst corpus of fake news in Spanish exclusively adapted for such a task was presented\\nin [2]; nevertheless, this corpus consists of 971 labeled news, which is an insufﬁcient amount of samples to train a solid\\nDL model from scratch. Therefore, the main objective of this work is to design a Machine Learning (ML) strategy for\\nthe detection of fake news in Spanish, based on Transfer Learning techniques and/or machine translation tools, which\\nallow the use of previously trained models, both in English and Spanish.\\nThis paper is organized as follows: section 2 presents some antecedents on the use of ML and DL models for fake\\nnews detection in different languages, doing emphasis on English and Spanish; section 3 presents the pre-processing\\nstrategies applied to the texts, and also the models and embeddings we employed; in section 4 we present the datasets\\nutilized and the methodology for evaluating the different models, as well as the settings for the experiments carried out\\nand the outcomes we obtained. Finally, we discuss the results and present the conclusions of this paper in section 5.\\n2 Related Work\\nAutomatic fake news detection (FND) is a task that has attracted extensive attention from AI researchers in recent years;\\nthis has been evidenced by the large number of publications in which the problem has been addressed by applying\\ndifferent strategies. Shu et al. [3] report a summary of research works on FND in social networks, analyzing the aspects\\ninvolved from psychology, social theories, and algorithmic points of view. As in many ML applications, the proposed\\napproaches addressing FND are composed of two stages: feature extraction and model building; the ﬁrst refers to the\\nnumerical representation of news content and related information; the second proposes the development of a machine\\nlearning model to distinguish between fake news and legitimate news. For example, Wu and Liu in [4] assume that fake\\nnews is typically manipulated to resemble real news; thus, they propose a classiﬁer based on propagation paths in social\\nnetworks using Long Short-Term Memory Recurrent Neural Networks (LSTM-RNN) and Embeddings. Although the\\nFND task has traditionally been stated as a bi-class classiﬁcation problem, in [5] the author presents a dataset in English\\n(The Liar Dataset), which is composed of 6 classes: pants-ﬁre, false, barely true, half-true, mostly true, and true. In\\naddition, this author evaluates four classiﬁcation models following an approach where he considered both meta-data and\\ntext; hence, he presented Support Vector Machine (SVM) as the best classical ML model, and Convolutional Neural\\nNetwork (CNN) as the best DL model, which outperformed the other models with an accuracy of 27% on the test set.\\nUsing this same dataset, Bracsoveanu and Andonie in [6], propose to add a pre-processing stage based on the extraction\\nof semantic features from the text. These authors also evaluate classical ML and DL models, ﬁnding the SVM model\\nto be the best in terms of performance (28.4%) for classical ML, and the CapNetLSTM model (64.4%) for DL, which\\nwas used in combination with a pre-trained Embeddings model; these results were obtained on the dataset presented in\\n[5]. The authors conclude that employing Semantic Features signiﬁcantly improves accuracy in fake news detection;\\nin particular, for DL models, the improvement in accuracy was up to 5-6%. Furthermore, they also highlighted that\\n\"the accuracy of the various models greatly varies depending on the data sets and the number of classes involved\", a\\nphenomenon we also noticed across this state-of-the-art review.\\nPrevious works tackled the FND task using datasets in English; however, this paper focuses on FND for Spanish.\\nFaustini and Covoes propose in [7] an approach using text features that can be generated independently of the news\\nsource platform and, as far as possible, independently of the news language under analysis. The authors report\\ncompetitive results for news in languages belonging to the Germanic, Latin, and Slavic language groups. They used\\nﬁve datasets, and each one was processed with four different Natural Language Processing (NLP) techniques for text\\nrepresentation. Then, experiments were performed with different models obtaining the best result with Random Forest\\nand SVM algorithms, combined with Bag-of-Words (BoW) as text representation technique; hence, they got a prediction\\nrate of up to 95% for news in the speciﬁed linguistic groups. Additionally, Posadas-Durán et al. [2] address the FND\\ntask for Spanish news, using different classical ML models: SVM, Random Forest, Logistic Regression, and Boosting;\\nthese models were combined with different strategies for text pre-processing that allow extracting useful semantic\\ninformation for the detection task: BOW, Part of Speech tags (POS tags) and n-grams, as well as applying Stop Words\\nto avoid prepositions and/or punctuation marks in the text. The experiments were carried out using a proprietary dataset\\n1 (released under CC-BY-4.0 license). The authors report results of up to 77.28% accuracy for one of the combinations.\\nTo the best of our knowledge, no works applying DL models in the Spanish FND task have been published so far.\\n1https://github.com/jpposadas/FakeNewsCorpusSpanish\\n2', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       "  Document(id_='b51881e0-a7b5-40eb-be92-7d99bde1a4e7', embedding=None, metadata={'page_label': '3', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='3 Methods\\n3.1 Preprocessing steps\\nIn order to obtain consistent results, a data standardization process known as Text Normalization was performed, which,\\nin addition to eliminating non-alphanumeric characters in the text, includes some of the most commonly used techniques\\nin NLP:\\n• Stop Words:we removed words there is an agreement they do not contribute to the models learning process in\\nthe context of the problem addressed; for instance, articles and prepositions.\\n• Stemming: this technique was used to reduce words to their root.\\n• Tokenization and Padding:as usual in text processing tasks, we performed tokenization and padding, when\\nrequired, for words and sentences representation.\\nSubsequently, we decided to compare some of the most common techniques regarding text representation: BoW, which\\nprovides the number of occurrences of each word in the text corpus; term frequency-inverse document frequency(tf-idf),\\nwhich provides a weighted measure of the importance of each term within the text (according to its frequency of\\noccurrence in sentences); and pre-trained Word Embeddings, where words and the semantic relationships among them\\nare represented as a vector. It is worth clarifying that, we call Word Embeddings to both pre-trained vectors such as\\nword2vec or GloVe, and embeddings obtained from pre-trained models such as ELMo or BERT (presented in subsection\\n3.2).\\n3.2 Models\\nClassical ML models, and DL models based on artiﬁcial neural networks were used. We employed ML models intending\\nto create a baseline for comparison purposes; hence, we selected the following: Support Vector Machine (SVM),\\nRandom Forest (RF), Gradient Boosting Tree (GBT), and Multi-Layer Perceptron (MLP). For the case of DL classiﬁers,\\nbesides word embeddings, two types of layers were used: Long Short-Term Memory Recurrent Neural Network\\n(LSTM-RNN) using a many-to-one architecture, and Convolutional Neural Network (CNN). LSTM-RNN processes\\nthe input data as sequences of dependent observations, while CNNs can process n-grams through the application of\\nconvolutional ﬁlters. A schematic of the DL classiﬁers in combination with a embedding layer is illustrated in Figure 1;\\nthis ﬁgure shows the arrangement of the aforementioned layers, and the different word embeddings we used which are\\npresented next.\\nFigure 1: Schematic of DL classiﬁers in combination with Embedding Layer\\n3', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       "  Document(id_='f1c0ac04-d171-405c-b103-3e4a91c9d0d3', embedding=None, metadata={'page_label': '4', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='In some experiments, we trained the embedding layer as part of the model training process. However, in most cases, we\\nused transfer learning strategies through pre-trained word embeddings. This procedure makes much sense when either\\nthere are not many samples available for training or the computational resources are limited. Four word-embedding\\nvariants were evaluated:\\n1. Global Vectors for Word Representation(GloVe): it is an unsupervised method that captures statistical\\ninformation from a text corpus; in order to generate word representations, its training process is based on\\nthe spectral co-occurrence matrix decomposition [8]. Hence, we made use of the 300-dimensional vectors\\npre-trained on the English Wikipedia corpus, available at [9].\\n2. Embeddings from a Language Model(ELMo): in contrast to GloVe, which provides a ﬁxed meaning for\\neach word, the representations generated by ELMo are functions of the entire sequence, instead of a single\\nword. ELMo encodes words by individual characters, such that it allows the same word to have different\\nrepresentative vectors under different contexts [10]. The pre-trained model was downloaded from the public\\nrepository Tensorﬂow Hub, which can be found at [11].\\n3. Bidirectional Encoder Representations from Transformers(BERT): it is a language representation model\\nbased on another type of model called Transformer, where instead of strictly analyzing the temporal dependence\\nof the input sequence, all possible combinations of the input sequence are evaluated through an attention layer\\n[12]. It has the advantage that its training process can be performed in parallel, since it does not depend on the\\ntemporal condition. For this research, the so-called BERT Base was used, which is a model with a total of 110\\nmillion pre-trained parameters. The pre-trained model was downloaded from the public repository Tensorﬂow\\nHub, available at [13].\\n4. BETO: this model corresponds to a BERT version but instead of English, this models is trained on a large\\ncorpus of text in Spanish [ 14]. The size of the model is similar to a BERT Base, with approximately 110\\nmillion parameters.\\n4 Experiments and Results\\n4.1 Datasets\\nFour free-to-use datasets were chosen to use in this study. Two of them consist of news in English labeled as fake or\\nreal: Fake and real news dataset[15], and News Data Set - Fake OR Real[16]; the other two datasets correspond to\\nnews in Spanish, also properly labeled: The Spanish Fake News Corpus [2] containing 971 news items, and fake news\\nin Spanish [17], consisting of 1600 news items. None of the above datasets had missing or null data, and they are well\\nbalanced considering the two classes involved. The English datasets were merged, resulting in a ﬁnal English corpus\\ncomprising 51233 samples, of which 26645 are fake, and 24588 are genuine; the same procedure was followed over the\\nindividual datasets in Spanish, resulting in a ﬁnal Spanish corpus consisting of 2571 samples, such that 1280 of them\\nare fake and 1291 genuine 2. Figure 2 shows through a chart the corresponding distribution for each resulting dataset.\\nSince the number of samples in Spanish is considerably small to train a DL model from scratch, one of the strategies\\nfollowed during experiments, consists of evaluating the capacity of a DL model trained with the English corpus to\\npredict fake Spanish news translated into English using the Google translation API.\\n4.2 Experimental setup\\nThe experiments were carried out using a Bootstrap (ShufﬂeSplit) validation methodology, considering 5 iterations.\\nDepending on each scheme (described below), the partitioning was done into three subsets (train, development, test) or\\ninto two subsets (train, test), taking 80% for training and 20% for testing (in the case of partitioning into three subsets,\\nfor the internal sub-division train/development we took 80% / 20% respectively); however, in some experiments the\\nsplit of the dataset was set to a ratio of train: 90% / test: 10%. These variations in the partitioning were considered due\\nto the few samples we had in the ﬁnal corpus in Spanish; hence, we wanted to try different combinations aiming at keep\\nas many samples for training as possible.\\nConsidering the balancing condition on the datasets we used, and the fact that we were addressing a bi-class\\nclassiﬁcation task, we chose Accuracy as the performance metric for measuring the generalization ability of the models.\\n2In this paper, we refer to the resulting datasets presented in this subsection as follows: the dataset in English, the dataset in\\nSpanish, and the translated dataset.\\n4', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       "  Document(id_='982998a3-2ec9-4ee1-9358-bcd78bc323c8', embedding=None, metadata={'page_label': '5', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Figure 2: Sample distribution for the resulting datasets in English and Spanish\\nRegarding the execution of experiments, four schemes were deﬁned in combination with the datasets and the different\\nmodels. Initially, a baseline was established, training and validating the four classical ML models listed in subsection\\n3.2, using the dataset in Spanish (ﬁrst scheme). For classical ML approaches, the texts were represented using BoW\\nand tf-idf techniques; this step was carried out to have a reference point for comparison purposes with the DL-based\\narchitectures. The subsequent experiments combine different DL models with different word embedding representations\\n(presented in sub-section 3.2), varying the datasets used for training and validation. The second scheme uses the\\ndataset in Spanish both to train and validate two vanilla DL architectures based on LSTM and CNN layers, and more\\nsophisticated architectures built on top of BERT-type models. Concerning the experiments with BETO embedding, we\\ntried with different values for the number of epochs, and also applied the early stopping strategy considering different\\nvalues of the hyperparameters tolerance and patience. For its part, the third scheme is similar to the former one but\\nusing the dataset in English instead, so in this case no experiments were performed using the pre-trained BETO model.\\nThe last scheme trains the models with the dataset in English and validates with the translated dataset (fourth scheme).\\nMoreover, we conducted some experiments where samples from the translated dataset were progressively mixed with\\nthe dataset in English during the training phase; then, the remaining portion of the translated dataset was used for\\nvalidation, i.e., emulating a learning curve.\\nThe following is the collection of hyperparameter values we considered when training and validating the different\\nmodels. Regarding the ML models for the baseline:\\n• (SVM) RBF and Linear Kernel; regularization parameter ’C’: 1e3, 1e-3; kernel coefﬁcient for RBF ’gamma’:\\n0.1, 1\\n• (RF and GBT) number of trees: 50, 100, 200, 300, 500; maximum number of features: 50, 100, 200, 300\\n• (MLP) hidden layers: 1, 2, 3; number of neurons per hidden layer: 10, 50; epochs: 1000, 1500\\nFurthermore, the combinations of these models were evaluated with BoW and tf-idf representations; removing and not\\nremoving Stop Words; applying and not applying Stemming; and considering a maximum vocabulary size of 10000,\\n20000, 30000 and 40000 words.\\nSimilarly, for the DL models evaluated we considered:\\n• LSTM: units present in hidden layers (Units) [this model was only implemented with a single hidden layer],\\nkernel regularizer (KR), recurrent regularizer(RR), dropout (D).\\n• CNN: amount of ﬁlters (F), kernel size (KS), number of units for additional dense layer (Units), kernel\\nregularizer (KR).\\nIt is also worth pointing out that, in order to set the input length for the models, we used a histograms-based approach to\\ndetermine the most common length (in words) of the news items, in both the datasets for English and Spanish news:\\n1500 and 500 words, respectively.\\n5', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       "  Document(id_='3ab62d6b-fff4-42d2-b6cf-c6a66012bec3', embedding=None, metadata={'page_label': '6', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='The source code used to carry out the experiments can be found in a publicly accessible repository at GitHub 3.\\n4.3 Results\\nTable 1 shows the best results for each of the models considered during the experiments of the ﬁrst scheme, which\\nwas described in subsection 4.2. It also shows the conﬁguration of pre-processing steps that achieved the best results.\\nMoreover, the hyperparameter values selected for each model were the following:\\n• (SVM) kernel RBF; ’C’: 1e3; kernel coefﬁcient ’gamma’: 1\\n• (RF and GBT) number of trees: 500; maximum number of features: 50\\n• (MLP) hidden layers: 1; neurons: 10; epochs: 1500\\nTable 1: Baseline results for the dataset in Spanish\\nModel Vocab Size Stemming Remove StopWords Text Representation test_acc\\nSVM 10000 NO YES tf-idf 0.798\\nRF 40000 NO YES tf-idf 0.802\\nGBT 40000 YES NO BoW 0.783\\nMLP 10000 YES NO tf-idf 0.794\\nAccording to the baseline results, RF in combination with a tf-idf text representation showed the highest accuracy.\\nSubsequently, we performed the experiments with the DL models (LSTM, CNN) in combination with the different types\\nof Word Embeddings; hence, we followed the second, third, and fourth schemes. From this point on, we permanently\\nremoved Stop Words and did not apply Stemming anymore regarding data pre-processing.\\nInitially, we ran some experiments using a trainable embedding layer; the results are summarized in Table 2, where the\\nhyperparameter values selected for each model were:\\n• LSTM (Spanish) 16 units; KR and KK equals 1; D equals 0\\n• LSTM (English) 4 units; KR and KK equals 0.01; D equals 0\\n• CNN (Spanish) F equals 16; KS equals 10; 4 units; KR equals 0.01\\n• CNN (English) F equals 16; KS equals 10; 12 units; KR equals 0\\nThe LSTM and CNN models trained with the English dataset, whose results are shown in Table 2, were also validated\\nwith the whole translated dataset, yielding accuracies of 56.7% and 53.2% respectively.\\nTable 2: Results for DL models with trainable embedding layer; the column dev_acc shows the accuracy in the\\ndevelopment set; std is the standard deviation, and test_acc shows the accuracy in the test set.\\nModel Dataset Language dev_acc std test_acc\\nLSTM Spanish 0.714 0.026 0.761\\nLSTM English 0.95 0.02 0.931\\nCNN Spanish 0.73 0.021 0.685\\nCNN English 0.984 0.002 0.982\\nNext, we performed the experiments using a Transfer Learning approach, with the pre-trained 300-feature GloVe\\nembedding layer presented in subsection 3.2; this time, the embedding values were left ﬁxed during the training process,\\nand only the added hidden layers were ﬁne-tuned. Since the GloVe vectors utilized were trained on a corpus in English,\\nthese experiments correspond to the third and fourth schemes. The results are summarized in Table 3; moreover, the\\nhyperparameter values chosen for each model were the following:\\n• (LSTM) 8 units; KR and KK equals 0; D equals 0.5\\n• (CNN) F equals 16; KS equals 10; 4 units; KR equals 0\\nThen, when validating the former models using the translated dataset (fourth scheme), we got accuracy values of 54%\\nand 53.8% for LSTM and CNN layers, respectively.\\n3https://github.com/kevinmaiden7/Spanish_FakeNewsDetection\\n6', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       "  Document(id_='7ea003dc-9156-4d7a-8e01-5b0f44258668', embedding=None, metadata={'page_label': '7', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Table 3: Results for DL models using GloVe embedding with the dataset in English. The column dev_acc shows the\\naccuracy in the development set; std is the standard deviation, and test_acc shows the accuracy in the test set.\\nModel dev_acc std test_acc\\nLSTM 0.962 0.006 0.924\\nCNN 0.974 0.002 0.973\\nAt this point, we decided to implement a learning curve in order to evaluate the effect of including data from the\\ntranslated dataset, into a training dataset composed of the original news in English. The models evaluated included\\nLSTM and CNN layers as well as trainable Embeddings and GloVe. Five experiments were run for each case, adding\\n500, 1000, 1500, 2000 and 2500 samples from the translated dataset to the training set, and then validating with the total\\namount of remaining samples of the translated dataset. Figure 3 shows the results for the CNN model with trainable\\nEmbedding, which was the best combination found in terms of accuracy, when applying this strategy.\\nFigure 3: Learning curve results for CNN with trainable embedding\\nBased on the previous results obtained with GloVe, and to simplify the experimental phase, the best hyperparameters of\\nLSTM and CNN layers found using this embedding, were left ﬁxed for the subsequent experiments applying ELMo and\\nBERT-type embeddings.\\nTable 4: Results for ELMo, BERT and BETO Embeddings\\nEmbedding Model scheme Epochs test_acc\\nELMo LSTM Third 7 0.973\\nELMo CNN Third 5 0.957\\nELMo CNN Fourth 7 0.525\\nBERT CNN Third 7 0.957\\nBERT CNN Fourth 7 0.53\\nBETO LSTM Second 25 0.80\\nRegarding the results with ELMo embedding, we got high accuracy outcomes for both LSTM and CNN models\\nconcerning the third scheme, as it is shown in Table 4; however, when it comes to the fourth scheme, the results show a\\ndegradation in performance. Additionally, taking into account the trend identiﬁed in the aforementioned learning curve\\napproach, we added 2500 samples from the translated dataset to the training set, ﬁtted the CNN layer in combination\\nwith ELMo embedding on this set, and validated with the remaining 71 samples of the translated dataset: we reached an\\naccuracy value of 70%.\\nFor the models built on top of BERT embedding, experiments were only carried out with the CNN layers; with this in\\nmind, as it is described in Table 4, we obtained a high accuracy result for the third scheme again, whereas not such a\\ngood level was achieved for the fourth scheme. Similarly to the procedure followed with ELMo embedding, 2500\\nsamples were added from the translated dataset to the training set, for then validating with the remaining 71 samples: in\\nthis case we got an accuracy level of 63.4%.\\n7', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       "  Document(id_='9a54ae6c-8980-4ccb-9a05-9598fc2bbc00', embedding=None, metadata={'page_label': '8', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Concerning BETO embedding, the experiments with this model were framed in the second scheme (training and\\nvalidating with the dataset in Spanish) since BETO itself is a model trained over a corpus in this language; in this case,\\nwe used both LSTM and CNN layers. Table 4 shows the results for this experiment, where it is possible to observe that\\nthe LSTM model trained with 25 epochs achieved results of up to 80% in accuracy for the test set; this is the best result\\nwe reached with DL models for the dataset in Spanish. Thus, Figure 4 shows the confusion matrix associated with this\\narchitecture for the test set; it is worth highlighting that we used the early stopping strategy, although it did not yield a\\nsigniﬁcant improvement in comparison to the previous results.\\nFigure 4: (BETO) normalized confusion matrix for LSTM with the dataset in Spanish\\n5 Discussion and Conclusions\\nRegarding the proposed baseline for datasets in Spanish (ﬁrst scheme), RF showed the best performance getting an\\naccuracy of 80%, and using the tf-idf text representation; however, this performance was not statistically different from\\nthat obtained with SVM, where a smaller vocabulary size was used. This model outperformed the best result reported in\\n[2], where The Spanish Fake News Corpusdataset was also utilized. Furthermore, we noticed that for this scheme, there\\nwere no signiﬁcant differences in the performance of the models when applying Stemming or removing StopWords, or\\neven when varying the text representation strategy or the vocabulary size.\\nIt is worth highlighting the gap between the number of samples in the resulting datasets for English and Spanish,\\nas it was shown in Figure 2. Since the models we used in this research follow a phenomenological approach, they\\nhighly depend on the amount of experimental data they are trained on. The above was evidenced by the prominent\\ndifference on accuracy we obtained in the third and fourth schemes, using GloVe, ELMo, and BERT embeddings.\\nAlso, concerning the second scheme, we noticed that the models exhibited a trend of overﬁtting due to the small\\nnumber of samples available for training; moreover, we observed that the regularization strategies we employed did not\\nsigniﬁcantly improve the performance.\\nIn regard to the fourth scheme, it is important to underline that the vocabulary present in the translated dataset\\ncorresponded to just 60% of that present in the dataset in English; this situation negatively affected the results we\\nobtained for the translation strategy. For this scheme, despite the excellent performance of the models trained and\\nvalidated with the dataset in English (third scheme), when we validated with the translated dataset, the values of\\naccuracy were drastically reduced. Consequently, the results of the implemented learning curve indicated a performance\\nimprovement (although in different ratios) as more samples were added from the translated dataset to the training\\nset (as it was shown in Figure 3); this pattern was noticed regardless of the combination between a model and the\\nembedding layer utilized.\\nConcerning the different embeddings we used, similar results were obtained for the third and fourth schemes when\\nusing GloVe, ELMo or BERT, in each of them; in fact, it is noteworthy that, in combination with these different\\nembeddings, the LSTM and CNN layers showed similar results. Furthermore, taking into account these pre-trained\\nmodels corresponded to the state-of-the-art in NLP, we were expecting to obtain salient results by mixing portions of\\nthe translated dataset to the dataset in English for training; however, due to the small number of samples available in the\\n8', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       "  Document(id_='99adf1b4-946b-4666-b5b7-7c056bde53d9', embedding=None, metadata={'page_label': '9', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='dataset in Spanish, and the discrepancies resulting from the translation, the predictive capability of the models was\\nlimited. Nonetheless, BETO embedding allowed us to obtain the best result for the dataset in Spanish (or any validation\\nover news items in Spanish using DL models), considering the fact that its approximately 110 million parameters were\\npre-trained on a corpus in this language; this enabled us to take full advantage of the Transfer Learning strategy, and\\nobtain an outstanding performance of 80% of accuracy on the test set, in spite of the small number of samples available\\nfor such deep network architecture. Figure 4 showed the result for the LSTM model combined with this embedding,\\nwhich corresponds to the best strategy identiﬁed for detecting fake news in Spanish using DL techniques: out of the\\n258 news items used for validation, the model correctly classiﬁed 76% of the fake news items, as well as 86% of the\\nlegitimate news items, which we consider a good hit ratio; by contrast, the model tends to confuse news items that are\\nfake with legitimate ones, which corresponds to the main error condition it incurred.\\nAlthough the best detection rate achieved for DL models was similar to that obtained with RF, there is indubitably\\nmore room for improvement in the case of Deep Neural network architectures, due to the combination with Word\\nEmbeddings and more advanced techniques. Thus, in the future, this research could continue aiming at building a\\nmore robust system from the best strategy we found (BETO + LSTM), if a set of labeled news in Spanish with a more\\nrepresentative number of samples are available; furthermore, more experiments combining hyperparameter values and\\nnetwork architectures could also be carried out.\\nReferences\\n[1] “5 claves para entender el escándalo de cambridge analytica que hizo que facebook perdiera us 37.000 millones\\nen un día (bbc news mundo).” https://www.bbc.com/mundo/noticias-43472797, Mar 2018. [Online;\\naccessed 09-Sep-2021].\\n[2] J.-P. Posadas-Durán, H. Gómez-Adorno, G. Sidorov, and J. J. M. Escobar, “Detection of fake news in a new corpus\\nfor the spanish language,”Journal of Intelligent & Fuzzy Systems, vol. 36, no. 5, pp. 4869–4876, 2019.\\n[3] K. Shu, A. Sliva, S. Wang, J. Tang, and H. Liu, “Fake news detection on social media: A data mining perspective,”\\nACM SIGKDD explorations newsletter, vol. 19, no. 1, pp. 22–36, 2017.\\n[4] L. Wu and H. Liu, “Tracing fake-news footprints: Characterizing social media messages by how they propagate,”\\nin Proceedings of the eleventh ACM international conference on Web Search and Data Mining, pp. 637–645, 2018.\\n[5] W. Y . Wang, “\" liar, liar pants on ﬁre\": A new benchmark dataset for fake news detection,” arXiv preprint\\narXiv:1705.00648, 2017.\\n[6] A. M. Bra¸ soveanu and R. Andonie, “Semantic fake news detection: a machine learning perspective,” inInterna-\\ntional Work-Conference on Artiﬁcial Neural Networks, pp. 656–667, Springer, 2019.\\n[7] P. H. A. Faustini and T. F. Covões, “Fake news detection in multiple platforms and languages,”Expert Systems\\nwith Applications, p. 113503, 2020.\\n[8] J. Pennington, R. Socher, and C. D. Manning, “Glove: Global vectors for word representation,” in Empirical\\nMethods in Natural Language Processing (EMNLP), pp. 1532–1543, 2014.\\n[9] J. Pennington, “Glove: Global vectors for word representation.” https://nlp.stanford.edu/projects/\\nglove/, 2014. [Online; accessed 09-Sep-2021].\\n[10] M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee, and L. Zettlemoyer, “Deep contextualized\\nword representations,”arXiv preprint arXiv:1802.05365, 2018.\\n[11] Google, “Elmo - tensorﬂow hub.” https://tfhub.dev/google/elmo/3, 2020. [Online; accessed 09-Sep-\\n2021].\\n[12] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training of deep bidirectional transformers for\\nlanguage understanding,”arXiv preprint arXiv:1810.04805, 2018.\\n[13] Google. https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2 , 2020. [Online; ac-\\ncessed 09-Sep-2021].\\n[14] J. Cañete, G. Chaperon, R. Fuentes, J.-H. Ho, H. Kang, and J. Pérez, “Spanish pre-trained bert model and\\nevaluation data,” inPML4DC at ICLR 2020, 2020.\\n[15] C. Bisaillon, “Fake and real news dataset.” https://www.kaggle.com/clmentbisaillon/\\nfake-and-real-news-dataset , mar 2020. [Online; accessed 09-Sep-2021].\\n[16] V . Ukani, “News data set - fake or real.” https://kaggle.com/vikasukani/\\nnews-data-set-fake-news-with-python , Jul 2020. [Online; accessed 09-Sep-2021].\\n9', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       "  Document(id_='a2db6b71-67ad-45d1-ba9f-d797826c194b', embedding=None, metadata={'page_label': '10', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='[17] A. Tretiakov, “noticias falsas en español 2020.” https://kaggle.com/arseniitretiakov/\\nnoticias-falsas-en-espaol , 2020. [Online; accessed 09-Sep-2021].\\n10', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents), len(documents), documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bae227",
   "metadata": {},
   "source": [
    "#### Splitting, Indexing and Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe3236e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 21:21:57,408 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(name=\"nlp_papers\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2998c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 21:22:15,591 - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "2025-09-07 21:22:17,879 - INFO - 1 prompt is loaded, with the key: query\n"
     ]
    }
   ],
   "source": [
    "# create the pipeline with transformations\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_overlap=0),\n",
    "        HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\"),\n",
    "    ],\n",
    "    vector_store=vector_store\n",
    ")\n",
    "\n",
    "nodes = await pipeline.arun(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a872fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list,\n",
       " 13,\n",
       " [TextNode(id_='5ca009f8-a815-4e1d-9117-cb73b2d0e902', embedding=[-0.03555683046579361, 0.00716931838542223, -0.02077505737543106, 0.056294530630111694, 0.08981095254421234, 0.0013609180459752679, 0.007944142445921898, 0.005815392360091209, 0.0328463576734066, 0.0034827161580324173, 0.020707139745354652, -0.014285522513091564, -0.027410371229052544, -0.00921441800892353, 0.04423157870769501, 0.021918274462223053, 0.021748002618551254, -0.07639149576425552, 0.020983949303627014, -0.02315150387585163, 0.06920871138572693, 0.006815837696194649, 0.01937733218073845, 0.02336173504590988, 0.003909441642463207, -0.0072477892972528934, 0.007037547416985035, 0.005949437152594328, -0.04405679553747177, -0.19036178290843964, 0.02314697951078415, -0.016400987282395363, 0.05768774077296257, -0.0362810380756855, -0.002133144298568368, 0.01096255797892809, -0.03683725371956825, -0.04325534403324127, -0.05004477873444557, 0.015324688516557217, -0.011126919649541378, -0.017206808552145958, 0.002138545038178563, -0.03271544352173805, 0.0483693853020668, -0.0616726391017437, -0.05421103909611702, 0.0063185496255755424, -0.038084618747234344, 0.00900612585246563, -0.03432818502187729, -0.013211904093623161, 0.00974919181317091, 0.02206188626587391, -0.003646902972832322, 0.031037313863635063, 0.041473694145679474, 0.009808346629142761, 0.04059330374002457, 0.051141221076250076, 0.03792603686451912, 0.10756848007440567, -0.13405217230319977, 0.02851123921573162, -0.11112605035305023, 0.009017751552164555, -0.002874581143260002, 0.013682355172932148, -0.008429803885519505, 0.051305193454027176, 0.007727217394858599, -0.024276454001665115, 0.045269425958395004, 0.029231226071715355, 0.021672066301107407, 0.0573916956782341, -0.005882644094526768, 0.036883387714624405, 0.03629138693213463, -0.012788699008524418, 0.020424682646989822, 0.017755478620529175, 0.023076649755239487, -0.05854826420545578, -0.006456977687776089, -0.04649291932582855, 0.01721348986029625, -0.02766081877052784, -0.028900273144245148, -0.038013894110918045, -0.0289288517087698, 0.03620675206184387, 0.038635969161987305, 0.03338976204395294, -0.010411306284368038, -0.010301475413143635, -0.05048588663339615, 0.021094348281621933, -0.037548214197158813, 0.3551611006259918, -0.005696006119251251, -0.04394620284438133, 0.027276210486888885, -0.027597615495324135, 0.010095193982124329, -0.008444474078714848, -0.010270966216921806, -0.0008772099390625954, -0.0030126029159873724, 0.038557786494493484, -0.08676984161138535, -0.03490963205695152, 0.028070122003555298, 0.009205538779497147, -0.04016439989209175, 0.0030673642177134752, 0.08128049224615097, 0.0558890737593174, -0.010438027791678905, 0.022117722779512405, 0.003540871199220419, -0.03888683766126633, 0.03419413045048714, 0.013840305618941784, 0.026211878284811974, 0.005778634920716286, 0.02076093479990959, 0.08579503744840622, 0.04939703270792961, 0.04524340480566025, -0.005103894509375095, 0.021043628454208374, -0.03477562591433525, 0.009972752071917057, 0.03331431746482849, 0.06406725198030472, -0.042848508805036545, 0.02865644544363022, -0.018099801614880562, -0.0025550550781190395, -0.04326505586504936, 0.02052915468811989, 0.06965560466051102, 0.03046286664903164, -0.12245148420333862, 0.03741537034511566, -0.058137182146310806, -0.014321527443826199, -0.08008112013339996, -0.023493032902479172, -0.014034068211913109, 0.06373147666454315, -0.03486023098230362, -0.015259258449077606, -0.00024015133385546505, -0.009184450842440128, 0.028877615928649902, 0.001506719971075654, -0.07710844278335571, -0.055067386478185654, -0.01933605782687664, -0.045002564787864685, -0.00502361822873354, 0.10372915863990784, 0.026747215539216995, -0.05277811735868454, -0.013207698240876198, 0.013947704806923866, 0.020757965743541718, -0.050613097846508026, 0.06965513527393341, 0.009660369716584682, 0.018790272995829582, 0.005078793503344059, -0.07347701489925385, 0.011644096113741398, -0.052848320454359055, -0.0072750975377857685, 0.006068154238164425, 0.01608450710773468, 0.004750346299260855, -0.06387747079133987, -0.01378688309341669, 0.07890424877405167, -0.01747502200305462, -0.038428470492362976, 0.00807945616543293, -0.03372953459620476, 0.08765878528356552, 0.059836115688085556, -0.0032146191224455833, 0.03986981883645058, -0.09231651574373245, 0.003383433446288109, -0.016003817319869995, -0.02604503184556961, -0.027507372200489044, 0.028585292398929596, 0.008157062344253063, 0.028223827481269836, -0.011062819510698318, 0.049152493476867676, -0.020142151042819023, -0.07179787755012512, -0.04941852018237114, -0.047733157873153687, 0.008590598590672016, -0.029457945376634598, 0.022858474403619766, 0.028455959632992744, -0.037391915917396545, -0.021674204617738724, 0.00030051262001506984, -0.06363444030284882, -0.001343285315670073, -0.011394510045647621, 0.03382080793380737, 0.06526928395032883, -0.03933728486299515, 0.055325575172901154, -0.03857726976275444, -0.011095097288489342, 0.0005971613572910428, -0.333325058221817, -0.09058824181556702, 0.015747934579849243, 0.03893381357192993, 0.007529956754297018, -0.07495080679655075, 0.051701996475458145, -0.013583981432020664, 0.09858471900224686, 0.07815149426460266, -0.02358611486852169, -0.0336737185716629, -0.038967911154031754, 0.007151380646973848, 0.03785889223217964, 0.053340114653110504, 0.05440058186650276, -0.0028917654417455196, -0.02926488034427166, 0.0025619121734052896, 0.007398675661534071, 0.041461776942014694, 0.012272518128156662, -0.08428189903497696, 0.009902858175337315, 0.05357053875923157, 0.06135331839323044, 0.0046416460536420345, -0.001363866962492466, -0.010806117206811905, -0.007604009937494993, 0.007387592922896147, -0.011775419116020203, -0.06761888414621353, 0.05600455775856972, -0.026813626289367676, 0.054030902683734894, 0.009552884846925735, 0.014143719337880611, 0.04280346632003784, 0.023647841066122055, -0.05244382098317146, -0.013554723002016544, -0.046631019562482834, -0.04034777730703354, -0.011069620959460735, -0.00027815092471428216, -0.000798943976406008, -0.0257610771805048, 0.04633399471640587, 0.0010060651693493128, 0.06395013630390167, 0.04373392462730408, 0.038680851459503174, -0.020474864169955254, -0.027377309277653694, -0.09001090377569199, 0.00035016544279642403, -0.05940723046660423, -0.045035891234874725, 0.039440929889678955, -0.026073407381772995, 0.01601303741335869, -0.044653721153736115, 0.012647158466279507, -0.011678666807711124, -0.021073682233691216, -0.029919657856225967, 0.04010849446058273, 0.09362412989139557, -0.0061364308930933475, 0.18702438473701477, 0.029895272105932236, 0.011166604235768318, 0.07338046282529831, 0.02985324338078499, -0.0016461028717458248, -0.11928974837064743, -0.05994756892323494, 0.016529345884919167, 0.08294308185577393, 0.054322972893714905, 0.07156070321798325, 0.037525758147239685, 0.02620525471866131, 0.014769040048122406, 0.03959331288933754, -0.024289807304739952, 0.011391541920602322, 0.06331585347652435, 0.009308011271059513, -0.023080984130501747, -0.01469864509999752, -0.059549737721681595, -0.020158955827355385, -0.04238155484199524, -0.22988846898078918, -0.024622676894068718, 0.00355131016112864, 0.05416145175695419, 0.03128010779619217, -0.06309499591588974, 0.019182153046131134, -0.05103670433163643, 0.06489954143762589, 0.00801805965602398, -0.021563217043876648, 0.0016658427193760872, 0.06018250808119774, -0.00977159384638071, -0.056615233421325684, 0.007128408178687096, 0.013243443332612514, 0.008929949253797531, 0.056215476244688034, 0.009472642093896866, -0.020425429567694664, -0.041666168719530106, 0.14346936345100403, -0.04453413188457489, -0.03500721603631973, 0.008772233501076698, 0.025726648047566414, -0.042851522564888, 0.007503261789679527, -0.005649170838296413, -0.040122244507074356, -0.015063481405377388, 0.050420377403497696, 0.016210652887821198, -0.05951344594359398, 0.06287478655576706, -0.055194780230522156, 0.009405144490301609, 0.006116630509495735, -0.019169257953763008, -0.03793803229928017, 0.0835653692483902, -0.02760055474936962, -0.05920654535293579, 0.012090400792658329, -0.016162924468517303, 0.057199470698833466, -0.07349316030740738, 0.012499924749135971, 0.014341209083795547, -0.002612106502056122, -0.04217114299535751, -0.015893369913101196, -0.018583981320261955, 0.029425568878650665, 0.029528960585594177, 0.006336332764476538, -0.01849322021007538, -0.01602642983198166, -0.033524226397275925, -0.020562902092933655, -0.03285440430045128, 0.05812563747167587, 0.05193203315138817, -0.030709102749824524], metadata={'page_label': '1', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='7bd775d9-9277-4e61-bb67-e7992afddcea', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '1', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='3285fca6c1d6bfa25a6697a06a1f7e5e7b481dabc752613ad549192bf70cf093')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='FAKE NEWS DETECTION IN SPANISH USING DEEP LEARNING\\nTECHNIQUES\\nKevin Martínez-Gallego\\nIntelligent Information Systems Lab\\nUniversidad de Antioquia\\nCalle 67 No. 53 - 108, 050010, Medellín, Colombia.\\nkevin.martinez@udea.edu.co\\nAndrés M. Álvarez-Ortiz\\nIntelligent Information Systems Lab\\nUniversidad de Antioquia\\nCalle 67 No. 53 - 108, 050010, Medellín, Colombia.\\namauricio.alvarez@udea.edu.co\\nJulián D. Arias-Londoño\\nIntelligent Information Systems Lab\\nDpt. of Systems Engineering and Computer Science\\nUniversidad de Antioquia\\nCalle 67 No. 53 - 108, 050010, Medellín, Colombia.\\njulian.ariasl@udea.edu.co\\nABSTRACT\\nThis paper addresses the problem of fake news detection in Spanish using Machine Learning\\ntechniques. It is fundamentally the same problem tackled for the English language; however, there\\nis not a signiﬁcant amount of publicly available and adequately labeled fake news in Spanish to\\neffectively train a Machine Learning model, similarly to those proposed for the English language.\\nTherefore, this work explores different training strategies and architectures to establish a baseline for\\nfurther research in this area. Four datasets were used, two in English and two in Spanish, and four\\nexperimental schemes were tested, including a baseline with classical Machine Learning models,\\ntrained and validated using a small dataset in Spanish. The remaining schemes include state-of-the-art\\nDeep Learning models trained (or ﬁne-tuned) and validated in English, trained and validated in\\nSpanish, and ﬁtted in English and validated with automatic translated Spanish sentences. The Deep\\nLearning architectures were built on top of different pre-trained Word Embedding representations,\\nincluding GloVe, ELMo, BERT, and BETO (a BERT version trained on a large corpus in Spanish).\\nAccording to the results, the best strategy was a combination of a pre-trained BETO model and a\\nRecurrent Neural Network based on LSTM layers, yielding an accuracy of up to 80%; nonetheless,\\na baseline model using a Random Forest estimator obtained similar outcomes. Additionally, the\\ntranslation strategy did not yield acceptable results because of the propagation error; there was also\\nobserved a signiﬁcant difference in models performance when trained in English or Spanish, mainly\\nattributable to the number of samples available for each language.\\nKeywords Deep Learning · Fake News Detection · Spanish · Supervised Learning · Word Embeddings · Transfer\\nLearning\\n1 Introduction\\nIn social networks, the proliferation of fake news is a strategy used to manipulate public opinion. For example, it is\\nwell-known the case of Cambridge Analytica, where the “private data of millions of people was used to psychologically\\nmanipulate voters in the 2016 US elections, where Donald Trump was elected president. The company not only sent\\ntailored advertising but developed fake news that it then replicated across social networks, blogs and media\" [1]. One of\\nthe strategies that have begun to be explored to prevent the proliferation of fake news, is the use of Artiﬁcial Intelligence\\narXiv:2110.06461v1  [cs.CL]  13 Oct 2021', mimetype='text/plain', start_char_idx=0, end_char_idx=3100, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       "  TextNode(id_='88b20806-31fd-4176-8866-ae7b1001d29f', embedding=[-0.02482086420059204, 0.01315857470035553, -0.02739838883280754, 0.028468333184719086, 0.11607041209936142, 0.0216705109924078, -0.02089986763894558, 0.0229116752743721, 0.035866573452949524, -0.024644099175930023, 0.03290177136659622, -0.018988411873579025, -0.04266371577978134, -0.0009698727517388761, 0.03577070310711861, 0.03160516917705536, 0.02640952728688717, -0.0899786725640297, 0.014541175216436386, -0.028552943840622902, 0.06742686033248901, 0.0006524093332700431, 0.030245257541537285, 0.011973630636930466, 0.01035804208368063, 0.007092774845659733, 0.00041718140710145235, -0.012267565354704857, -0.04168480634689331, -0.19408297538757324, 0.005836530588567257, -0.008817361667752266, 0.05025467276573181, -0.030438045039772987, -0.00668742973357439, 0.0024565632920712233, -0.03150186687707901, -0.009371062740683556, -0.04259477183222771, 0.009295585565268993, -0.004639393649995327, -0.02923896536231041, 0.011124622076749802, -0.051071178168058395, 0.044082339853048325, -0.04012153670191765, -0.057296525686979294, 0.03625396639108658, -0.03336561098694801, -0.004289545584470034, -0.008493266999721527, -0.008006072603166103, 0.00837164930999279, 0.0151401087641716, 0.0005783580709248781, 0.030329199507832527, 0.036367736756801605, 0.0023240039590746164, 0.02623607963323593, 0.08391618728637695, 0.044261183589696884, 0.08748921751976013, -0.14804978668689728, 0.0275744516402483, -0.09129466116428375, 0.028552623465657234, -0.03061576932668686, 0.03327405825257301, -0.020183298736810684, 0.07074978202581406, 0.002825139556080103, -0.03388941287994385, 0.04766019061207771, 0.0301719531416893, 0.016222111880779266, 0.027874169871211052, -0.0016868067905306816, 0.009190673008561134, 0.016102110967040062, -0.04132363572716713, 0.008093717508018017, 0.037196703255176544, 0.025889454409480095, -0.038549914956092834, -0.033181414008140564, -0.04955499991774559, 0.0240631140768528, -0.020234206691384315, -0.01597309671342373, -0.0421571284532547, -0.03083185851573944, 0.02964240126311779, 0.06093617528676987, 0.04552791267633438, -0.028912242501974106, -0.025072991847991943, -0.012326753698289394, 0.014212211593985558, 0.007530461065471172, 0.36746931076049805, -0.018166355788707733, -0.04768196493387222, 0.021700073033571243, -0.02632077969610691, 0.008045261725783348, -0.01577082648873329, -0.007945643737912178, -0.008349109441041946, 0.006016939878463745, 0.024711593985557556, -0.10074926167726517, -0.010429461486637592, 0.0328756608068943, -0.015429377555847168, -0.022898947820067406, -0.013490883633494377, 0.09536618739366531, 0.03566845878958702, -0.02911575883626938, 0.0013933975715190172, 0.003515017218887806, -0.029069814831018448, 0.0431688092648983, 0.012130401097238064, 0.01249352190643549, 0.026800483465194702, 0.04860100522637367, 0.09625808894634247, 0.057386212050914764, 0.022604864090681076, 0.0015308689326047897, 0.03638117015361786, -0.025727465748786926, 0.019618770107626915, 0.026306943967938423, 0.04546802490949631, -0.04660029709339142, 0.023822763934731483, -0.013864578679203987, -0.013977360911667347, -0.029077665880322456, 0.015935538336634636, 0.05037423223257065, 0.010162947699427605, -0.11955992877483368, 0.07847997546195984, -0.07523265480995178, -0.0006089285016059875, -0.06846354901790619, -0.0051118154078722, 0.019000396132469177, 0.0905056744813919, -0.020104555413126945, -0.015938078984618187, 0.016720423474907875, 0.0014051191974431276, 0.04725018888711929, -0.012638636864721775, -0.08264832198619843, -0.031149765476584435, 0.015520535409450531, -0.0513344369828701, -0.00833134911954403, 0.10247306525707245, 0.0133550725877285, -0.028205275535583496, -0.02582325041294098, -0.010008761659264565, 0.010945076122879982, -0.0476493239402771, 0.05185454338788986, -0.01856052130460739, 0.0012035915860906243, 0.008726948872208595, -0.05909635126590729, 0.006917477119714022, -0.04300270974636078, -0.005467134062200785, 0.010743986815214157, 0.022414153441786766, -0.016335587948560715, -0.048545096069574356, -0.014434872195124626, 0.06575675308704376, -0.00799625739455223, -0.03343377634882927, 0.026229122653603554, -0.02934027649462223, 0.0755472406744957, 0.06923269480466843, -0.01066554430872202, 0.028595605865120888, -0.0689435824751854, 0.0014710081741213799, -0.0264180526137352, -0.03311854228377342, -0.021701859310269356, 0.035727646201848984, -0.009653037413954735, 0.01217617653310299, -0.02819880284368992, 0.04998346418142319, -0.025498297065496445, -0.05606857314705849, -0.03664078935980797, -0.052640896290540695, 0.02443775348365307, -0.039348054677248, -0.004504160489886999, 0.01023948471993208, -0.03972659260034561, -0.018323605880141258, -0.0119221406057477, -0.06631340831518173, 0.0022083118092268705, -0.03867679089307785, 0.01969953253865242, 0.02462458238005638, -0.055368054658174515, 0.04507141187787056, -0.04374900832772255, -0.013416788540780544, 0.022564737126231194, -0.3348541855812073, -0.07251886278390884, 0.02708742581307888, 0.018015116453170776, 0.029000261798501015, -0.08740878850221634, 0.02329275943338871, -0.016331296414136887, 0.10403314232826233, 0.11252061277627945, -0.008364139124751091, -0.06044063717126846, -0.06557141989469528, 0.014190837740898132, 0.05200649052858353, 0.057042453438043594, 0.023005833849310875, 0.01990143582224846, -0.03838203847408295, 0.023213054984807968, 0.005807297304272652, 0.023412544280290604, -0.003540064673870802, -0.08588618040084839, 0.03173188492655754, 0.02231895551085472, 0.0754166692495346, 0.006438758689910173, -0.002488495549187064, 0.011400590650737286, -0.026477454230189323, 0.016447966918349266, -0.03231734409928322, -0.07358714938163757, 0.02680116333067417, -0.03859598562121391, 0.015148093923926353, 0.00857675913721323, 0.0005702365306206048, 0.039533328264951706, 0.030530154705047607, -0.013551265001296997, -0.0021179208997637033, -0.08014988899230957, -0.033109039068222046, -0.011089443229138851, -0.0073210555128753185, -0.015186437405645847, -0.03370934724807739, 0.07849562168121338, -0.009868006221950054, 0.05959472060203552, 0.03848392888903618, 0.04496687650680542, -0.03881724551320076, -0.03301903232932091, -0.07792523503303528, 0.0017358156619593501, -0.07354667782783508, -0.049072183668613434, 0.029030660167336464, -0.03684325888752937, 0.034878578037023544, -0.06071212515234947, 0.010955693200230598, 0.012327580712735653, -0.06978974491357803, -0.03874094784259796, 0.006462417542934418, 0.08813056349754333, -0.007030918728560209, 0.17023758590221405, 0.03952556103467941, 0.015012307092547417, 0.06464891135692596, 0.023802200332283974, -0.006452787667512894, -0.09681646525859833, -0.058916643261909485, 0.007139476947486401, 0.09628552198410034, 0.06260433793067932, 0.06612099707126617, 0.046497538685798645, 0.016189269721508026, 0.012360774911940098, 0.02318163774907589, -0.007098519708961248, 0.041989050805568695, 0.05502172186970711, 0.00222983886487782, -0.020083170384168625, 0.01761941984295845, -0.05310891568660736, 0.0026161728892475367, -0.01907416433095932, -0.22172021865844727, -0.03502335026860237, 0.029027940705418587, 0.0736740231513977, 0.017318636178970337, -0.036962948739528656, 0.0349176824092865, -0.024074921384453773, 0.06015050411224365, -0.0035820803605020046, -0.041134245693683624, 0.021833714097738266, 0.028201567009091377, -0.01430582720786333, -0.04382214695215225, 0.007182668428868055, 0.01151063572615385, 0.008733263239264488, 0.025324122980237007, 0.01665523089468479, -0.025209562852978706, -0.029082220047712326, 0.14735014736652374, -0.03386007249355316, -0.030059421434998512, -0.011922866106033325, 0.03529693931341171, -0.050283003598451614, -0.003436703933402896, 0.005089868325740099, -0.043958764523267746, -0.013627385720610619, 0.04195667803287506, 0.024772413074970245, -0.058185454457998276, 0.04633234813809395, -0.05872981622815132, 0.009602953679859638, 0.0023840204812586308, -0.02811403013765812, -0.03137167543172836, 0.06626103073358536, -0.027767324820160866, -0.04746212437748909, 0.029928194358944893, 0.02255018800497055, 0.06427767872810364, -0.04909951984882355, -0.013305054046213627, 0.022745030000805855, -0.01202920638024807, -0.037277866154909134, -0.0029461432714015245, 0.007556038908660412, 0.03842925280332565, 0.0404871329665184, 0.023000724613666534, 0.0002603315806481987, -0.006900658831000328, -0.05329853668808937, -0.024637136608362198, -0.007762498687952757, 0.04257909208536148, 0.07266189903020859, -0.03619810938835144], metadata={'page_label': '2', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e521fc4e-0309-48e4-8171-819132848abb', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '2', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='9c877a6b4c4239b537e2bcacde1da81ccf5f566fcf7e1ec72922dca99c239f68'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cc7b2c89-64a0-414e-ae91-a782553f6ad2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4a8190974c6a46f5740fe82605954302fff7b34968aa1222f62910c2e6bc9308')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='(AI) techniques and, more precisely, Deep Learning (DL) for their detection and subsequent removal. Most of the\\nwork that has been done in this ﬁeld uses datasets of news written in English as a source of information, which are\\ncomposed of properly labeled sentences publicly available. Although fake news is a common problem across different\\nlanguages, including Spanish, there is not a signiﬁcant amount of properly labeled fake news in Spanish to effectively\\ntrain a DL model for fake news detection, similar to those proposed for the English language. Indeed, to the best of our\\nknowledge, recently in 2019 the ﬁrst corpus of fake news in Spanish exclusively adapted for such a task was presented\\nin [2]; nevertheless, this corpus consists of 971 labeled news, which is an insufﬁcient amount of samples to train a solid\\nDL model from scratch. Therefore, the main objective of this work is to design a Machine Learning (ML) strategy for\\nthe detection of fake news in Spanish, based on Transfer Learning techniques and/or machine translation tools, which\\nallow the use of previously trained models, both in English and Spanish.\\nThis paper is organized as follows: section 2 presents some antecedents on the use of ML and DL models for fake\\nnews detection in different languages, doing emphasis on English and Spanish; section 3 presents the pre-processing\\nstrategies applied to the texts, and also the models and embeddings we employed; in section 4 we present the datasets\\nutilized and the methodology for evaluating the different models, as well as the settings for the experiments carried out\\nand the outcomes we obtained. Finally, we discuss the results and present the conclusions of this paper in section 5.\\n2 Related Work\\nAutomatic fake news detection (FND) is a task that has attracted extensive attention from AI researchers in recent years;\\nthis has been evidenced by the large number of publications in which the problem has been addressed by applying\\ndifferent strategies. Shu et al. [3] report a summary of research works on FND in social networks, analyzing the aspects\\ninvolved from psychology, social theories, and algorithmic points of view. As in many ML applications, the proposed\\napproaches addressing FND are composed of two stages: feature extraction and model building; the ﬁrst refers to the\\nnumerical representation of news content and related information; the second proposes the development of a machine\\nlearning model to distinguish between fake news and legitimate news. For example, Wu and Liu in [4] assume that fake\\nnews is typically manipulated to resemble real news; thus, they propose a classiﬁer based on propagation paths in social\\nnetworks using Long Short-Term Memory Recurrent Neural Networks (LSTM-RNN) and Embeddings. Although the\\nFND task has traditionally been stated as a bi-class classiﬁcation problem, in [5] the author presents a dataset in English\\n(The Liar Dataset), which is composed of 6 classes: pants-ﬁre, false, barely true, half-true, mostly true, and true. In\\naddition, this author evaluates four classiﬁcation models following an approach where he considered both meta-data and\\ntext; hence, he presented Support Vector Machine (SVM) as the best classical ML model, and Convolutional Neural\\nNetwork (CNN) as the best DL model, which outperformed the other models with an accuracy of 27% on the test set.\\nUsing this same dataset, Bracsoveanu and Andonie in [6], propose to add a pre-processing stage based on the extraction\\nof semantic features from the text. These authors also evaluate classical ML and DL models, ﬁnding the SVM model\\nto be the best in terms of performance (28.4%) for classical ML, and the CapNetLSTM model (64.4%) for DL, which\\nwas used in combination with a pre-trained Embeddings model; these results were obtained on the dataset presented in\\n[5]. The authors conclude that employing Semantic Features signiﬁcantly improves accuracy in fake news detection;\\nin particular, for DL models, the improvement in accuracy was up to 5-6%. Furthermore, they also highlighted that\\n\"the accuracy of the various models greatly varies depending on the data sets and the number of classes involved\", a\\nphenomenon we also noticed across this state-of-the-art review.\\nPrevious works tackled the FND task using datasets in English; however, this paper focuses on FND for Spanish.', mimetype='text/plain', start_char_idx=0, end_char_idx=4343, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       "  TextNode(id_='cc7b2c89-64a0-414e-ae91-a782553f6ad2', embedding=[-0.014943450689315796, 0.016930703073740005, -0.032495323568582535, 0.027996307238936424, 0.10885249823331833, -0.01928376406431198, -0.02216627076268196, 0.051401011645793915, 0.007189765572547913, -0.004937569610774517, 0.01172403059899807, -0.01913329027593136, -0.02228785865008831, 0.019935505464673042, 0.0448545403778553, 0.02876882441341877, 0.05059012025594711, -0.052100636065006256, -0.02475908026099205, -0.038729649037122726, 0.02940945141017437, -0.009526478126645088, 0.03539277985692024, -0.0006801396957598627, 0.017617905512452126, -0.008674371056258678, 0.003953044768422842, 0.013170450925827026, -0.046481456607580185, -0.203425794839859, -0.0074786352925002575, -0.02684810385107994, 0.0902981385588646, -0.0353839173913002, -0.032709818333387375, 0.0369129404425621, -0.04283981770277023, -0.004437148571014404, -0.051694151014089584, 0.015729006379842758, -0.03996936231851578, -0.026788344606757164, -0.021208064630627632, -0.009347912855446339, 0.03758006915450096, -0.06233065202832222, -0.017207512632012367, 0.018224555999040604, -0.0812768042087555, 0.026854446157813072, -0.010173098184168339, -0.003715626895427704, -0.014748080633580685, 0.010263992473483086, 0.02664448879659176, 0.030703837051987648, -0.0010108292335644364, -0.032600924372673035, 0.006363757885992527, 0.05713397264480591, 0.00046400597784668207, 0.056434374302625656, -0.16223476827144623, 0.021567001938819885, -0.08828424662351608, 0.04350799694657326, -0.03771363943815231, 0.03437098488211632, -0.015521003864705563, 0.05081024765968323, 0.022516315802931786, 0.013969062827527523, 0.05678027495741844, 0.0504721961915493, 0.006687376648187637, 0.049875520169734955, 0.014671772718429565, 0.004367554560303688, 0.029964597895741463, 0.017699850723147392, 0.022994043305516243, 0.05396910756826401, 0.0028049435932189226, -0.019468480721116066, -0.01736639440059662, -0.02104048803448677, -0.007964184507727623, -0.02812132239341736, 0.005472071468830109, -0.03496463596820831, -0.045259036123752594, 0.0026174825616180897, 0.03570697084069252, 0.011777169071137905, -0.06775716692209244, -0.04356754943728447, 0.009890597313642502, 0.006334594450891018, 0.01185897458344698, 0.3714407980442047, -0.005103600211441517, 0.005128049291670322, 0.05905101075768471, -0.06695224344730377, 0.02111203595995903, -0.023662548512220383, -0.03529253229498863, -0.022267743945121765, -0.002476033754646778, 0.007413889747112989, -0.04161859303712845, -0.014198239892721176, 0.009876943193376064, -0.029607603326439857, -0.013545069843530655, -0.029305443167686462, 0.10352843999862671, 0.06274604797363281, -0.03145076707005501, 0.00830292608588934, -0.029600169509649277, -0.024792462587356567, 0.013621841557323933, -0.009587357752025127, 0.05718756094574928, 0.04021801799535751, 0.06250005960464478, 0.07742363214492798, 0.09558938443660736, 0.016774671152234077, 0.008066138252615929, 0.040710724890232086, -0.03990788012742996, 0.0014772997237741947, 0.007836420089006424, 0.028812695294618607, -0.03177711367607117, 0.044477954506874084, -0.024935442954301834, -0.0476941242814064, -0.027881529182195663, -0.03654170781373978, 0.0535263791680336, 0.03509204834699631, -0.1494043916463852, 0.05627011880278587, -0.05208297818899155, -0.00037604867247864604, -0.08200547844171524, -0.01962781324982643, -0.03160238638520241, 0.08619321882724762, 0.017300890758633614, -0.026830323040485382, -0.006026260554790497, -0.012619981542229652, 0.05673534795641899, -0.05018748342990875, -0.0606456995010376, -0.02963864430785179, 0.02516409195959568, -0.022458916530013084, 0.007907143794000149, 0.07266303151845932, 0.00907560158520937, -0.04636775702238083, 0.0026923585683107376, 0.024654977023601532, 0.0011414237087592483, -0.043406154960393906, 0.04902856424450874, -0.010590762831270695, 0.025786757469177246, 0.012841533869504929, -0.04324981942772865, -0.00978553481400013, -0.029105769470334053, -0.015840908512473106, 0.02795918844640255, -0.00331433885730803, 0.007727855816483498, -0.05257130786776543, -0.022237403318285942, 0.043444205075502396, -0.02635202556848526, -0.03347773849964142, -0.028987396508455276, -0.036962930113077164, 0.0734429582953453, 0.037148747593164444, -0.007301108445972204, 0.034468334168195724, -0.026792112737894058, 0.0030043849255889654, -0.013864210806787014, 0.015814010053873062, 0.014910903759300709, 0.012243671342730522, -0.025457996875047684, -0.006684870924800634, -0.04319119080901146, 0.06195536628365517, -0.04010440409183502, -0.060463741421699524, -0.03706784546375275, -0.08193667232990265, 0.023267200216650963, -0.017225492745637894, 0.023262163624167442, -0.01162566989660263, -0.01122018601745367, -0.015677303075790405, 0.011812800541520119, -0.025152910500764847, -0.022066138684749603, -0.044534195214509964, -0.0006841982831247151, 0.05439057573676109, -0.044993042945861816, 0.08770100027322769, -0.03322162479162216, -0.03068714402616024, 0.015995992347598076, -0.33048301935195923, -0.07325597107410431, 0.042017534375190735, 0.042351700365543365, 0.011520450003445148, -0.06758775562047958, 0.024361087009310722, -0.028165096417069435, 0.05405845493078232, 0.09437651187181473, -0.03727155923843384, -0.04023071750998497, -0.07173755764961243, 0.001190735143609345, 0.03908718377351761, 0.044766511768102646, 0.030539624392986298, 0.01890287548303604, -0.03144681453704834, 0.0035074257757514715, 0.017963683232665062, 0.00981938373297453, 0.010384883731603622, -0.048111334443092346, 0.02299237996339798, -0.017431989312171936, 0.08405464142560959, 0.049059901386499405, -0.007714919745922089, -0.016147445887327194, -0.01986437290906906, 0.013849708251655102, -0.021669553592801094, -0.016240697354078293, 0.057473257184028625, 0.00664237467572093, 0.021212592720985413, 0.01198954600840807, -0.0023284009657800198, 0.048659007996320724, 0.05446852371096611, 0.00950756948441267, 0.023854201659560204, -0.06726399064064026, -0.041656531393527985, -0.0421336330473423, 0.014520595781505108, -0.01837867498397827, -0.03588191419839859, 0.028250154107809067, 0.011477872729301453, 0.06673266738653183, 0.07469028979539871, 0.0384177565574646, -0.01886020042002201, -0.0267026349902153, -0.07087976485490799, 0.014594991691410542, -0.058252040296792984, -0.07802990078926086, 0.043669406324625015, -0.02159917540848255, 0.05082971975207329, -0.06493736803531647, 0.014245164580643177, 0.011540275067090988, -0.0402960442006588, -0.036968886852264404, 0.007440558169037104, 0.07115112990140915, -0.041194044053554535, 0.14398911595344543, 0.004301849752664566, 0.01954304426908493, 0.05195016413927078, 0.013564600609242916, -0.0035908056888729334, -0.0716438814997673, -0.039432670921087265, 6.15934959569131e-06, 0.10913805663585663, 0.06806351989507675, 0.08026237785816193, -0.0024792891927063465, 0.0028202892281115055, -0.004732436966150999, 0.03822901472449303, -0.009738536551594734, 0.03852619230747223, 0.0722028911113739, -0.0008594060782343149, -0.003348531434312463, 0.022662930190563202, -0.026844922453165054, 0.017125042155385017, 0.010547630488872528, -0.25095510482788086, -0.014790019951760769, 0.03089538961648941, 0.0021598050370812416, 0.0327526293694973, -0.02864200994372368, 0.0326085202395916, -0.07327362895011902, 0.02521480992436409, 0.0009191673598252237, -0.022424103692173958, 0.04909800738096237, 0.03439253941178322, -0.03193826228380203, -0.01124880276620388, 0.03376470133662224, 0.034156784415245056, 0.017200477421283722, 0.02185378409922123, -0.01166614331305027, 0.00390885304659605, -0.018638262525200844, 0.16679275035858154, -0.029458116739988327, -0.03547414019703865, 0.004312869161367416, 0.025632014498114586, -0.05863203480839729, -0.013977235183119774, 0.021797385066747665, 0.014338864013552666, -0.03355320915579796, 0.09418483823537827, 0.02659853920340538, -0.06420662999153137, 0.03444261476397514, -0.020982813090085983, 0.03811943903565407, -0.004468416795134544, -0.04814988002181053, 0.0009402451105415821, 0.05627073720097542, -0.033113207668066025, -0.08439379185438156, 0.019557716324925423, 0.00075759511673823, 0.07851524651050568, -0.05549092963337898, 0.001228228909894824, 0.008841733448207378, -0.01793481409549713, -0.006193553563207388, -0.049533452838659286, -0.013262487947940826, 0.03493807464838028, 0.0023193100932985544, 0.01036289893090725, 0.013301651924848557, 0.002043995773419738, -0.05453263968229294, -0.04568633809685707, -0.03710872679948807, 0.007709173951297998, 0.06007453799247742, -0.013311696238815784], metadata={'page_label': '2', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e521fc4e-0309-48e4-8171-819132848abb', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '2', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='9c877a6b4c4239b537e2bcacde1da81ccf5f566fcf7e1ec72922dca99c239f68'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='88b20806-31fd-4176-8866-ae7b1001d29f', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '2', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='6bf00440385cd8810d1e1f561f81e0256dbaa3468fe4ebdd16366b7c04780bc2')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Faustini and Covoes propose in [7] an approach using text features that can be generated independently of the news\\nsource platform and, as far as possible, independently of the news language under analysis. The authors report\\ncompetitive results for news in languages belonging to the Germanic, Latin, and Slavic language groups. They used\\nﬁve datasets, and each one was processed with four different Natural Language Processing (NLP) techniques for text\\nrepresentation. Then, experiments were performed with different models obtaining the best result with Random Forest\\nand SVM algorithms, combined with Bag-of-Words (BoW) as text representation technique; hence, they got a prediction\\nrate of up to 95% for news in the speciﬁed linguistic groups. Additionally, Posadas-Durán et al. [2] address the FND\\ntask for Spanish news, using different classical ML models: SVM, Random Forest, Logistic Regression, and Boosting;\\nthese models were combined with different strategies for text pre-processing that allow extracting useful semantic\\ninformation for the detection task: BOW, Part of Speech tags (POS tags) and n-grams, as well as applying Stop Words\\nto avoid prepositions and/or punctuation marks in the text. The experiments were carried out using a proprietary dataset\\n1 (released under CC-BY-4.0 license). The authors report results of up to 77.28% accuracy for one of the combinations.\\nTo the best of our knowledge, no works applying DL models in the Spanish FND task have been published so far.\\n1https://github.com/jpposadas/FakeNewsCorpusSpanish\\n2', mimetype='text/plain', start_char_idx=4344, end_char_idx=5897, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       "  TextNode(id_='c7da3fe9-da44-4066-9869-ee57e9b1a4aa', embedding=[-0.009469946846365929, 0.009593228809535503, -0.02267494797706604, 0.01882537268102169, 0.050630997866392136, -0.014590118080377579, -0.04810953885316849, 0.014144648797810078, 0.05505803972482681, -0.035129886120557785, 0.005233197472989559, -0.006825482007116079, 0.008662127889692783, 0.01305682584643364, 0.023424796760082245, 0.018808096647262573, 0.010010565631091595, 0.0100971395149827, -0.010839633643627167, -0.045094773173332214, 0.05774849280714989, -0.00044071549200452864, 0.03593497350811958, 0.002257022075355053, 0.035611409693956375, -0.015960190445184708, -0.022365065291523933, -0.017616452649235725, -0.003309981431812048, -0.20785805583000183, 0.03249161317944527, -0.03157195448875427, 0.1012437492609024, -0.0005608728970400989, -0.0355805829167366, 0.040592774748802185, -0.06084033101797104, 0.0202057883143425, -0.0044072153978049755, -0.009598457254469395, -0.03557596355676651, -0.03561810031533241, -0.04675602912902832, -0.04188390076160431, 0.05468348413705826, -0.06901538372039795, -0.04506321996450424, -0.036504290997982025, -0.029122117906808853, 0.02546394057571888, -0.010489821434020996, -0.03293873742222786, -0.017581798136234283, 0.025747772306203842, 0.02748323231935501, 0.03289022669196129, 0.04258660599589348, 0.0073750317096710205, 0.030809132382273674, 0.06471952050924301, 0.014342591166496277, 0.04215572401881218, -0.14910605549812317, 0.05988948419690132, -0.024206945672631264, 0.036093570291996, -0.022368932142853737, 0.052535008639097214, -0.03604447841644287, 0.05918744578957558, -0.027894631028175354, -0.00971182994544506, 0.028646811842918396, 0.08451290428638458, 0.029893692582845688, 0.053856562823057175, 0.048128508031368256, -0.012941630557179451, 0.030109187588095665, -0.02302490547299385, 0.03444085270166397, 0.03324422240257263, 0.03636468946933746, -0.013670919463038445, 0.020566163584589958, -0.02699499949812889, -0.006981946993619204, -0.03941866010427475, -0.014318590052425861, -0.0634210854768753, -0.040997229516506195, -0.026100924238562584, 0.0010705580934882164, 0.026148943230509758, -0.0837840586900711, -0.06242082640528679, 0.019115863367915154, 0.027173461392521858, -0.0033258215989917517, 0.319442480802536, -0.02010311372578144, -0.0028553642332553864, 0.016777178272604942, -0.05169767513871193, -0.008320373483002186, -0.005799488164484501, -0.02691689133644104, -0.0018719021463766694, -0.03481685370206833, 0.0485374815762043, -0.043222084641456604, -0.03653862327337265, -0.0035221013240516186, -0.024915816262364388, -0.0019137986237183213, -0.017228392884135246, 0.06314835697412491, 0.04863985627889633, 0.022517094388604164, -0.003128939075395465, -0.026332054287195206, -0.004736873786896467, -0.03251629322767258, 0.009548849426209927, 0.04914577305316925, 0.030239416286349297, 0.07710118591785431, 0.0794050395488739, 0.07544625550508499, 0.020832108333706856, 0.023163938894867897, 0.033376652747392654, -0.08711617439985275, 0.023894013836979866, -0.010809115134179592, 0.06372231245040894, -0.03519168123602867, -0.00026851435541175306, -0.03304301202297211, -0.024022014811635017, -0.028205450624227524, 0.020876707509160042, 0.03303585946559906, -0.002667204011231661, -0.12981124222278595, 0.13388009369373322, -0.06482432782649994, -0.050910163670778275, -0.04128893464803696, -0.035266753286123276, -0.01052738819271326, 0.06909924745559692, -0.03550850972533226, -0.006818610709160566, 0.01896795630455017, 0.024079784750938416, 0.05926777794957161, -0.049015119671821594, -0.09188611805438995, -0.019883306697010994, 0.006471200380474329, -0.006628784816712141, -0.023417694494128227, 0.12333562225103378, 0.04026353731751442, -0.06091461703181267, -0.002506800927221775, -0.030389204621315002, -0.03359012305736542, -0.0363561287522316, 0.06399784982204437, -0.01727655902504921, -0.007225785870105028, 0.06735553592443466, -0.061955783516168594, 0.030007513239979744, -0.05169416964054108, -0.04388723149895668, 0.03302505984902382, -0.005600265692919493, 0.008970439434051514, -0.031976133584976196, -0.006703154183924198, 0.05319458991289139, 0.02071109041571617, -0.00990845263004303, -0.008322632871568203, 0.001999863889068365, 0.06122438237071037, 0.020629916340112686, 0.014535794034600258, 0.0004949463182128966, -0.06672093272209167, -0.020991627126932144, -0.022131383419036865, 0.043067511171102524, 0.007344117853790522, 0.001078384113498032, -0.032922036945819855, -0.0428052693605423, 0.012620558962225914, 0.08545751124620438, 0.009451370686292648, -0.0731588676571846, -0.030926736071705818, -0.0007171582547016442, 0.013398348353803158, -0.029674148187041283, 0.01171672809869051, 0.044113822281360626, -0.05694812908768654, -0.015013650059700012, -0.016473498195409775, -0.04741086810827255, -0.0012812395580112934, 0.015574873425066471, 0.03515055403113365, 0.06210212782025337, -0.016147073358297348, 0.06034596264362335, -0.031528670340776443, -0.015339634381234646, -0.029021266847848892, -0.31811031699180603, -0.04956555739045143, 0.03692181780934334, 0.0121235903352499, 0.047458749264478683, -0.06257891654968262, 0.0009958125883713365, -0.008297291584312916, 0.008211616426706314, 0.04963459447026253, -0.05217178538441658, -0.03316092491149902, -0.056323155760765076, -0.03583666309714317, 0.022744109854102135, 0.03505011647939682, 0.06570649147033691, 0.0010072615696117282, -0.038399845361709595, 0.015522843226790428, 0.029809216037392616, 0.008382628671824932, -0.004202370066195726, -0.06222708150744438, -0.0008714394643902779, -0.0015598511090502143, 0.07614948600530624, 0.014693166129291058, 0.05542955547571182, -0.05052231252193451, 0.015331973321735859, -0.00257118116132915, -0.044068947434425354, -0.02436112053692341, 0.03800499811768532, -0.045368269085884094, 0.002756419125944376, 0.026376618072390556, -0.00505974143743515, 0.0352863110601902, 0.0050264508463442326, 0.019069163128733635, 0.052002694457769394, -0.05806783214211464, -0.03292432054877281, -0.03862135857343674, -1.1863546205859166e-05, -0.07983498275279999, -0.017291788011789322, -0.0002751068095676601, 0.006476226728409529, 0.05729379877448082, -0.0007860484765842557, 0.010159281082451344, -0.018033703789114952, 0.006993594579398632, -0.066559799015522, 0.021166862919926643, -0.06661252677440643, -0.0611698254942894, 0.041298333555459976, -0.08206281810998917, 0.06383657455444336, -0.048505671322345734, -0.020976604893803596, 0.0098029226064682, 0.00914874766021967, 0.025498662143945694, -0.010127839632332325, 0.04150675982236862, -0.07144293189048767, 0.1106836125254631, 0.01036026980727911, -0.012931025587022305, 0.0801352858543396, 0.01334607508033514, -0.005157222039997578, -0.07651456445455551, -0.05193512514233589, 0.023664532229304314, 0.08809240162372589, 0.06361990422010422, 0.10771165788173676, -0.024267196655273438, 0.037973593920469284, 0.05059034749865532, 0.049262188374996185, -0.048711396753787994, 0.023264754563570023, 0.07583274692296982, -0.011108430102467537, -0.029654428362846375, 0.02232326753437519, 0.0014615420950576663, -0.0021559877786785364, -0.027346191927790642, -0.2516251802444458, 0.000847550283651799, 0.04214303195476532, 0.04194709286093712, 0.024996424093842506, -0.010809296742081642, 0.01115635596215725, -0.06116194650530815, 0.031075390055775642, 0.027222391217947006, -0.062058452516794205, 0.051007840782403946, 0.05928293243050575, -0.04791000112891197, -0.03300999850034714, 0.030838845297694206, 0.0651092454791069, 0.00579913379624486, 0.012516386806964874, -0.01975739374756813, 0.01137334480881691, -0.035717159509658813, 0.17292192578315735, -0.06888560950756073, -0.0029286087956279516, -0.04345135763287544, 0.044521041214466095, -0.017184583470225334, -0.021243084222078323, 0.03650246933102608, 0.01773759536445141, 0.005563848186284304, 0.11686985194683075, 0.05216437578201294, -0.005953842308372259, 0.04709206894040108, 0.022708710283041, -0.0006731029134243727, 0.01163934450596571, -0.0014221486635506153, 0.01141945831477642, 0.0387861467897892, -0.05131445452570915, -0.08920291811227798, 0.0033018230460584164, -0.00044802858610637486, 0.07031776010990143, -0.051101572811603546, -0.024971909821033478, 0.017800722271203995, -0.05201492831110954, -0.0065143899992108345, -0.02029760740697384, -0.014688830822706223, 0.0732540488243103, 0.03571183234453201, -0.030841227620840073, 0.0006568882963620126, -0.02817413955926895, -0.031240025535225868, -0.008769138716161251, -0.04645989090204239, -0.014775400049984455, 0.08867690712213516, -0.02729117125272751], metadata={'page_label': '3', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='b51881e0-a7b5-40eb-be92-7d99bde1a4e7', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '3', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='f44390a7ec43c149fcccfa1aa3bbf0547cebe9b0994a80650269561966e23fc0')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='3 Methods\\n3.1 Preprocessing steps\\nIn order to obtain consistent results, a data standardization process known as Text Normalization was performed, which,\\nin addition to eliminating non-alphanumeric characters in the text, includes some of the most commonly used techniques\\nin NLP:\\n• Stop Words:we removed words there is an agreement they do not contribute to the models learning process in\\nthe context of the problem addressed; for instance, articles and prepositions.\\n• Stemming: this technique was used to reduce words to their root.\\n• Tokenization and Padding:as usual in text processing tasks, we performed tokenization and padding, when\\nrequired, for words and sentences representation.\\nSubsequently, we decided to compare some of the most common techniques regarding text representation: BoW, which\\nprovides the number of occurrences of each word in the text corpus; term frequency-inverse document frequency(tf-idf),\\nwhich provides a weighted measure of the importance of each term within the text (according to its frequency of\\noccurrence in sentences); and pre-trained Word Embeddings, where words and the semantic relationships among them\\nare represented as a vector. It is worth clarifying that, we call Word Embeddings to both pre-trained vectors such as\\nword2vec or GloVe, and embeddings obtained from pre-trained models such as ELMo or BERT (presented in subsection\\n3.2).\\n3.2 Models\\nClassical ML models, and DL models based on artiﬁcial neural networks were used. We employed ML models intending\\nto create a baseline for comparison purposes; hence, we selected the following: Support Vector Machine (SVM),\\nRandom Forest (RF), Gradient Boosting Tree (GBT), and Multi-Layer Perceptron (MLP). For the case of DL classiﬁers,\\nbesides word embeddings, two types of layers were used: Long Short-Term Memory Recurrent Neural Network\\n(LSTM-RNN) using a many-to-one architecture, and Convolutional Neural Network (CNN). LSTM-RNN processes\\nthe input data as sequences of dependent observations, while CNNs can process n-grams through the application of\\nconvolutional ﬁlters. A schematic of the DL classiﬁers in combination with a embedding layer is illustrated in Figure 1;\\nthis ﬁgure shows the arrangement of the aforementioned layers, and the different word embeddings we used which are\\npresented next.\\nFigure 1: Schematic of DL classiﬁers in combination with Embedding Layer\\n3', mimetype='text/plain', start_char_idx=0, end_char_idx=2382, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       "  TextNode(id_='880b9cb5-f930-4df4-9776-58524465d9cf', embedding=[-0.02150428108870983, -0.01289453450590372, -0.0010746889747679234, 0.050258804112672806, 0.04089561849832535, 0.009466342628002167, -0.024164017289876938, -0.009276316501200199, 0.024403180927038193, -0.022578416392207146, 0.006269362755119801, -0.02693839557468891, 0.028639521449804306, 0.027054041624069214, 0.04905833676457405, -0.011332519352436066, -0.006200170144438744, -0.03270920738577843, -0.04076456278562546, -0.06884484738111496, 0.05486998334527016, -0.006088114343583584, 0.012265077792108059, -0.016366472467780113, 0.007327343337237835, -0.008710120804607868, -0.02051490917801857, 0.01118770893663168, -0.0025349585339426994, -0.22445525228977203, -0.0030465861782431602, -0.031864892691373825, 0.03231324255466461, 0.05927647650241852, -0.030510639771819115, 0.05199491232633591, -0.0382518470287323, 0.001382639748044312, -0.04448608309030533, 0.024149904027581215, -0.03008098155260086, 0.007686346769332886, -0.015309586189687252, -0.01557590439915657, 0.032812513411045074, -0.032011013478040695, -0.0365680567920208, -0.017239175736904144, -0.05991457775235176, -0.015471551567316055, 0.04242318496108055, -0.03840361163020134, -0.02391939051449299, 0.027632759883999825, 0.04167494550347328, 0.04311469569802284, 0.02536482736468315, -0.007749602664262056, -0.001969139324501157, 0.07795240730047226, -0.0006408222834579647, 0.040821097791194916, -0.1352481096982956, 0.04336119070649147, -0.04145357385277748, 0.04454050958156586, -0.0361938439309597, 0.04391539469361305, -0.02743559144437313, 0.07337294518947601, -0.008167561143636703, -0.03482046723365784, 0.010274882428348064, 0.032543450593948364, 0.028549207374453545, 0.06736250221729279, 0.059721048921346664, 0.00954341422766447, 0.046958256512880325, -0.041743963956832886, 0.005211357027292252, 0.021956538781523705, 0.0264236181974411, -0.025796016678214073, -0.004323778674006462, -0.0490802638232708, 0.01684129238128662, -0.04407310485839844, -0.019455308094620705, 0.02001834474503994, -0.04115968570113182, -0.011105573736131191, -0.005931915249675512, 0.02497907541692257, -0.026894520968198776, -0.06163618341088295, 0.0496213361620903, 0.006760608404874802, -0.021755389869213104, 0.35104069113731384, -0.010402187705039978, -0.017857370898127556, 0.03905119001865387, -0.04522386193275452, 0.015396921895444393, -0.014164564199745655, -0.015486117452383041, 0.008556471206247807, -0.06693755090236664, 0.03318973258137703, -0.07140666246414185, -0.013709471561014652, -0.016965080052614212, -0.03723980486392975, 0.012251747772097588, -0.029583873227238655, 0.04518495872616768, 0.03385672718286514, 0.027579201385378838, -0.01852010004222393, -0.052718114107847214, -0.020748144015669823, 0.01870294287800789, 0.009671148844063282, 0.026886245235800743, 0.025695474818348885, 0.04532257467508316, 0.09524403512477875, 0.1054358258843422, 0.01436536479741335, 0.009336445480585098, 0.022133318707346916, -0.07242894172668457, 0.034523699432611465, -0.023461291566491127, 0.032076988369226456, -0.020922333002090454, -0.0011000153608620167, -0.053601767867803574, 0.0013907833490520716, 0.01538892649114132, 0.01686452142894268, 0.038795407861471176, 0.0074891033582389355, -0.0939953550696373, 0.11936858296394348, -0.05440192297101021, -0.03238607197999954, -0.016114914789795876, 0.017133252695202827, 0.011493371799588203, 0.06999814510345459, 0.006194623187184334, -0.01814880594611168, 0.0019598128274083138, 0.04984540119767189, 0.02573058195412159, 0.00755977351218462, -0.03543010726571083, -0.01345688197761774, -0.01172079797834158, -0.015584206208586693, -0.02246772311627865, 0.06555773317813873, 0.04244140535593033, -0.06178651005029678, -0.043041832745075226, -0.014248591847717762, -0.0014459718950092793, -0.06559934467077255, 0.11293894797563553, -0.0023685572668910027, 0.016593413427472115, 0.032144173979759216, -0.04947143420577049, 0.018415436148643494, -0.0643593817949295, -0.03471392020583153, 0.011100828647613525, -0.003271134803071618, 0.027857428416609764, -0.07040706276893616, -0.03012240119278431, 0.03883197158575058, -0.027434958145022392, -0.012222002260386944, -0.009439121931791306, -0.015254669822752476, 0.08092628419399261, 0.017310714349150658, 0.0155565794557333, 0.0009235966135747731, -0.05459122732281685, 0.010699329897761345, -0.007852083072066307, 0.019674794748425484, 0.00456645293161273, 0.022139746695756912, -0.024020710960030556, -0.008496281690895557, -0.012955752201378345, 0.0861714705824852, -0.0226507056504488, -0.05971147492527962, -0.06049816682934761, -0.01050810981541872, 0.011988346464931965, 0.005761939566582441, 0.02939879149198532, 0.03032159060239792, -0.06276881694793701, -0.028173884376883507, 0.011993071995675564, -0.004673873074352741, -0.028509076684713364, 0.04169122874736786, -0.004731498658657074, 0.08563878387212753, 0.027842877432703972, 0.031576670706272125, -0.09022823721170425, -0.06750880926847458, -0.005121110938489437, -0.32853421568870544, -0.06280239671468735, 0.009447670541703701, 0.015293046832084656, 0.014460375532507896, -0.05777786672115326, 0.01161121018230915, -0.007116502150893211, 0.05288117751479149, 0.031388331204652786, -0.018449127674102783, -0.048002902418375015, -0.03275757655501366, -0.03412711247801781, -0.013458957895636559, 0.03215666860342026, 0.03846759721636772, -0.013553011231124401, -0.00661936029791832, 0.04545336589217186, -0.0023514116182923317, -0.009748308919370174, 0.01479263510555029, -0.008623629808425903, 0.03862782195210457, -0.012889734469354153, 0.1122790277004242, -0.006977538112550974, 0.020336003974080086, -0.06710522621870041, -0.005387257784605026, -0.004804208409041166, -0.03164711594581604, -0.042438820004463196, 0.030262064188718796, -0.039134055376052856, 0.020502744242548943, 0.04061109572649002, 0.006172852125018835, 0.003818345721811056, 0.005379526410251856, -0.012197038158774376, 0.023822905495762825, -0.06340163201093674, -0.0392356775701046, -0.027425458654761314, -0.028559379279613495, -0.04451652988791466, -0.050632186233997345, 0.009171790443360806, 0.030606858432292938, 0.037163276225328445, 0.05536249279975891, -7.233785436255857e-05, -0.07137327641248703, 0.006659321486949921, -0.04871619865298271, 0.007422091439366341, -0.035968706011772156, -0.00851504411548376, 0.03755387291312218, -0.04073837772011757, 0.046907875686883926, -0.0843198150396347, 0.014226800762116909, 0.012595572508871555, -0.020636431872844696, 0.004746441263705492, 0.010645916685461998, 0.009972039610147476, -0.06795229762792587, 0.12706196308135986, -0.024731380864977837, 0.007413762621581554, 0.061652276664972305, 0.006021789275109768, 0.00969389546662569, -0.06306996196508408, -0.09939323365688324, 0.0082904864102602, 0.08847759664058685, 0.017011549323797226, 0.06858614087104797, -0.01044455822557211, 0.06615059822797775, 0.009806190617382526, 0.09990847855806351, -0.004814143292605877, 0.01266429666429758, 0.08525396883487701, -0.016647258773446083, -0.02224855311214924, -0.00316862971521914, -0.0127565898001194, 0.0001237245451193303, -0.07325306534767151, -0.24772368371486664, 0.0294756181538105, 0.0743398666381836, 0.06765004992485046, 0.03129909560084343, -0.039484716951847076, 0.02443704940378666, -0.08349170535802841, 0.015628933906555176, 0.012051427736878395, -0.014188137836754322, 0.023721491917967796, 0.10014014691114426, 0.0017960231052711606, -0.04485451430082321, 0.03594233840703964, 0.08381890505552292, 0.009115925058722496, 0.026515191420912743, -0.004084968939423561, -0.017308542504906654, -0.03008616715669632, 0.18355010449886322, -0.04042394086718559, 0.0037119181361049414, -0.028330061584711075, 0.02146720327436924, -0.08416086435317993, 0.009811223484575748, 0.027528872713446617, 0.014732957817614079, 0.0069841546937823296, 0.07540286332368851, 0.024651920422911644, -0.03687296807765961, 0.021957624703645706, -0.012021249160170555, 0.009037495590746403, 0.04700189083814621, 0.002809976926073432, 0.038475923240184784, 0.012326597236096859, -0.04550885036587715, -0.0971330925822258, -0.00453158188611269, 0.06770648807287216, 0.10820978879928589, -0.031605761498212814, -0.08536110073328018, 0.011269867420196533, 0.008445760235190392, 0.00606763968244195, -0.003630919149145484, -0.04173973202705383, 0.05530622974038124, 0.060825783759355545, 0.0022571939043700695, -0.00034004973713308573, -0.01648685149848461, -0.012354787439107895, -0.0022835726849734783, -0.05497486889362335, 0.008141793310642242, 0.016298113390803337, -0.016763266175985336], metadata={'page_label': '4', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='f1c0ac04-d171-405c-b103-3e4a91c9d0d3', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '4', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='fa221218474492cec6a5c3c239f691bd31603369f061368374b47a7ade9b3be8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6c7552f3-0b49-458c-a3fd-6e2e95ae9d12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7a255df0292d986d9fe8ecdb6c070fab7dba037e7c770c1ef993c2515f2a6b5e')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='In some experiments, we trained the embedding layer as part of the model training process. However, in most cases, we\\nused transfer learning strategies through pre-trained word embeddings. This procedure makes much sense when either\\nthere are not many samples available for training or the computational resources are limited. Four word-embedding\\nvariants were evaluated:\\n1. Global Vectors for Word Representation(GloVe): it is an unsupervised method that captures statistical\\ninformation from a text corpus; in order to generate word representations, its training process is based on\\nthe spectral co-occurrence matrix decomposition [8]. Hence, we made use of the 300-dimensional vectors\\npre-trained on the English Wikipedia corpus, available at [9].\\n2. Embeddings from a Language Model(ELMo): in contrast to GloVe, which provides a ﬁxed meaning for\\neach word, the representations generated by ELMo are functions of the entire sequence, instead of a single\\nword. ELMo encodes words by individual characters, such that it allows the same word to have different\\nrepresentative vectors under different contexts [10]. The pre-trained model was downloaded from the public\\nrepository Tensorﬂow Hub, which can be found at [11].\\n3. Bidirectional Encoder Representations from Transformers(BERT): it is a language representation model\\nbased on another type of model called Transformer, where instead of strictly analyzing the temporal dependence\\nof the input sequence, all possible combinations of the input sequence are evaluated through an attention layer\\n[12]. It has the advantage that its training process can be performed in parallel, since it does not depend on the\\ntemporal condition. For this research, the so-called BERT Base was used, which is a model with a total of 110\\nmillion pre-trained parameters. The pre-trained model was downloaded from the public repository Tensorﬂow\\nHub, available at [13].\\n4. BETO: this model corresponds to a BERT version but instead of English, this models is trained on a large\\ncorpus of text in Spanish [ 14]. The size of the model is similar to a BERT Base, with approximately 110\\nmillion parameters.\\n4 Experiments and Results\\n4.1 Datasets\\nFour free-to-use datasets were chosen to use in this study. Two of them consist of news in English labeled as fake or\\nreal: Fake and real news dataset[15], and News Data Set - Fake OR Real[16]; the other two datasets correspond to\\nnews in Spanish, also properly labeled: The Spanish Fake News Corpus [2] containing 971 news items, and fake news\\nin Spanish [17], consisting of 1600 news items. None of the above datasets had missing or null data, and they are well\\nbalanced considering the two classes involved. The English datasets were merged, resulting in a ﬁnal English corpus\\ncomprising 51233 samples, of which 26645 are fake, and 24588 are genuine; the same procedure was followed over the\\nindividual datasets in Spanish, resulting in a ﬁnal Spanish corpus consisting of 2571 samples, such that 1280 of them\\nare fake and 1291 genuine 2. Figure 2 shows through a chart the corresponding distribution for each resulting dataset.\\nSince the number of samples in Spanish is considerably small to train a DL model from scratch, one of the strategies\\nfollowed during experiments, consists of evaluating the capacity of a DL model trained with the English corpus to\\npredict fake Spanish news translated into English using the Google translation API.\\n4.2 Experimental setup\\nThe experiments were carried out using a Bootstrap (ShufﬂeSplit) validation methodology, considering 5 iterations.\\nDepending on each scheme (described below), the partitioning was done into three subsets (train, development, test) or\\ninto two subsets (train, test), taking 80% for training and 20% for testing (in the case of partitioning into three subsets,\\nfor the internal sub-division train/development we took 80% / 20% respectively); however, in some experiments the\\nsplit of the dataset was set to a ratio of train: 90% / test: 10%. These variations in the partitioning were considered due\\nto the few samples we had in the ﬁnal corpus in Spanish; hence, we wanted to try different combinations aiming at keep\\nas many samples for training as possible.\\nConsidering the balancing condition on the datasets we used, and the fact that we were addressing a bi-class\\nclassiﬁcation task, we chose Accuracy as the performance metric for measuring the generalization ability of the models.', mimetype='text/plain', start_char_idx=0, end_char_idx=4431, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       "  TextNode(id_='6c7552f3-0b49-458c-a3fd-6e2e95ae9d12', embedding=[-0.020840294659137726, -0.02427803725004196, -0.004775209818035364, 0.00585971400141716, 0.09840137511491776, 0.029456786811351776, 0.01062184851616621, 0.003472513286396861, 0.0071659209206700325, 0.001798222423531115, 0.07184585928916931, -0.013282720930874348, -0.03293547034263611, 0.009556137956678867, 0.028235211968421936, 0.009463384747505188, 0.010691062547266483, -0.04919128865003586, -0.01505607832223177, 0.01537766121327877, 0.05494631081819534, 0.0024200251791626215, 0.053171053528785706, -0.004917745944112539, 0.026990989223122597, 0.06917161494493484, -0.02302396669983864, -0.014515308663249016, -0.06311152130365372, -0.16645602881908417, 0.009748594835400581, -0.007744943257421255, 0.026612967252731323, -0.04316294193267822, 0.016441449522972107, -0.017216447740793228, -0.01158593688160181, -5.9443504142109305e-05, -0.0032873270101845264, -0.001528585096821189, 0.0005829041474498808, -0.03711393103003502, 0.03146999701857567, -0.03027387149631977, 0.05902286618947983, -0.049085598438978195, -0.030546724796295166, 0.0020465319976210594, -0.030426550656557083, -0.012847634963691235, -0.05566147714853287, -0.017050419002771378, 0.02120921202003956, 0.026610421016812325, -0.012401897460222244, 0.010137452743947506, 0.050529297441244125, -0.02321922779083252, 0.074600450694561, 0.03437325358390808, 0.052059054374694824, 0.0979454442858696, -0.17802776396274567, 0.04444270581007004, -0.07457301765680313, 0.035805560648441315, -0.02190152183175087, -0.0017919453093782067, -0.048131734132766724, 0.013446180149912834, -0.07725923508405685, -0.056380532681941986, 0.045687779784202576, 0.03572544455528259, 0.023196592926979065, 0.014534424059092999, -0.026963604614138603, -0.02515561319887638, -0.027431627735495567, 0.026788262650370598, -0.019076596945524216, 0.047410834580659866, 0.009331922046840191, -0.036446087062358856, -0.016124453395605087, -0.017524974420666695, 0.027832219377160072, 0.008143077604472637, -0.02928912453353405, 0.021734947338700294, -0.009019999764859676, 0.010080842301249504, 0.05229267105460167, 0.07730014622211456, -0.110824815928936, -0.04457711800932884, -0.007396696601063013, 0.047869060188531876, 0.013860303908586502, 0.3833564817905426, -0.0022608668077737093, -0.07392764091491699, 0.0070752594619989395, 0.01584206148982048, -0.04585721716284752, -0.029043707996606827, 0.02002004347741604, -0.004468954633921385, 0.005092883016914129, 0.030583513900637627, -0.08368025720119476, -0.030390145257115364, -0.004943030886352062, -0.022156530991196632, -0.0027260263450443745, -0.05348151549696922, 0.028140714392066002, 0.05748233199119568, -0.026454340666532516, 0.010736449621617794, -0.013286063447594643, -0.041193887591362, 0.044956836849451065, 0.00021426616876851767, 0.016347652301192284, 0.03570614382624626, 0.07033024728298187, 0.059304408729076385, 0.06319337338209152, 0.003257939824834466, 0.024865906685590744, 0.03140202909708023, -0.0013766427291557193, 0.012409312650561333, 0.025118086487054825, 0.028694309294223785, 0.012631942518055439, 0.03216540440917015, 0.017455635592341423, -0.0002528639743104577, 0.0050605363212525845, 0.013818583451211452, 0.021943314000964165, 0.004282945767045021, -0.0647573322057724, 0.09868619590997696, -0.050311096012592316, 0.03635949268937111, -0.014417958445847034, 0.006581749767065048, 0.000726660480722785, 0.11290197819471359, -0.005993213504552841, -0.009848315268754959, -0.014937600120902061, 0.0002607475034892559, 0.05982323735952377, -0.03391771763563156, -0.06711065769195557, -0.010035248473286629, 0.022256871685385704, -0.03836628422141075, 0.02237941510975361, 0.1231294497847557, 0.013786719180643559, -0.06253104656934738, -0.021931784227490425, 0.0035820859484374523, 0.04585547745227814, -0.01323192659765482, -0.00086964201182127, 1.3901181773690041e-05, 0.01481346320360899, 0.04220836982131004, -0.007181005086749792, 0.038752734661102295, -0.03427539020776749, 0.052494730800390244, -0.012824458070099354, -0.001997623359784484, -0.02924385294318199, -0.03403147682547569, -0.08082453161478043, 0.027950843796133995, -0.03296574205160141, -0.014772208407521248, -0.02403354085981846, 0.02744380384683609, 0.07325838506221771, 0.08046288788318634, -0.005910112056881189, 0.010293028317391872, -0.0663091242313385, 0.01607578620314598, -0.02656344324350357, -0.010294838808476925, -0.034520696848630905, 0.022074637934565544, 0.014190638437867165, -0.05568299442529678, 0.027216818183660507, 0.024276401847600937, -0.0195863526314497, 0.02030300721526146, -0.04575858265161514, -0.028997087851166725, -0.007422890514135361, -0.05011102184653282, -0.04433291032910347, -0.015567895956337452, -0.0390273816883564, -0.004487774334847927, 0.007499356754124165, -0.03698217496275902, -0.007987056858837605, -0.010131868533790112, 0.03609514981508255, 0.026372168213129044, -0.04210745915770531, 0.0392952524125576, -0.04396839439868927, -0.007199898827821016, -0.010801874101161957, -0.36102890968322754, -0.04164091497659683, 0.008678043261170387, 0.0022076687309890985, -0.013104608282446861, -0.040654994547367096, 0.047697510570287704, 0.06143990531563759, 0.03854943811893463, 0.10096267610788345, -0.0014067009324207902, 0.001774159842170775, -0.06870148330926895, -0.02580999583005905, 0.014726828783750534, 0.04276219755411148, 0.03559517487883568, -0.03154372051358223, -0.050156496465206146, 0.029955841600894928, 0.04375988245010376, 0.022826848551630974, -0.030032431706786156, -0.02080758661031723, 0.004233694169670343, 0.03576614335179329, 0.08126527816057205, 0.0490676686167717, 0.013675051741302013, -0.03205309808254242, -0.015452646650373936, 0.04168004170060158, -0.06368790566921234, -0.06225188449025154, 0.03853748366236687, -0.02904757484793663, -0.010174857452511787, -0.020148547366261482, -0.018096167594194412, -0.002486561657860875, 0.017391083762049675, -0.050202626734972, -0.007860671728849411, -0.060228846967220306, 0.0072176046669483185, -0.04198681563138962, -0.0041247098706662655, 0.02612808160483837, -0.00440331781283021, 0.04349636659026146, -0.047159042209386826, 0.06347712874412537, 0.0391966849565506, 0.008066211827099323, -0.0035037887282669544, -0.007582496386021376, -0.07259166985750198, 0.0053775073029100895, -0.08192351460456848, -0.038618601858615875, 0.05061379447579384, -0.010880718007683754, 0.043986521661281586, -0.056543320417404175, 0.017445359379053116, -0.007964065298438072, -0.04789765179157257, -0.042124029248952866, 0.019715961068868637, 0.032025743275880814, -0.03396150469779968, 0.10803494602441788, -0.009662523865699768, 0.012648484669625759, 0.03554563969373703, 0.06015215069055557, -0.001511194626800716, -0.1100442036986351, -0.07542186230421066, -0.015829453244805336, 0.05544140562415123, 0.0726126879453659, 0.04541048780083656, -0.005769079551100731, 0.028690416365861893, 0.010006651282310486, 0.03701567277312279, -0.0483577735722065, 0.05058741942048073, 0.02181887999176979, 0.04569626227021217, -0.0035197145771235228, -0.010137409903109074, -0.034261297434568405, 0.01450327131897211, -0.011617617681622505, -0.22957590222358704, -0.045492444187402725, 0.035796161741018295, 0.08103972673416138, -0.010915767401456833, -0.027658170089125633, 0.030676575377583504, -0.041791971772909164, 0.043847132474184036, -0.007964420132339, -0.01452514436095953, 0.04922030493617058, 0.01504542026668787, -0.032951004803180695, -0.031787872314453125, -0.007835350930690765, 0.06271011382341385, 0.03281784430146217, 0.06344781816005707, 0.022605450823903084, -0.036203477531671524, -0.052416227757930756, 0.18609172105789185, 0.0391647033393383, -0.06370709091424942, 0.014841028489172459, 0.053954724222421646, -0.03842788562178612, -0.024778200313448906, 0.022249847650527954, -0.01616724207997322, -0.018631717190146446, 0.016718024387955666, 0.025958659127354622, -0.028166156262159348, 0.041811101138591766, -0.08958340436220169, 0.02847149781882763, 0.016155721619725227, -0.0013011889532208443, -0.035047147423028946, 0.01774054393172264, -0.051669325679540634, -0.06202581152319908, 0.024393610656261444, 0.022846881300210953, 0.005914153065532446, -0.10725118964910507, 0.015603669919073582, -0.02046838216483593, -0.025198472663760185, -0.027225930243730545, -0.025542527437210083, -0.02300364524126053, 0.012710962444543839, 0.054191190749406815, 0.00999543908983469, 0.0032651876099407673, -0.018439805135130882, 0.026788024231791496, -0.020315947011113167, -0.027703361585736275, 0.04837731271982193, 0.03682122007012367, -0.014757232740521431], metadata={'page_label': '4', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='f1c0ac04-d171-405c-b103-3e4a91c9d0d3', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '4', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='fa221218474492cec6a5c3c239f691bd31603369f061368374b47a7ade9b3be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='880b9cb5-f930-4df4-9776-58524465d9cf', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '4', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='16709c756df612118f534028b9889a781962c0372b210fc1c52f8e98fe0d0ece')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='2In this paper, we refer to the resulting datasets presented in this subsection as follows: the dataset in English, the dataset in\\nSpanish, and the translated dataset.\\n4', mimetype='text/plain', start_char_idx=4432, end_char_idx=4601, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       "  TextNode(id_='5b81631e-1492-4b36-b251-d08e34777723', embedding=[-0.021244069561362267, 0.016102269291877747, -0.022670941427350044, 0.04064624384045601, 0.07543506473302841, 0.025980159640312195, -0.04147462919354439, 0.015339003875851631, 0.04366898536682129, -0.010739772580564022, 0.014758497476577759, -0.05862271413207054, 0.0021850529592484236, 0.013975214213132858, 0.05137620121240616, 0.013644446618855, 0.012892058119177818, -0.06749401986598969, -0.015022709965705872, -0.012706479988992214, 0.014975909143686295, -0.017125513404607773, 0.042471930384635925, 0.002207911340519786, -0.00260437885299325, 0.010288834571838379, 0.011409256607294083, -0.0028943782672286034, -0.025551415979862213, -0.2363796830177307, 0.005359715316444635, -0.05236504599452019, 0.05390371382236481, -0.005843163467943668, -0.020563194528222084, 0.04341701790690422, -0.04196171462535858, -0.022752052173018456, -0.017598183825612068, 0.0010443446226418018, -0.023125527426600456, -0.007978953421115875, -0.0036006243899464607, -0.058075547218322754, 0.03912265971302986, -0.05545225366950035, -0.04923784360289574, 0.017735660076141357, -0.05696558207273483, 0.022799039259552956, -0.031737394630908966, -0.03909584507346153, -0.0029446056578308344, 0.045133721083402634, 0.004153290763497353, 0.04680861532688141, 0.02388191409409046, 0.027018839493393898, 0.009457982145249844, 0.06389409303665161, 0.027705447748303413, 0.06418168544769287, -0.14447183907032013, 0.04156704619526863, -0.0647415742278099, 0.06172841414809227, -0.0375107116997242, 0.021680571138858795, -0.028992047533392906, 0.03369451314210892, -0.024283383041620255, -0.01870754547417164, 0.04767078161239624, 0.04138941690325737, 0.005268186796456575, 0.05994708836078644, 0.014013140462338924, -0.007450099103152752, 0.01836625300347805, -0.015697015449404716, 0.02423139475286007, 0.022172998636960983, 0.030260203406214714, -0.038838233798742294, 0.0061117797158658504, -0.0449695959687233, 0.002238246612250805, -0.007510268595069647, -0.056257158517837524, -0.006491892505437136, -0.02586597390472889, -0.00122677197214216, 0.010234959423542023, 0.03149900585412979, -0.031056199222803116, -0.03150898590683937, 0.015997668728232384, -0.011055206879973412, -0.022472627460956573, 0.4115511178970337, 0.01936945877969265, -0.044881656765937805, -0.01699037291109562, -0.019760742783546448, 0.01287899725139141, -0.008886802941560745, -0.012635593302547932, -0.019118012860417366, -0.005385813768953085, 0.005437501706182957, -0.06623419374227524, -0.051730938255786896, 0.035103939473629, -0.022918956354260445, -0.02438693679869175, -0.0026536560617387295, 0.057067081332206726, 0.02490808814764023, -0.005949995014816523, -0.0009063917677849531, -0.02444452792406082, -0.025201229378581047, 0.03705631569027901, -0.019224105402827263, 0.03356542810797691, -0.01002846471965313, 0.07244554162025452, 0.07648734003305435, 0.07999136298894882, 0.018851403146982193, 0.013962806202471256, 0.0317082479596138, -0.08573415875434875, 0.007678671274334192, 0.005986319854855537, 0.0686243325471878, -0.008586273528635502, 0.011119426228106022, 0.001401140121743083, -0.01569226384162903, 0.004435133654624224, 0.011134246364235878, 0.04330495372414589, 0.018867960199713707, -0.08856526017189026, 0.10208333283662796, -0.06419201195240021, -0.0059535023756325245, -0.05238953232765198, -0.009608293883502483, 0.016931766644120216, 0.09816549718379974, 0.024991851300001144, 0.0035468214191496372, 0.0020385696552693844, 0.032819341868162155, 0.031741559505462646, -0.025539204478263855, -0.06646011024713516, -0.03933512419462204, -0.01748795621097088, -0.04857650399208069, -0.012165662832558155, 0.061502546072006226, -0.018790092319250107, -0.035568997263908386, -0.032853446900844574, -0.011435773223638535, 0.018061958253383636, -0.022051654756069183, 0.07342471927404404, 0.009452058002352715, 0.0025368265341967344, 0.03262041136622429, -0.0742301493883133, -0.005803246516734362, -0.056576259434223175, -0.02280336432158947, 0.008296191692352295, 0.01163826510310173, 0.0011318264296278358, -0.025286497548222542, -0.03130033612251282, 0.07395897060632706, -0.017280230298638344, -0.02908649481832981, -0.014327457174658775, -0.03439950570464134, 0.05659032240509987, 0.06603216379880905, -0.008156055584549904, 0.010479524731636047, -0.04394075274467468, 0.018634961917996407, -0.005757354199886322, -0.014058014377951622, -0.03279983997344971, 0.0440433993935585, -0.02612713910639286, -0.002861020155251026, -0.01459462009370327, 0.08609199523925781, -0.003435881808400154, -0.06549840420484543, -0.05116751417517662, -0.019242575392127037, 0.012613458558917046, -0.033148545771837234, 0.034664034843444824, -0.004773032385855913, -0.03138749301433563, -0.01713840663433075, 0.03320806473493576, -0.02883714810013771, -0.002333809155970812, 0.029548974707722664, 0.004820909816771746, 0.046419695019721985, -0.026175538077950478, 0.06039389222860336, -0.043135836720466614, -0.008052880875766277, 0.008098568767309189, -0.33217599987983704, -0.06420712172985077, 0.01688339188694954, 0.010833044536411762, 0.016658928245306015, -0.05483274906873703, 0.05450749397277832, 0.002863857429474592, 0.08652345836162567, 0.08965195715427399, -0.028248820453882217, -0.042070433497428894, -0.05063255876302719, -0.005158791318535805, 0.021692590788006783, 0.06058641895651817, 0.036716632544994354, 0.018402181565761566, -0.03766103461384773, 0.026643918827176094, 0.0065031577832996845, -0.001265679020434618, -0.005187514238059521, -0.061020635068416595, 0.017887113615870476, 0.02188989333808422, 0.07769698649644852, -0.004614184144884348, -0.0013753672828897834, -0.024480760097503662, 0.005092327948659658, 0.03678801283240318, -0.01725347526371479, -0.04119196534156799, 0.03655458241701126, -0.027171239256858826, 0.019836550578475, 0.028399214148521423, -0.01715249940752983, 0.0222586989402771, 0.017561038956046104, 0.002806941047310829, -0.001580459182150662, -0.0800459086894989, -0.05604436993598938, -0.036863747984170914, -0.013041033409535885, 0.008210321888327599, -0.02844405174255371, 0.008239800110459328, -0.02414756268262863, 0.04456896334886551, 0.0486992672085762, 0.006591551937162876, -0.03719814866781235, -0.010561040602624416, -0.07729904353618622, 0.02429577335715294, -0.05973215401172638, -0.06008370965719223, 0.04925020411610603, -0.06019832193851471, 0.05695750191807747, -0.070182204246521, 0.0009810165502130985, -0.020888134837150574, -0.00881973747164011, -0.02898884005844593, 0.008751952089369297, 0.04092087224125862, -0.046077921986579895, 0.13500477373600006, 0.01601972058415413, 0.012581904418766499, 0.06872797757387161, 0.01664716936647892, -0.011824589222669601, -0.09365931153297424, -0.05726690962910652, 0.02068302407860756, 0.09014550596475601, 0.05837642773985863, 0.04078700393438339, 0.014288809150457382, 0.06799786537885666, 0.020412269979715347, 0.0817742571234703, -0.0048324246890842915, 0.03878971189260483, 0.08978456258773804, 0.011341871693730354, -0.04756351187825203, -0.019697390496730804, -0.02353266440331936, -0.015352451242506504, 0.004346256144344807, -0.2430027574300766, -0.019275715574622154, 0.027103649452328682, 0.07336734980344772, 0.008920340798795223, -0.02671412192285061, 0.002050223061814904, -0.07840723544359207, 0.03076166845858097, -0.03103586845099926, -0.019678618758916855, 0.055808693170547485, 0.0626615434885025, -0.016766425222158432, -0.05573369190096855, 0.0026459642685949802, 0.028376450762152672, 0.013036802411079407, 0.07157561182975769, 0.002067091641947627, -0.009890887886285782, -0.018198104575276375, 0.1447961926460266, -0.06071196496486664, -0.02747114934027195, -0.006841539405286312, 0.02502347342669964, -0.07497796416282654, 0.0016727581387385726, 0.02335892617702484, -0.019361762329936028, -0.011230768635869026, 0.08005554229021072, 0.015834519639611244, -0.04193364083766937, 0.056638944894075394, -0.05657358840107918, 0.010998979210853577, 0.024218302220106125, -0.01834999956190586, 0.016706224530935287, 0.07043937593698502, -0.044701479375362396, -0.038794998079538345, 0.0017333849100396037, 0.027815664187073708, 0.0907759815454483, -0.049908597022295, -0.018415464088320732, 0.013906463049352169, -0.024323005229234695, -0.0212197657674551, -0.010561229661107063, 0.012916532345116138, 0.035733725875616074, 0.015079469420015812, 0.0009557366720400751, 0.017325984314084053, -0.029241425916552544, -0.024090060964226723, 6.435821705963463e-05, -0.04716528207063675, 0.037715762853622437, 0.0354723185300827, -0.030239326879382133], metadata={'page_label': '5', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='982998a3-2ec9-4ee1-9358-bcd78bc323c8', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '5', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='fc24f703893ef70a6af8ed0fb46f4c8d07560eeccd3074996e17fb81996d9736')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Figure 2: Sample distribution for the resulting datasets in English and Spanish\\nRegarding the execution of experiments, four schemes were deﬁned in combination with the datasets and the different\\nmodels. Initially, a baseline was established, training and validating the four classical ML models listed in subsection\\n3.2, using the dataset in Spanish (ﬁrst scheme). For classical ML approaches, the texts were represented using BoW\\nand tf-idf techniques; this step was carried out to have a reference point for comparison purposes with the DL-based\\narchitectures. The subsequent experiments combine different DL models with different word embedding representations\\n(presented in sub-section 3.2), varying the datasets used for training and validation. The second scheme uses the\\ndataset in Spanish both to train and validate two vanilla DL architectures based on LSTM and CNN layers, and more\\nsophisticated architectures built on top of BERT-type models. Concerning the experiments with BETO embedding, we\\ntried with different values for the number of epochs, and also applied the early stopping strategy considering different\\nvalues of the hyperparameters tolerance and patience. For its part, the third scheme is similar to the former one but\\nusing the dataset in English instead, so in this case no experiments were performed using the pre-trained BETO model.\\nThe last scheme trains the models with the dataset in English and validates with the translated dataset (fourth scheme).\\nMoreover, we conducted some experiments where samples from the translated dataset were progressively mixed with\\nthe dataset in English during the training phase; then, the remaining portion of the translated dataset was used for\\nvalidation, i.e., emulating a learning curve.\\nThe following is the collection of hyperparameter values we considered when training and validating the different\\nmodels. Regarding the ML models for the baseline:\\n• (SVM) RBF and Linear Kernel; regularization parameter ’C’: 1e3, 1e-3; kernel coefﬁcient for RBF ’gamma’:\\n0.1, 1\\n• (RF and GBT) number of trees: 50, 100, 200, 300, 500; maximum number of features: 50, 100, 200, 300\\n• (MLP) hidden layers: 1, 2, 3; number of neurons per hidden layer: 10, 50; epochs: 1000, 1500\\nFurthermore, the combinations of these models were evaluated with BoW and tf-idf representations; removing and not\\nremoving Stop Words; applying and not applying Stemming; and considering a maximum vocabulary size of 10000,\\n20000, 30000 and 40000 words.\\nSimilarly, for the DL models evaluated we considered:\\n• LSTM: units present in hidden layers (Units) [this model was only implemented with a single hidden layer],\\nkernel regularizer (KR), recurrent regularizer(RR), dropout (D).\\n• CNN: amount of ﬁlters (F), kernel size (KS), number of units for additional dense layer (Units), kernel\\nregularizer (KR).\\nIt is also worth pointing out that, in order to set the input length for the models, we used a histograms-based approach to\\ndetermine the most common length (in words) of the news items, in both the datasets for English and Spanish news:\\n1500 and 500 words, respectively.\\n5', mimetype='text/plain', start_char_idx=0, end_char_idx=3113, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       "  TextNode(id_='a6e03e5f-90b9-4634-8c3f-228020d9629e', embedding=[-0.0021575025748461485, 0.03400994837284088, -0.021752767264842987, 0.03283855319023132, 0.08089907467365265, -0.014269419014453888, -0.037323806434869766, 0.026964236050844193, 0.05010342597961426, -0.009335502982139587, 0.03157826140522957, -0.024754660204052925, -0.006321941502392292, 0.03923429921269417, 0.04175998270511627, 0.023434406146407127, 0.0008970253984443843, -0.04370392858982086, -0.01577679067850113, -0.030171331018209457, 0.027218615636229515, -0.022689297795295715, 0.033330000936985016, -0.008379295468330383, 0.013166419230401516, 0.004327274393290281, -0.012168953195214272, -0.005519374273717403, -0.014251897111535072, -0.2333156019449234, 0.011122995056211948, -0.04157423600554466, 0.07832995057106018, 0.0005421628011390567, -0.013560413382947445, 0.036790698766708374, -0.049867287278175354, -0.03897571936249733, -0.06571966409683228, -0.0035923791583627462, -0.009479263797402382, -0.008391683921217918, -0.0002929996990133077, -0.023937206715345383, 0.03953666612505913, -0.04934263229370117, -0.0325334407389164, -0.008859489113092422, -0.050009164959192276, 0.03706660866737366, -0.030294125899672508, -0.038186248391866684, 0.019880102947354317, 0.049437329173088074, 0.0203853789716959, 0.023879975080490112, 0.054208721965551376, 0.016315972432494164, 0.01205881405621767, 0.056771766394376755, 0.010842401534318924, 0.06610793620347977, -0.14376114308834076, 0.010549724102020264, -0.04854947328567505, 0.03671443462371826, -0.024967025965452194, -0.0010829525999724865, -0.022886376827955246, 0.06434232741594315, -0.011746148578822613, 0.013117819093167782, 0.030784666538238525, 0.017556436359882355, 0.00869134534150362, 0.047275252640247345, 0.013213465921580791, 0.007688692770898342, 0.027020176872611046, -0.030477896332740784, 0.03960094973444939, 0.03589186817407608, 0.026640672236680984, -0.041727215051651, 0.02525702305138111, -0.038025226444005966, -0.017355967313051224, -0.009104298427700996, -0.04029698669910431, -0.019888602197170258, -0.014820124953985214, -0.03160778433084488, -0.010681861080229282, 0.023885196074843407, -0.05320559814572334, -0.039433348923921585, 0.00615908857434988, 0.0014830096624791622, 0.011599709279835224, 0.3954072892665863, 0.017568431794643402, -0.03530551493167877, 0.006797109730541706, -0.053090471774339676, 0.0032169546466320753, -0.014814072288572788, -0.015813009813427925, 0.0034839247819036245, -0.00760238291695714, 0.015048610046505928, -0.0596555657684803, -0.06103161722421646, 0.04880403354763985, 0.0188140831887722, -0.014845812693238258, -0.008052561432123184, 0.09213445335626602, 0.029589012265205383, -0.012869905680418015, 0.007147106342017651, -0.031959958374500275, -0.0015680083306506276, 0.03213478997349739, -0.04550158232450485, 0.03640632703900337, 0.030459467321634293, 0.056299660354852676, 0.07584184408187866, 0.07586180418729782, 0.030453825369477272, 0.022780101746320724, 0.014069421216845512, -0.022522108629345894, 0.03464282304048538, 0.00912980642169714, 0.04203309491276741, -0.008614677004516125, 0.02521497756242752, -0.04746829345822334, -0.01777714677155018, -0.022599229589104652, 0.01946876384317875, 0.04602542519569397, 0.0019306321628391743, -0.12965068221092224, 0.10471352934837341, -0.07156600058078766, -0.027794936671853065, -0.053544994443655014, -0.02243305929005146, -0.0011108595645055175, 0.07802857458591461, 0.026000656187534332, -0.043406836688518524, -0.006879766937345266, 0.014756961725652218, 0.03375117480754852, -0.022886676713824272, -0.06412392854690552, -0.025927167385816574, 0.0040387655608356, -0.016042213886976242, -0.003526564221829176, 0.09184342622756958, -0.00593212665989995, -0.051264580339193344, -0.019670356065034866, -0.008055991493165493, -0.009404626674950123, -0.03262441232800484, 0.05795910581946373, -0.01332132425159216, 0.0053603448905050755, 0.00782026257365942, -0.06083063408732414, 0.00724896602332592, -0.05136039853096008, 0.005279012955725193, 0.011381331831216812, -0.0005725586670450866, 0.030885258689522743, -0.033729955554008484, -0.03572434186935425, 0.045186806470155716, -0.021839788183569908, -0.010458255186676979, -0.018445197492837906, -0.04965194687247276, 0.05212116241455078, 0.027548033744096756, -0.013075703755021095, -0.004762561060488224, -0.04763941094279289, 0.011287124827504158, -0.0035756679717451334, 0.005801363382488489, -0.007298003416508436, 0.006186615210026503, -0.02235603891313076, -0.016803117468953133, -0.000639173376839608, 0.07192563265562057, -0.02503696084022522, -0.04543863609433174, -0.021678315475583076, -0.03098023310303688, -0.0014837918570265174, -0.03225734084844589, 0.03125327080488205, 0.001713080215267837, -0.029357902705669403, -0.0292661190032959, 0.024036068469285965, -0.033509690314531326, -0.007905671373009682, -0.017831239849328995, 0.0027300964575260878, 0.0679977610707283, -0.011777195148169994, 0.08044054359197617, -0.02880890481173992, -0.01363039668649435, -0.03209478035569191, -0.3365994989871979, -0.08279949426651001, 0.03446369245648384, 0.025499414652585983, 0.033883821219205856, -0.06699828058481216, 0.03792764991521835, -0.009509602561593056, 0.09082622826099396, 0.0565723292529583, -0.02819359116256237, -0.022057566791772842, -0.06884787976741791, -0.026953669264912605, 0.012741304002702236, 0.057087305933237076, 0.059425920248031616, 0.03545215353369713, -0.03969907760620117, 0.012415314093232155, 0.03438320383429527, 0.008412295021116734, 0.022145269438624382, -0.03968698903918266, -0.008216770365834236, -0.010512652806937695, 0.07314563542604446, 0.03825309872627258, 0.013870823197066784, -0.019690584391355515, -0.01464507170021534, 0.018316132947802544, -0.011784745380282402, -0.04059981554746628, 0.04811454936861992, -0.02817811630666256, 0.012701446190476418, 0.015682362020015717, -0.010996241122484207, 0.04097430780529976, 0.015561685897409916, -0.013739760965108871, 0.006794685963541269, -0.10190553218126297, -0.07784496247768402, -0.045782968401908875, -0.0067244479432702065, -0.04133982956409454, -0.032331787049770355, 0.01029153447598219, -0.002058465965092182, 0.03542308509349823, 0.06212155893445015, 0.0006934960838407278, -0.02264697104692459, -0.033795103430747986, -0.09630467742681503, -0.0045029884204268456, -0.06572932749986649, -0.04000671207904816, 0.05175968259572983, -0.05108826234936714, 0.02473379485309124, -0.05880993232131004, 0.024136949330568314, 0.009844383224844933, -0.020574238151311874, 0.008781894110143185, 0.019593317061662674, 0.04917049780488014, -0.05819765478372574, 0.1394582986831665, 0.038004614412784576, 0.0264402125030756, 0.076448954641819, 0.001559107331559062, -0.020697226747870445, -0.06593643873929977, -0.05451266095042229, 0.04019569978117943, 0.08851611614227295, 0.08035100996494293, 0.06441173702478409, 0.0016268001636490226, 0.03012530691921711, 0.04223797842860222, 0.06616561114788055, -0.019724365323781967, 0.01624234765768051, 0.07471292465925217, 0.0023306128568947315, -0.036980997771024704, 0.012666143476963043, -0.05662325769662857, 0.013869158923625946, 0.007284496445208788, -0.25620195269584656, 0.007821816019713879, 0.025434695184230804, 0.03565271943807602, 0.008952678181231022, -0.024313518777489662, 0.019535239785909653, -0.07383322715759277, 0.029076285660266876, -0.007460902910679579, -0.026392366737127304, 0.06160687282681465, 0.07566753774881363, -0.022096805274486542, -0.029136240482330322, -0.01339225098490715, 0.031230101361870766, -0.002448795363306999, 0.057953786104917526, 0.0025198364164680243, -0.006842845119535923, -0.02400466427206993, 0.14942395687103271, -0.04214441776275635, -0.04977375641465187, -0.01885935477912426, 0.029496438801288605, -0.07107566297054291, -0.007687611039727926, -0.0006759935058653355, 0.010058042593300343, -0.02914181910455227, 0.07441538572311401, 0.03339666128158569, -0.052167899906635284, 0.05423635616898537, -0.01800711080431938, 0.011603389866650105, 0.021585632115602493, -0.027310319244861603, 0.026295606046915054, 0.07000470906496048, -0.034796737134456635, -0.05547727271914482, 0.013567178510129452, -0.022070568054914474, 0.10489670932292938, -0.03421517461538315, -0.006837490014731884, -0.013754494488239288, -0.016977814957499504, -0.004087331239134073, -0.0258820578455925, -0.0013812532415613532, 0.0306770708411932, 0.01295829750597477, -0.01001136377453804, 0.002527642995119095, -0.004948655609041452, -0.049857109785079956, -0.014159364625811577, -0.030546534806489944, 0.04835401847958565, 0.09255435317754745, -0.010945649817585945], metadata={'page_label': '6', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='3ab62d6b-fff4-42d2-b6cf-c6a66012bec3', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '6', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='c11dbe766b605dbe782c443824743f71236063dfddbed5ee59b530a29feeef6d')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='The source code used to carry out the experiments can be found in a publicly accessible repository at GitHub 3.\\n4.3 Results\\nTable 1 shows the best results for each of the models considered during the experiments of the ﬁrst scheme, which\\nwas described in subsection 4.2. It also shows the conﬁguration of pre-processing steps that achieved the best results.\\nMoreover, the hyperparameter values selected for each model were the following:\\n• (SVM) kernel RBF; ’C’: 1e3; kernel coefﬁcient ’gamma’: 1\\n• (RF and GBT) number of trees: 500; maximum number of features: 50\\n• (MLP) hidden layers: 1; neurons: 10; epochs: 1500\\nTable 1: Baseline results for the dataset in Spanish\\nModel Vocab Size Stemming Remove StopWords Text Representation test_acc\\nSVM 10000 NO YES tf-idf 0.798\\nRF 40000 NO YES tf-idf 0.802\\nGBT 40000 YES NO BoW 0.783\\nMLP 10000 YES NO tf-idf 0.794\\nAccording to the baseline results, RF in combination with a tf-idf text representation showed the highest accuracy.\\nSubsequently, we performed the experiments with the DL models (LSTM, CNN) in combination with the different types\\nof Word Embeddings; hence, we followed the second, third, and fourth schemes. From this point on, we permanently\\nremoved Stop Words and did not apply Stemming anymore regarding data pre-processing.\\nInitially, we ran some experiments using a trainable embedding layer; the results are summarized in Table 2, where the\\nhyperparameter values selected for each model were:\\n• LSTM (Spanish) 16 units; KR and KK equals 1; D equals 0\\n• LSTM (English) 4 units; KR and KK equals 0.01; D equals 0\\n• CNN (Spanish) F equals 16; KS equals 10; 4 units; KR equals 0.01\\n• CNN (English) F equals 16; KS equals 10; 12 units; KR equals 0\\nThe LSTM and CNN models trained with the English dataset, whose results are shown in Table 2, were also validated\\nwith the whole translated dataset, yielding accuracies of 56.7% and 53.2% respectively.\\nTable 2: Results for DL models with trainable embedding layer; the column dev_acc shows the accuracy in the\\ndevelopment set; std is the standard deviation, and test_acc shows the accuracy in the test set.\\nModel Dataset Language dev_acc std test_acc\\nLSTM Spanish 0.714 0.026 0.761\\nLSTM English 0.95 0.02 0.931\\nCNN Spanish 0.73 0.021 0.685\\nCNN English 0.984 0.002 0.982\\nNext, we performed the experiments using a Transfer Learning approach, with the pre-trained 300-feature GloVe\\nembedding layer presented in subsection 3.2; this time, the embedding values were left ﬁxed during the training process,\\nand only the added hidden layers were ﬁne-tuned. Since the GloVe vectors utilized were trained on a corpus in English,\\nthese experiments correspond to the third and fourth schemes. The results are summarized in Table 3; moreover, the\\nhyperparameter values chosen for each model were the following:\\n• (LSTM) 8 units; KR and KK equals 0; D equals 0.5\\n• (CNN) F equals 16; KS equals 10; 4 units; KR equals 0\\nThen, when validating the former models using the translated dataset (fourth scheme), we got accuracy values of 54%\\nand 53.8% for LSTM and CNN layers, respectively.\\n3https://github.com/kevinmaiden7/Spanish_FakeNewsDetection\\n6', mimetype='text/plain', start_char_idx=0, end_char_idx=3138, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       "  TextNode(id_='b5286c1f-2a1c-43bb-84e6-6633df2e3a74', embedding=[-0.011591394431889057, -0.004727633204311132, 0.010818921029567719, 0.03215319290757179, 0.09583412855863571, 0.04671469330787659, -0.030721185728907585, -0.001147885574027896, 0.013614431954920292, 0.004482404328882694, 0.02867942303419113, -0.046778541058301926, 0.02734566666185856, 0.012742157094180584, 0.033360179513692856, -0.025316106155514717, -0.02057410031557083, -0.029839450493454933, -0.05089579150080681, -0.03055293671786785, 0.039266716688871384, -0.04672561213374138, 0.0024548762012273073, -0.037957314401865005, 0.003893373068422079, -0.001493158983066678, 0.013156476430594921, -0.036410920321941376, -0.013645928353071213, -0.2529258728027344, -0.01591705158352852, -0.042638421058654785, 0.04850063472986221, 0.010073497891426086, -0.027574323117733, 0.01159213948994875, -0.011951509863138199, -0.029716458171606064, -0.026089200749993324, -0.007828258909285069, -0.01552470214664936, 0.0389973446726799, -0.018701044842600822, -0.04341254010796547, 0.0717143639922142, -0.025482969358563423, -0.03938767686486244, 0.025112904608249664, -0.035254720598459244, 0.01702115312218666, 0.013170648366212845, -0.025044497102499008, -0.024915294721722603, 0.034913863986730576, 0.04271171614527702, 0.031775932759046555, -0.0007394058629870415, 0.0472615584731102, -0.007207697723060846, 0.06862158328294754, 0.006760491989552975, 0.06696401536464691, -0.11475573480129242, 0.04058289900422096, -0.05097663775086403, 0.010397973470389843, -0.009624161757528782, -0.014930284582078457, -0.013072974979877472, 0.038285184651613235, 0.017694013193249702, -0.026916658505797386, 0.02726503275334835, 0.0338590145111084, 0.0156363807618618, 0.06656897813081741, 0.019173787906765938, -0.0034375882241874933, 0.023032579571008682, -0.0438302718102932, -0.0011360222706571221, 0.025819992646574974, 0.019590260460972786, -0.02342665009200573, -0.00910175684839487, -0.06423436105251312, 0.02855381742119789, -0.011771994642913342, -0.032025571912527084, 0.02768442966043949, -0.03257892280817032, 0.01844608038663864, -0.041716236621141434, 0.008100206963717937, -0.037074655294418335, -0.03095776028931141, 0.02234823815524578, 0.02058720961213112, -0.05630089342594147, 0.3711452782154083, -0.014605189673602581, -0.019845962524414062, -0.0034777557011693716, -0.006106667220592499, 0.0037363464944064617, -0.045486170798540115, 0.03139306232333183, -0.029942508786916733, -0.05991256982088089, 0.021008003503084183, -0.03773113712668419, -0.033755071461200714, 2.8604214094229974e-05, -0.013440095819532871, -0.000934786454308778, 0.02209261991083622, 0.050464924424886703, 0.032478924840688705, 0.016294635832309723, -0.004650643561035395, -0.022840291261672974, 0.0050621312111616135, 0.011701097711920738, -0.02907707542181015, 0.0009234179742634296, 0.021350575610995293, 0.048703309148550034, 0.08820979297161102, 0.09761939942836761, 0.01456635631620884, -0.011828092858195305, -0.01165257953107357, -0.08894066512584686, 0.024484440684318542, -0.010735280811786652, 0.06158364936709404, -0.00779425073415041, 0.03398902714252472, -0.025372248142957687, 0.026321550831198692, -0.006768291350454092, 0.012244878336787224, 0.07253468036651611, -0.0025998775381594896, -0.0773574635386467, 0.10937872529029846, -0.07355401664972305, -0.007844934239983559, -0.00972011499106884, -0.011229230090975761, 0.061366498470306396, 0.08813449740409851, -0.0034321474377065897, -0.03967157006263733, 0.002196597633883357, -0.003911485429853201, 0.04884713143110275, 0.007691784296184778, -0.06409937888383865, -0.026972364634275436, -0.02108079008758068, -0.05594949424266815, -0.005978711880743504, 0.07253330200910568, -0.033813610672950745, -0.056582190096378326, -0.029197704046964645, -0.0009890540968626738, 0.03526506572961807, -0.026316994801163673, 0.09636086970567703, 0.03378290310502052, -0.008536639623343945, 0.0001306068734265864, -0.05299777165055275, 0.0263639185577631, -0.041133392602205276, -0.0746273547410965, -0.013532032258808613, 0.02931341715157032, 0.01683155819773674, -0.04925880208611488, -0.023817498236894608, 0.05049265921115875, -0.03678543120622635, -0.030503269284963608, -0.017038796097040176, -0.03369658440351486, 0.06330312043428421, 0.04270556941628456, 0.003246824024245143, 0.01961774192750454, -0.061777401715517044, 0.053953059017658234, 0.014445257373154163, -0.013455127365887165, -0.01201382651925087, 0.03594065457582474, -0.012805287726223469, -0.0362568236887455, -0.02135632000863552, 0.05738035589456558, -0.02490922063589096, -0.06932900100946426, -0.033635251224040985, -0.006472798530012369, -0.038043033331632614, -0.03918778523802757, 0.024490416049957275, 0.054192714393138885, -0.05690415948629379, -0.011564892716705799, -0.008310248143970966, -0.038951337337493896, 0.011210791766643524, 0.030033212155103683, 0.037934064865112305, 0.051830779761075974, -0.027439113706350327, 0.04731237143278122, -0.08490090072154999, -0.0012330099707469344, -0.0038936780765652657, -0.34838777780532837, -0.04972800984978676, 0.02227560058236122, -0.004820587579160929, 0.011525885201990604, -0.08538010716438293, 0.027126453816890717, 0.014248557388782501, 0.09473900496959686, 0.027816995978355408, -0.0023580731358379126, 0.002367971930652857, -0.046680551022291183, -0.03134741261601448, 0.03669830411672592, 0.040568869560956955, 0.04834558442234993, -0.028861835598945618, -0.02255835197865963, 0.023903455585241318, -0.04178152605891228, 0.013748819939792156, 0.015234299935400486, -0.03323918208479881, 0.006601748056709766, 0.011675465852022171, 0.08546105772256851, -0.0024054942186921835, 0.015143792144954205, -0.04754244536161423, -0.014047696255147457, 0.03908814862370491, -0.016029514372348785, -0.02891542762517929, 0.040931105613708496, -0.030519355088472366, 0.06846195459365845, 0.01148343924432993, 0.005867100320756435, 0.010682148858904839, -0.03760037571191788, -0.009717575274407864, 0.03757163882255554, -0.11470018327236176, -0.06584692746400833, -0.044231921434402466, 0.008350972086191177, 0.008677389472723007, -0.057960279285907745, -0.006739687640219927, 0.01859309896826744, -0.009857654571533203, 0.05805660039186478, 0.00043637765338644385, -0.028617050498723984, 0.0028078004252165556, -0.08376532793045044, 0.012272346764802933, -0.025768399238586426, 0.01632770150899887, 0.006199761293828487, -0.05122070759534836, 0.06244882941246033, -0.07607428729534149, -0.006941968575119972, -0.014822146855294704, -0.016210759058594704, -0.0127782067283988, 0.015395503491163254, 0.005239809863269329, -0.0155220041051507, 0.1137005016207695, 0.002994721522554755, 0.004752450156956911, 0.058143388479948044, 0.006599085405468941, 0.019663475453853607, -0.049456458538770676, -0.06327131390571594, 0.02321062609553337, 0.09591694176197052, 0.05483127012848854, 0.052023932337760925, -0.03143203631043434, 0.0466032512485981, 0.021257400512695312, 0.0671713575720787, -0.0067084915935993195, 0.006369166541844606, 0.06851699203252792, 0.00646861270070076, -0.03907831385731697, -0.0063524129800498486, -0.0446942038834095, 0.008130049332976341, -0.014733579941093922, -0.2775322198867798, 0.02145380526781082, 0.03891441971063614, 0.047781940549612045, -0.0210337582975626, -0.04107058793306351, 0.023236136883497238, -0.08658158034086227, 0.037786923348903656, -0.024226311594247818, 0.001197453704662621, 0.0777895599603653, 0.08296356350183487, 0.003182855201885104, -0.00522227818146348, -0.00647242134436965, 0.029084734618663788, 0.014154438860714436, 0.0637354701757431, 0.011616618372499943, -0.006347832269966602, 0.004748043138533831, 0.16982875764369965, -0.03808639571070671, -0.03222446143627167, 0.013866138644516468, 0.009812993928790092, -0.07334621995687485, 0.012097790837287903, 0.005019846837967634, -0.0030510942451655865, -0.01481544692069292, 0.04410291090607643, 0.04333799332380295, -0.032562289386987686, 0.07403753697872162, -0.057578280568122864, 0.02934429422020912, 0.02150852046906948, 0.019766204059123993, 0.058036185801029205, 0.02469867281615734, -0.015909604728221893, -0.036087583750486374, 0.02028478868305683, 0.03087003342807293, 0.09733867645263672, -0.0028902289923280478, -0.03791741654276848, -0.020487040281295776, -0.013105287216603756, -0.015347231179475784, -0.0016144359251484275, -0.0013818030711263418, 0.01832735165953636, 0.04171648994088173, 0.016036396846175194, 0.009932161308825016, -0.008369429968297482, -0.02026909962296486, 0.001332949846982956, -0.07402235269546509, 0.008089401759207249, 0.009733268991112709, 0.039539746940135956], metadata={'page_label': '7', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='7ea003dc-9156-4d7a-8e01-5b0f44258668', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '7', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='8e91bb0d125b651448374d14e4a1c7ec0e3632c89356b752cbb1680cb23dae1b')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Table 3: Results for DL models using GloVe embedding with the dataset in English. The column dev_acc shows the\\naccuracy in the development set; std is the standard deviation, and test_acc shows the accuracy in the test set.\\nModel dev_acc std test_acc\\nLSTM 0.962 0.006 0.924\\nCNN 0.974 0.002 0.973\\nAt this point, we decided to implement a learning curve in order to evaluate the effect of including data from the\\ntranslated dataset, into a training dataset composed of the original news in English. The models evaluated included\\nLSTM and CNN layers as well as trainable Embeddings and GloVe. Five experiments were run for each case, adding\\n500, 1000, 1500, 2000 and 2500 samples from the translated dataset to the training set, and then validating with the total\\namount of remaining samples of the translated dataset. Figure 3 shows the results for the CNN model with trainable\\nEmbedding, which was the best combination found in terms of accuracy, when applying this strategy.\\nFigure 3: Learning curve results for CNN with trainable embedding\\nBased on the previous results obtained with GloVe, and to simplify the experimental phase, the best hyperparameters of\\nLSTM and CNN layers found using this embedding, were left ﬁxed for the subsequent experiments applying ELMo and\\nBERT-type embeddings.\\nTable 4: Results for ELMo, BERT and BETO Embeddings\\nEmbedding Model scheme Epochs test_acc\\nELMo LSTM Third 7 0.973\\nELMo CNN Third 5 0.957\\nELMo CNN Fourth 7 0.525\\nBERT CNN Third 7 0.957\\nBERT CNN Fourth 7 0.53\\nBETO LSTM Second 25 0.80\\nRegarding the results with ELMo embedding, we got high accuracy outcomes for both LSTM and CNN models\\nconcerning the third scheme, as it is shown in Table 4; however, when it comes to the fourth scheme, the results show a\\ndegradation in performance. Additionally, taking into account the trend identiﬁed in the aforementioned learning curve\\napproach, we added 2500 samples from the translated dataset to the training set, ﬁtted the CNN layer in combination\\nwith ELMo embedding on this set, and validated with the remaining 71 samples of the translated dataset: we reached an\\naccuracy value of 70%.\\nFor the models built on top of BERT embedding, experiments were only carried out with the CNN layers; with this in\\nmind, as it is described in Table 4, we obtained a high accuracy result for the third scheme again, whereas not such a\\ngood level was achieved for the fourth scheme. Similarly to the procedure followed with ELMo embedding, 2500\\nsamples were added from the translated dataset to the training set, for then validating with the remaining 71 samples: in\\nthis case we got an accuracy level of 63.4%.\\n7', mimetype='text/plain', start_char_idx=0, end_char_idx=2636, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       "  TextNode(id_='5bdf2d2e-034e-458b-96ee-7125ea904575', embedding=[-0.018919698894023895, 0.03798602148890495, -0.030629610642790794, 0.06249802187085152, 0.07659287005662918, 0.02651173807680607, -0.039376650005578995, 0.00017936511721927673, 0.02337174117565155, -0.005889780353754759, 0.011497888714075089, -0.06790509819984436, 0.016309771686792374, 0.02666015550494194, 0.0570082888007164, -0.004616599064320326, -0.010015707463026047, -0.06200649216771126, -0.008967953734099865, 0.01321205124258995, 0.02604483813047409, -0.013526754453778267, 0.03802762180566788, 0.008995424956083298, -0.022467736154794693, 0.004697383381426334, 0.007629318628460169, 0.014949748292565346, -0.03688383847475052, -0.24720387160778046, 0.009493368677794933, -0.03702915087342262, 0.04637856036424637, -0.004539416171610355, -0.031904447823762894, 0.043759774416685104, -0.0242146085947752, -0.040275704115629196, -0.01332081202417612, -0.018433066084980965, -0.0004785128403455019, 0.005430534016340971, -0.012782826088368893, -0.04546589031815529, 0.03363902121782303, -0.03583184629678726, -0.04953305423259735, 0.02986377291381359, -0.06672191619873047, 0.030224356800317764, -0.021791784092783928, -0.02144988812506199, 0.0007526981644332409, 0.0583806075155735, 0.012119593098759651, 0.04233560711145401, 0.004549333360046148, 0.022329866886138916, 8.760990021983162e-05, 0.06684910506010056, 0.013281860388815403, 0.046680424362421036, -0.1336735039949417, 0.034429360181093216, -0.06569352746009827, 0.02599145472049713, -0.027989860624074936, 0.007139057386666536, -0.035237718373537064, 0.062596894800663, -0.006901370361447334, -0.02230154536664486, 0.022823292762041092, 0.05279557406902313, 0.030924510210752487, 0.04562786966562271, 0.015607928857207298, 0.011602489277720451, -0.0005041107651777565, 0.0005968830664642155, 0.035531315952539444, 0.026445025578141212, 0.0438707135617733, -0.039475470781326294, 0.013663682155311108, -0.05544549599289894, -0.008393623866140842, -0.01899740844964981, -0.03964993357658386, -0.006247689947485924, -0.0040016453713178635, 0.008967305533587933, 0.01416563056409359, 0.037670839577913284, -0.012624254450201988, -0.031096385791897774, 0.024064593017101288, 0.017986958846449852, -0.030815036967396736, 0.37490105628967285, 0.002928116824477911, -0.01011728961020708, -0.006270748097449541, 0.003501943312585354, -9.608289110474288e-05, -0.03520069643855095, 0.0032872555311769247, 0.0008901382680051029, -0.007762367371469736, 0.017565421760082245, -0.05032164603471756, -0.04739593714475632, 0.04395236074924469, 0.004096279852092266, -0.0144342090934515, -0.03095575049519539, 0.07582629472017288, 0.051074784249067307, -0.026554806157946587, 0.018727360293269157, -0.032497137784957886, 0.002277785912156105, 0.015732882544398308, -0.012285372242331505, 0.02363038808107376, -0.0033133942633867264, 0.06798942387104034, 0.07370855659246445, 0.06575894355773926, 0.0059508937411010265, -0.0027979498263448477, 0.007458665873855352, -0.07113273441791534, -0.0009080127929337323, 0.02170541323721409, 0.055076535791158676, -0.029382670298218727, 0.002203211421146989, 0.0035095408093184233, -0.02158540114760399, 0.006092533934861422, 0.026373565196990967, 0.05641395226120949, 0.017520656809210777, -0.08435416221618652, 0.0870746374130249, -0.06567775458097458, -0.016844578087329865, -0.045812733471393585, -0.0034547990653663874, 0.005643424578011036, 0.060817886143922806, -0.00961050484329462, -0.003568237414583564, 0.011918087489902973, -0.012474076822400093, 0.030813181772828102, -0.019221791997551918, -0.07038132101297379, -0.054402176290750504, -0.028968775644898415, -0.048619456589221954, 0.003223637118935585, 0.04129607975482941, -0.03720956668257713, -0.03222810477018356, -0.051146071404218674, 0.0002713330904953182, 0.008840799331665039, -0.053902968764305115, 0.07129316031932831, 0.024458877742290497, 0.0007315021357499063, -0.030243821442127228, -0.07502716779708862, 0.021990763023495674, -0.06028329208493233, -0.030807238072156906, 0.009465319104492664, -0.004998344462364912, 0.011885980144143105, -0.03466390445828438, -0.03516661375761032, 0.06722737103700638, -0.027391334995627403, -0.05373872444033623, -0.015815002843737602, -0.04023464769124985, 0.038226086646318436, 0.0694022998213768, -0.0028756242245435715, -0.009796754457056522, -0.08599294722080231, 0.011886750347912312, -0.015740491449832916, -0.022899311035871506, -0.03748759627342224, 0.013378122821450233, -0.0034108844120055437, 0.0062766410410404205, -0.016183534637093544, 0.08345324546098709, -0.003921941388398409, -0.06201595440506935, -0.0442715585231781, -0.015131814405322075, 0.018462851643562317, -0.03769455850124359, 0.021510889753699303, 0.020572271198034286, -0.05442589893937111, -0.020490523427724838, 0.019650397822260857, -0.012978896498680115, 0.008797709830105305, 0.03691818192601204, 0.015563570894300938, 0.03626447170972824, -0.024509480223059654, 0.047070782631635666, -0.04244594648480415, -0.01964043639600277, 0.025902722030878067, -0.3320698142051697, -0.08114521950483322, -0.012950219213962555, 0.022242898121476173, 0.029729066416621208, -0.06915280222892761, 0.047550223767757416, 0.020267853513360023, 0.06826088577508926, 0.058714695274829865, -0.022542841732501984, -0.02919408492743969, -0.05715290457010269, -0.012564046308398247, 0.0014793508453294635, 0.05740952491760254, 0.06004507839679718, -0.007759908679872751, -0.02859468385577202, 0.020987646654248238, -0.02882322482764721, 0.0359305813908577, -0.0032201658468693495, -0.07172015309333801, 0.0333535261452198, 0.030239466577768326, 0.08733276277780533, 0.002231152728199959, 0.03850458562374115, -0.035970237106084824, 0.031168630346655846, 0.04254859313368797, -0.027253903448581696, -0.04025435447692871, 0.04516312852501869, -0.03931165114045143, 0.04464796930551529, 0.03140523284673691, -0.01580594666302204, 0.006706951651722193, 0.03793543949723244, -0.014865893870592117, 0.012081294320523739, -0.0906577780842781, -0.06740054488182068, -0.011548234149813652, -0.013163280673325062, 0.012324369512498379, -0.04960371181368828, 0.02815679833292961, -0.010010688565671444, 0.049752067774534225, 0.05744186416268349, 0.013781767338514328, -0.018024221062660217, -0.0030506502371281385, -0.09517425298690796, 0.011455598287284374, -0.07263415306806564, -0.03145168349146843, 0.048933256417512894, -0.032115716487169266, 0.06188017129898071, -0.0860263779759407, 0.00751985888928175, -0.044650543481111526, -0.006068839691579342, -0.046617038547992706, 0.02394423820078373, 0.0430976040661335, 0.0034557192120701075, 0.12903155386447906, -0.0018197096651419997, 0.019012965261936188, 0.08154591172933578, -0.008208030834794044, 9.640307689551264e-05, -0.0844528079032898, -0.04589255899190903, 0.04528476297855377, 0.10252609103918076, 0.06624870002269745, 0.046499911695718765, 0.01634148135781288, 0.061772383749485016, 0.03849678859114647, 0.09822991490364075, 0.010634895414113998, 0.012851361185312271, 0.09277494251728058, 0.030197912827134132, -0.02318449132144451, -0.010132131166756153, -0.03715520724654198, -0.02348625287413597, -0.02490457333624363, -0.26220938563346863, 0.014384613372385502, 0.01414476428180933, 0.06291406601667404, 0.0052114143036305904, -0.04226362332701683, 0.014936603605747223, -0.05435193330049515, 0.04004509374499321, -0.0019031629199162126, -0.027393938973546028, 0.08436554670333862, 0.060723766684532166, -0.02086574025452137, -0.06970246881246567, 0.009236335754394531, 0.008076788857579231, 0.003940389025956392, 0.06296033412218094, -0.0023683125618845224, -0.016731513664126396, -0.03262162581086159, 0.15377205610275269, -0.07094898819923401, -0.0395963191986084, 0.006005114875733852, 0.02729116752743721, -0.0739397183060646, -0.00011838802311103791, 0.023451142013072968, -0.024343648925423622, 0.019935522228479385, 0.062396880239248276, 0.011406157165765762, -0.04450083523988724, 0.0438409261405468, -0.0403655506670475, 0.021248674020171165, 0.01639389991760254, -0.020493896678090096, 0.008230246603488922, 0.041582100093364716, -0.06646455079317093, -0.022984592244029045, 0.011070752516388893, 0.016815494745969772, 0.10587320476770401, -0.014640606008470058, -0.017149101942777634, 0.0063996934331953526, -0.026382993906736374, -0.04808168485760689, -0.004238127265125513, 0.014677503146231174, 0.02371451072394848, 0.02452290616929531, -0.008926615118980408, 0.007603975012898445, -0.00621787691488862, 0.0006252772291190922, -0.0019958876073360443, -0.06123143061995506, 0.058401916176080704, 0.03540565073490143, -0.026946038007736206], metadata={'page_label': '8', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='9a54ae6c-8980-4ccb-9a05-9598fc2bbc00', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '8', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='2e1cfbf22b1c267fa93cef7359e9c931d84292c4d954f23e5e121bfa7facefc1')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Concerning BETO embedding, the experiments with this model were framed in the second scheme (training and\\nvalidating with the dataset in Spanish) since BETO itself is a model trained over a corpus in this language; in this case,\\nwe used both LSTM and CNN layers. Table 4 shows the results for this experiment, where it is possible to observe that\\nthe LSTM model trained with 25 epochs achieved results of up to 80% in accuracy for the test set; this is the best result\\nwe reached with DL models for the dataset in Spanish. Thus, Figure 4 shows the confusion matrix associated with this\\narchitecture for the test set; it is worth highlighting that we used the early stopping strategy, although it did not yield a\\nsigniﬁcant improvement in comparison to the previous results.\\nFigure 4: (BETO) normalized confusion matrix for LSTM with the dataset in Spanish\\n5 Discussion and Conclusions\\nRegarding the proposed baseline for datasets in Spanish (ﬁrst scheme), RF showed the best performance getting an\\naccuracy of 80%, and using the tf-idf text representation; however, this performance was not statistically different from\\nthat obtained with SVM, where a smaller vocabulary size was used. This model outperformed the best result reported in\\n[2], where The Spanish Fake News Corpusdataset was also utilized. Furthermore, we noticed that for this scheme, there\\nwere no signiﬁcant differences in the performance of the models when applying Stemming or removing StopWords, or\\neven when varying the text representation strategy or the vocabulary size.\\nIt is worth highlighting the gap between the number of samples in the resulting datasets for English and Spanish,\\nas it was shown in Figure 2. Since the models we used in this research follow a phenomenological approach, they\\nhighly depend on the amount of experimental data they are trained on. The above was evidenced by the prominent\\ndifference on accuracy we obtained in the third and fourth schemes, using GloVe, ELMo, and BERT embeddings.\\nAlso, concerning the second scheme, we noticed that the models exhibited a trend of overﬁtting due to the small\\nnumber of samples available for training; moreover, we observed that the regularization strategies we employed did not\\nsigniﬁcantly improve the performance.\\nIn regard to the fourth scheme, it is important to underline that the vocabulary present in the translated dataset\\ncorresponded to just 60% of that present in the dataset in English; this situation negatively affected the results we\\nobtained for the translation strategy. For this scheme, despite the excellent performance of the models trained and\\nvalidated with the dataset in English (third scheme), when we validated with the translated dataset, the values of\\naccuracy were drastically reduced. Consequently, the results of the implemented learning curve indicated a performance\\nimprovement (although in different ratios) as more samples were added from the translated dataset to the training\\nset (as it was shown in Figure 3); this pattern was noticed regardless of the combination between a model and the\\nembedding layer utilized.\\nConcerning the different embeddings we used, similar results were obtained for the third and fourth schemes when\\nusing GloVe, ELMo or BERT, in each of them; in fact, it is noteworthy that, in combination with these different\\nembeddings, the LSTM and CNN layers showed similar results. Furthermore, taking into account these pre-trained\\nmodels corresponded to the state-of-the-art in NLP, we were expecting to obtain salient results by mixing portions of\\nthe translated dataset to the dataset in English for training; however, due to the small number of samples available in the\\n8', mimetype='text/plain', start_char_idx=0, end_char_idx=3674, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       "  TextNode(id_='d96e97c5-4f22-4568-a69e-684534e20342', embedding=[-0.02286418341100216, 0.022313551977276802, -0.03939001262187958, 0.042606476694345474, 0.08597895503044128, 0.019357485696673393, -0.029446367174386978, 0.009726354852318764, 0.028229855000972748, 0.014418908394873142, 0.01023352425545454, -0.03424437716603279, -0.01726866327226162, -0.006010249722748995, 0.053528908640146255, 0.011268285103142262, 0.012933919206261635, -0.07812803983688354, -0.0027099838480353355, 0.01014716736972332, 0.061455026268959045, -0.016455359756946564, 0.026225656270980835, 0.020440515130758286, 0.006925604771822691, -0.007952822372317314, 0.00497507955878973, 0.0007809913950040936, -0.056092821061611176, -0.2440664917230606, -0.00962548702955246, -0.03233768045902252, 0.034154828637838364, -0.037219077348709106, -0.01997966878116131, 0.0014905337011441588, -0.014072173275053501, -0.057150378823280334, -0.021330663934350014, 0.014749753288924694, -0.01311609148979187, -0.0003795869997702539, -0.010900527238845825, -0.038277965039014816, 0.04225356876850128, -0.038301460444927216, -0.040712203830480576, 0.04570771008729935, -0.04512893408536911, 0.030254242941737175, -0.02336256206035614, 0.005197545979171991, -0.004689580760896206, 0.04148397594690323, 0.0018507373752072453, 0.04095769301056862, 0.012041237205266953, 0.005180612672120333, 0.015621311031281948, 0.08113381266593933, 0.023084033280611038, 0.07476592063903809, -0.1244698166847229, 0.012139718979597092, -0.08747051656246185, 0.023461654782295227, -0.01614866591989994, 0.027683118358254433, -0.046256519854068756, 0.051690421998500824, 0.006015695631504059, -0.041545141488313675, 0.04505210369825363, 0.032544925808906555, 0.04686901718378067, 0.050436537712812424, 0.009153214283287525, 0.006119974423199892, -0.024089999496936798, -0.01738574728369713, 0.02919730544090271, 0.03954431787133217, 0.05392767861485481, -0.0478813499212265, -0.018828051164746284, -0.04905570670962334, 0.012842969968914986, -0.00428479490801692, -0.04266486316919327, -0.010707288049161434, -0.011681444011628628, 0.010367675684392452, 0.0303953904658556, 0.03699476271867752, -0.031216192990541458, -0.012779070995748043, -0.0009293488692492247, 0.024177003651857376, -0.014455435797572136, 0.4067644774913788, 0.0003164007794111967, -0.017023399472236633, 0.009025175124406815, -0.017763826996088028, -0.012803154066205025, -0.023800821974873543, 0.016291964799165726, -0.003711661556735635, -0.002673567971214652, 0.015181096270680428, -0.07692807167768478, -0.03885915130376816, 0.04699809476733208, -0.010052475146949291, -0.020360758528113365, -0.013834112323820591, 0.06536318361759186, 0.05467722564935684, -0.03953895345330238, 0.001551843131892383, -0.03381470590829849, 0.003214580239728093, 0.05718417838215828, 0.003963594324886799, 0.01933569461107254, 0.017431888729333878, 0.060180071741342545, 0.07729242742061615, 0.06339018791913986, 0.04293319955468178, -0.016786865890026093, 0.008296924643218517, -0.04353680461645126, 0.006165334023535252, 0.002048318972811103, 0.04613805189728737, -0.049986373633146286, 0.009176217950880527, 0.01728862337768078, -0.007895844988524914, -0.008562800474464893, 0.023623710498213768, 0.05581805855035782, 0.02164672501385212, -0.11004243046045303, 0.06774957478046417, -0.057689767330884933, -0.004834395833313465, -0.06164243817329407, 0.007545932196080685, 0.00879846140742302, 0.08248662948608398, -0.017757700756192207, -0.007538867648690939, 0.0026510588359087706, -0.018545672297477722, 0.030758153647184372, -0.010641895234584808, -0.08318762481212616, -0.036217838525772095, -0.01028501894325018, -0.0621773935854435, 0.024531111121177673, 0.06312385201454163, -0.03809165954589844, -0.017099693417549133, -0.025619404390454292, 0.013227141462266445, 0.006710786372423172, -0.06747416406869888, 0.056359268724918365, 0.015278484672307968, -0.0034205999691039324, -0.01026296429336071, -0.04202263057231903, 0.01213013380765915, -0.04472029209136963, -0.017709385603666306, 0.006300534587353468, -0.008280345238745213, 0.011565830558538437, -0.036729540675878525, -0.0477399006485939, 0.07213261723518372, -0.013935445807874203, -0.03980415686964989, -0.007773830089718103, -0.03602995350956917, 0.05517101660370827, 0.07574883103370667, -0.004855508450418711, 0.020604677498340607, -0.0971919596195221, 0.03448398411273956, -0.021534742787480354, -0.037976015359163284, -0.044668786227703094, 0.01666937582194805, 0.002114653354510665, 0.014337794855237007, -0.004805448465049267, 0.04979732632637024, -0.027974726632237434, -0.05301344767212868, -0.07709744572639465, -0.04315214976668358, 0.02269095368683338, -0.04080905392765999, -0.01097860001027584, 0.007780815940350294, -0.043500933796167374, -0.009953698143362999, 0.030565982684493065, -0.022361112758517265, -0.004620930179953575, 0.0019019865430891514, 0.0184781514108181, 0.03134883940219879, -0.028919750824570656, 0.06933955103158951, -0.054192736744880676, -0.011568553745746613, 0.02794632688164711, -0.33210423588752747, -0.0745418444275856, 0.005283685401082039, 0.0063835494220256805, 0.029282521456480026, -0.06432951241731644, 0.04288820922374725, 0.01960734650492668, 0.1037808284163475, 0.09301997721195221, -0.002250519348308444, -0.027568595483899117, -0.06610517203807831, 0.02019614726305008, 0.007002187892794609, 0.04486754536628723, 0.029851537197828293, -0.01529629621654749, -0.04369034990668297, 0.02183498814702034, -0.031229836866259575, 0.04560908302664757, -0.022028636187314987, -0.04859476163983345, 0.021963994950056076, 0.0021272459998726845, 0.07878715544939041, 0.005960741546005011, 0.005190664436668158, -0.011927726678550243, 0.016288822516798973, 0.031078016385436058, -0.010651027783751488, -0.04821838438510895, 0.03619663417339325, -0.020676327869296074, 0.035186611115932465, 0.011702767573297024, 0.008738582022488117, 0.034757014364004135, 0.026776887476444244, -0.025083398446440697, 0.012087414041161537, -0.08815604448318481, -0.045548126101493835, -0.006649843417108059, -0.018703142181038857, 0.021903302520513535, -0.0501234233379364, 0.05847514420747757, -0.021184256300330162, 0.05458109453320503, 0.05087815970182419, 0.033179108053445816, -0.03911462798714638, -0.022522076964378357, -0.07618442922830582, 0.0025384759064763784, -0.07989180833101273, -0.023951401934027672, 0.0231341365724802, -0.03250053524971008, 0.04337099567055702, -0.08936598896980286, -0.0018506246851757169, -0.03385256230831146, -0.013584361411631107, -0.028132392093539238, 0.02855498157441616, 0.05793239548802376, 0.011040041223168373, 0.13311296701431274, 0.03625933825969696, 0.023523714393377304, 0.08057797700166702, 0.007134932093322277, -0.014059550128877163, -0.08923853188753128, -0.044813815504312515, 0.020456304773688316, 0.09360667318105698, 0.05387909337878227, 0.03794718161225319, 0.02410350739955902, 0.0512339286506176, 0.02753080055117607, 0.06161162629723549, -0.0029666784685105085, 0.010774930007755756, 0.06206117942929268, 0.03400186821818352, -0.03997576981782913, -0.02159225195646286, -0.04906081780791283, -0.005984341725707054, -0.03276088833808899, -0.23804570734500885, -0.014653601683676243, 0.010145350359380245, 0.07461323589086533, 0.009806540794670582, -0.04484817758202553, 0.020482439547777176, -0.054893650114536285, 0.05099209025502205, 0.0030384408310055733, 0.0010945384856313467, 0.057528842240571976, 0.03646163269877434, -0.006192189175635576, -0.05147315561771393, -0.005765479523688555, -0.02525370381772518, 0.002571186749264598, 0.06153038889169693, 0.019942495971918106, -0.02882387675344944, -0.029446879401803017, 0.15828974545001984, -0.023859171196818352, -0.052022241055965424, 0.01776924543082714, 0.04368463158607483, -0.04442505165934563, -0.0017266382928937674, -0.0012000353308394551, -0.04843539372086525, 0.023834744468331337, 0.036667075008153915, 0.014156664721667767, -0.06493820250034332, 0.033048879355192184, -0.04464675113558769, 0.036637112498283386, 0.00019915647862944752, -0.02349226549267769, 0.0044355024583637714, 0.06326522678136826, -0.06207249313592911, 0.0024941142182797194, 0.012517226859927177, 0.004503124393522739, 0.08010701090097427, -0.039872560650110245, -0.006051909644156694, 0.01391163282096386, -0.03364238515496254, -0.04255569726228714, 0.00997887458652258, -0.0026178485713899136, 0.011869334615767002, 0.0425339974462986, 0.0010504290694370866, 0.01980026252567768, -0.015760570764541626, -0.02295832149684429, -0.016493631526827812, -0.024361953139305115, 0.06891552358865738, 0.04868897795677185, -0.024158943444490433], metadata={'page_label': '9', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='99adf1b4-946b-4666-b5b7-7c056bde53d9', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '9', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='4f4229c00d83bed89170f53b3d659db750a2b4084511589c17080ef29c444aeb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0758fe99-4a42-4d3e-82ea-427c9ce38ce1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4371777d4655fa8a4d91b12dc49ec7a93c4ad67d6006567606fbcb493a9bea13')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='dataset in Spanish, and the discrepancies resulting from the translation, the predictive capability of the models was\\nlimited. Nonetheless, BETO embedding allowed us to obtain the best result for the dataset in Spanish (or any validation\\nover news items in Spanish using DL models), considering the fact that its approximately 110 million parameters were\\npre-trained on a corpus in this language; this enabled us to take full advantage of the Transfer Learning strategy, and\\nobtain an outstanding performance of 80% of accuracy on the test set, in spite of the small number of samples available\\nfor such deep network architecture. Figure 4 showed the result for the LSTM model combined with this embedding,\\nwhich corresponds to the best strategy identiﬁed for detecting fake news in Spanish using DL techniques: out of the\\n258 news items used for validation, the model correctly classiﬁed 76% of the fake news items, as well as 86% of the\\nlegitimate news items, which we consider a good hit ratio; by contrast, the model tends to confuse news items that are\\nfake with legitimate ones, which corresponds to the main error condition it incurred.\\nAlthough the best detection rate achieved for DL models was similar to that obtained with RF, there is indubitably\\nmore room for improvement in the case of Deep Neural network architectures, due to the combination with Word\\nEmbeddings and more advanced techniques. Thus, in the future, this research could continue aiming at building a\\nmore robust system from the best strategy we found (BETO + LSTM), if a set of labeled news in Spanish with a more\\nrepresentative number of samples are available; furthermore, more experiments combining hyperparameter values and\\nnetwork architectures could also be carried out.\\nReferences\\n[1] “5 claves para entender el escándalo de cambridge analytica que hizo que facebook perdiera us 37.000 millones\\nen un día (bbc news mundo).” https://www.bbc.com/mundo/noticias-43472797, Mar 2018. [Online;\\naccessed 09-Sep-2021].\\n[2] J.-P. Posadas-Durán, H. Gómez-Adorno, G. Sidorov, and J. J. M. Escobar, “Detection of fake news in a new corpus\\nfor the spanish language,”Journal of Intelligent & Fuzzy Systems, vol. 36, no. 5, pp. 4869–4876, 2019.\\n[3] K. Shu, A. Sliva, S. Wang, J. Tang, and H. Liu, “Fake news detection on social media: A data mining perspective,”\\nACM SIGKDD explorations newsletter, vol. 19, no. 1, pp. 22–36, 2017.\\n[4] L. Wu and H. Liu, “Tracing fake-news footprints: Characterizing social media messages by how they propagate,”\\nin Proceedings of the eleventh ACM international conference on Web Search and Data Mining, pp. 637–645, 2018.\\n[5] W. Y . Wang, “\" liar, liar pants on ﬁre\": A new benchmark dataset for fake news detection,” arXiv preprint\\narXiv:1705.00648, 2017.\\n[6] A. M. Bra¸ soveanu and R. Andonie, “Semantic fake news detection: a machine learning perspective,” inInterna-\\ntional Work-Conference on Artiﬁcial Neural Networks, pp. 656–667, Springer, 2019.\\n[7] P. H. A. Faustini and T. F. Covões, “Fake news detection in multiple platforms and languages,”Expert Systems\\nwith Applications, p. 113503, 2020.\\n[8] J. Pennington, R. Socher, and C. D. Manning, “Glove: Global vectors for word representation,” in Empirical\\nMethods in Natural Language Processing (EMNLP), pp. 1532–1543, 2014.\\n[9] J. Pennington, “Glove: Global vectors for word representation.” https://nlp.stanford.edu/projects/\\nglove/, 2014. [Online; accessed 09-Sep-2021].\\n[10] M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee, and L. Zettlemoyer, “Deep contextualized\\nword representations,”arXiv preprint arXiv:1802.05365, 2018.', mimetype='text/plain', start_char_idx=0, end_char_idx=3609, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       "  TextNode(id_='0758fe99-4a42-4d3e-82ea-427c9ce38ce1', embedding=[-0.041444066911935806, -0.020957309752702713, -0.011308576911687851, 0.0395907424390316, 0.10887260735034943, 0.025917958468198776, -0.0019273704383522272, 0.0021284709218889475, 0.004989605396986008, 0.021763470023870468, 0.07052695006132126, -0.02523566596210003, -0.01074845902621746, 0.018206562846899033, 0.06674060225486755, 0.013183915056288242, 0.0336490161716938, -0.05163349583745003, -0.03366521745920181, -0.005774919409304857, 0.12805740535259247, 0.002549547702074051, 0.029413698241114616, -0.00018823315622285008, 0.03759326785802841, 0.03469056636095047, 0.013955074362456799, 0.012590842321515083, -0.024206049740314484, -0.22066567838191986, 0.006095318589359522, -0.04027320444583893, 0.03439464420080185, -0.02615595981478691, 0.004576231352984905, 0.00768707413226366, -0.025057319551706314, -0.03341476246714592, -0.04128292575478554, 0.03395935893058777, -0.03499474748969078, 0.013581978157162666, -0.0036649275571107864, -0.01863585226237774, 0.057936057448387146, -0.051815859973430634, -0.008569165132939816, -0.01176740787923336, -0.03653949499130249, -0.007387113757431507, -0.010104361921548843, -0.024465221911668777, 0.01208287663757801, 0.009018708020448685, 0.030774548649787903, 0.03490255028009415, 0.0580715611577034, -0.02503799833357334, 0.039807576686143875, 0.07927827537059784, 0.024700069800019264, 0.045199792832136154, -0.13893717527389526, 0.05171039327979088, -0.041703660041093826, -0.003574240952730179, -0.03860465809702873, -0.034157782793045044, -0.01860886998474598, 0.014447679743170738, -0.012086525559425354, -0.01313343457877636, 0.052092425525188446, 0.017947062849998474, 0.01230000052601099, 0.02477911300957203, 0.026776263490319252, 0.019803762435913086, 0.021557392552495003, -0.018609385937452316, 0.0035820084158331156, 0.05547034367918968, -0.013456996530294418, -0.0641053318977356, 0.01802193373441696, -0.04977750778198242, 0.04766475036740303, 0.004504441283643246, -0.01692144200205803, -0.022326316684484482, -0.03029443882405758, -0.037732113152742386, 0.04128977656364441, 0.020665636286139488, -0.00024233481963165104, -0.03787487745285034, -0.05107078701257706, 0.01854514330625534, -0.0019896533340215683, 0.3969387710094452, -0.012618659064173698, -0.012636743485927582, 0.03206092119216919, 0.0016071118880063295, -0.012495506554841995, -0.01632235012948513, 0.010484201833605766, -0.020908555015921593, -0.016519786790013313, 0.03652022406458855, -0.0709613561630249, -0.033572498708963394, 0.007932220585644245, -0.016670387238264084, -0.0024848845787346363, 0.0028108740225434303, 0.03715886175632477, -0.004910639487206936, -0.0464322455227375, 0.03484780341386795, 0.0012554157292470336, -0.012789209373295307, 0.03708430379629135, 0.008683775551617146, 0.0017808175180107355, 0.02162126824259758, 0.01658758334815502, 0.08470819145441055, 0.07449228316545486, 0.03439297527074814, 0.005934868473559618, -0.008704880252480507, -0.03736278414726257, 0.037836119532585144, 0.03511326387524605, 0.042274314910173416, -0.04184213653206825, 0.020630836486816406, -0.010576639324426651, -0.0017652608221396804, -0.036685023456811905, -0.014022146351635456, 0.025749335065484047, 0.017390601336956024, -0.08401451259851456, 0.09552334994077682, -0.08640388399362564, 0.006341868545860052, -0.03175824508070946, -0.0013882474740967155, -0.0018889695638790727, 0.0896100327372551, -0.02158849872648716, -0.014864139258861542, 0.009682969190180302, 0.009772256948053837, -0.011349261738359928, 0.02639262191951275, -0.06403802335262299, -0.01890582963824272, -0.0020936124492436647, -0.06255179643630981, 0.014951124787330627, 0.04565957933664322, -0.0071830665692687035, -0.04951076954603195, -0.015156228095293045, 0.03720598295331001, 0.02183062583208084, -0.028302233666181564, 0.06058632582426071, 0.021773388609290123, 0.015587126836180687, 0.01230472233146429, -0.03490130975842476, -0.024839570745825768, -0.026454417034983635, -0.029540689662098885, -0.006678113713860512, 0.02605922520160675, -0.03593602403998375, -0.06170970946550369, -0.06887388229370117, 0.06765439361333847, -0.0424506701529026, -0.0038547555450350046, 0.011037223972380161, -0.017626754939556122, 0.09202306717634201, 0.04216787964105606, 0.0006978804594837129, 0.03553895652294159, -0.046964988112449646, -0.006167247425764799, -0.008013484999537468, -0.023758262395858765, -0.038711342960596085, 0.02133387327194214, -0.009851539507508278, -0.005024050362408161, -0.01728226989507675, 0.02753319777548313, -0.029294749721884727, -0.050217535346746445, -0.03954237699508667, 0.00384707422927022, -0.0426272377371788, -0.026484504342079163, 0.041536375880241394, -0.0054793753661215305, -0.014868664555251598, -0.043284688144922256, -0.003321412717923522, -0.03158316761255264, -0.0025048500392585993, -0.008521939627826214, 0.0069774785079061985, 0.05868181213736534, -0.05363049730658531, 0.031741321086883545, -0.09747053682804108, 0.04248540848493576, -0.026317967101931572, -0.3666688799858093, -0.06633369624614716, -0.03089357353746891, 0.015933362767100334, -0.006493235472589731, -0.06937314569950104, 0.03361944854259491, 0.02128884196281433, 0.09195416420698166, 0.08731145411729813, 0.016406262293457985, -0.0008275588043034077, -0.04972948133945465, -0.023940717801451683, 0.002659719670191407, 0.04916827753186226, 0.05234678462147713, -0.031080689281225204, 0.022575149312615395, 0.06418606638908386, -0.016585567966103554, 0.045370835810899734, -0.008501526899635792, -0.006178638432174921, 0.03352341428399086, 0.009653599001467228, 0.08144456893205643, 0.07310917973518372, 0.01250174269080162, -0.06367536634206772, -0.01233677938580513, 0.04732764512300491, -0.020540574565529823, -0.0017331314738839865, 0.0474558100104332, -0.02068527415394783, 0.034405965358018875, -0.024973075836896896, 0.028514374047517776, 0.006981812883168459, 0.006801602430641651, -0.02505692094564438, 0.03193240612745285, -0.07873034477233887, -0.0024915069807320833, -0.02745683304965496, 0.0015323625411838293, 0.015721770003437996, -0.02767089754343033, 0.027044113725423813, 0.019764482975006104, 0.054724860936403275, 0.05500982329249382, 0.021587936207652092, -0.011383892968297005, -0.03576159104704857, -0.06591366231441498, -0.032634660601615906, -0.0662248358130455, -0.028431547805666924, 0.051140204071998596, -0.014638771302998066, 0.023931283503770828, -0.06783095002174377, 0.034903690218925476, 0.002914062002673745, -0.0455499030649662, -0.033011794090270996, 0.060395948588848114, 0.09593599289655685, -0.04486946016550064, 0.11451411992311478, 0.027689583599567413, 0.023679671809077263, 0.0752321407198906, 0.02201985940337181, 0.017665179446339607, -0.08319253474473953, -0.04350382462143898, 0.0002564061142038554, 0.04862323775887489, 0.04390127956867218, 0.059541214257478714, 0.02148636244237423, 0.01957189477980137, -0.037585556507110596, 0.016579842194914818, -0.050378963351249695, 0.048562075942754745, 0.026644494384527206, 0.013460967689752579, -0.013377507217228413, 0.021089529618620872, -0.03737340122461319, 0.03687324747443199, 0.011008862406015396, -0.2420525997877121, -0.025519434362649918, 0.04598525911569595, 0.05345002934336662, 0.04316363483667374, -0.027878906577825546, 0.028170602396130562, -0.0735798254609108, 0.03761301934719086, -0.026868408545851707, -0.06234215945005417, 0.03659883514046669, 0.07015783339738846, -0.03632161766290665, -0.06388751417398453, 0.026789216324687004, 0.0463559553027153, 0.019189465790987015, 0.08048855513334274, 0.00943402387201786, -0.024484096094965935, -0.05819074064493179, 0.1470654308795929, 0.036246269941329956, -0.06315670907497406, 0.0021842336282134056, -0.0076537420973181725, -0.05667347088456154, 0.015557928010821342, 0.003926093690097332, -0.03412959724664688, -0.008744106628000736, 0.028323762118816376, 0.019344402477145195, -0.025558888912200928, -0.015420953743159771, -0.05573665723204613, -0.0013451852137222886, 0.004158027935773134, -0.03175891190767288, -0.015139902010560036, 0.02913413941860199, -0.03516977280378342, -0.06562292575836182, -0.015063599683344364, 0.012892413884401321, 0.03709610924124718, -0.05576573312282562, -0.05255794897675514, -0.019389817491173744, 0.005000927019864321, -0.016236526891589165, -0.013676987960934639, -0.04708961024880409, 0.028834093362092972, 0.05932438373565674, 0.02552105486392975, 0.002310388721525669, -0.018247360363602638, -0.022590458393096924, -0.056062351912260056, -0.032485391944646835, 0.03654628247022629, 0.02287297137081623, -0.019502637907862663], metadata={'page_label': '9', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='99adf1b4-946b-4666-b5b7-7c056bde53d9', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '9', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='4f4229c00d83bed89170f53b3d659db750a2b4084511589c17080ef29c444aeb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d96e97c5-4f22-4568-a69e-684534e20342', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '9', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='28c0a2d960f158353a5b771f65f2b3c3e39455fd5b7b12b8f5284b2b25a74d40')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='[11] Google, “Elmo - tensorﬂow hub.” https://tfhub.dev/google/elmo/3, 2020. [Online; accessed 09-Sep-\\n2021].\\n[12] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training of deep bidirectional transformers for\\nlanguage understanding,”arXiv preprint arXiv:1810.04805, 2018.\\n[13] Google. https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2 , 2020. [Online; ac-\\ncessed 09-Sep-2021].\\n[14] J. Cañete, G. Chaperon, R. Fuentes, J.-H. Ho, H. Kang, and J. Pérez, “Spanish pre-trained bert model and\\nevaluation data,” inPML4DC at ICLR 2020, 2020.\\n[15] C. Bisaillon, “Fake and real news dataset.” https://www.kaggle.com/clmentbisaillon/\\nfake-and-real-news-dataset , mar 2020. [Online; accessed 09-Sep-2021].\\n[16] V . Ukani, “News data set - fake or real.” https://kaggle.com/vikasukani/\\nnews-data-set-fake-news-with-python , Jul 2020. [Online; accessed 09-Sep-2021].\\n9', mimetype='text/plain', start_char_idx=3610, end_char_idx=4491, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       "  TextNode(id_='94b2caa9-bf7a-474b-8c6c-34d6641ef012', embedding=[-0.04462859779596329, -0.0293769221752882, -0.028853315860033035, 0.02325955219566822, 0.08886309713125229, 0.0040738401003181934, -0.02268746681511402, 0.058303821831941605, -0.004371533636003733, -0.002001071348786354, 0.0683927834033966, 0.002607464324682951, -0.04750450700521469, 0.022856982424855232, 0.03571493178606033, 0.013723120093345642, 0.03830277919769287, -0.04021051153540611, 0.008081086911261082, -0.019578276202082634, 0.08359299600124359, 0.035814374685287476, 0.02659771963953972, 0.030314939096570015, 0.009767883457243443, 0.035340916365385056, -0.00368443108163774, 0.009215088561177254, -0.07221634685993195, -0.18286007642745972, 0.0047850171104073524, -0.0395725816488266, 0.010896584950387478, -0.03639340400695801, 0.029851149767637253, -0.03498241677880287, -0.03992021456360817, 0.0014898297376930714, 0.006964636500924826, 0.02980496920645237, -0.03247943893074989, 0.021215729415416718, -0.011121902614831924, -0.040871571749448776, 0.041969772428274155, -0.05142122879624367, -0.047971393913030624, 0.03088335134088993, 0.023855505511164665, -0.017382418736815453, -0.045518696308135986, -0.0029886229895055294, 0.009310731664299965, -0.020164145156741142, 0.010976056568324566, 0.01632378064095974, 0.0548502616584301, -0.022578686475753784, 0.0502631850540638, 0.05702033266425133, 0.05826690047979355, 0.034793198108673096, -0.1667134314775467, 0.041592590510845184, -0.050942230969667435, 0.01033522468060255, 0.010904699563980103, 0.02290705218911171, -0.032661497592926025, -0.0331367552280426, -0.029881874099373817, -0.0388641431927681, 0.0073384372517466545, 0.03322209417819977, 0.011961025185883045, -0.03192577511072159, 0.017524264752864838, 0.006392295937985182, -0.033229976892471313, -0.021154973655939102, 0.02912944182753563, 0.046368688344955444, 0.01941242441534996, -0.03942529112100601, -0.02152884751558304, -0.04193561151623726, 0.04329613223671913, 0.02199959196150303, 0.00037534028524532914, -0.016360992565751076, -0.020291466265916824, -0.03147348016500473, 0.08635188639163971, 0.03139149025082588, -0.10761373490095139, -0.03644196316599846, -0.017031354829669, 0.03857564181089401, 0.01782027818262577, 0.507922351360321, -0.005102802067995071, -0.004808023106306791, 0.05519898608326912, 0.005384232848882675, 0.011297261342406273, -0.010740583762526512, -0.026393551379442215, 0.01225544698536396, -0.012595714069902897, 0.02136584185063839, -0.030038470402359962, -0.03443515673279762, 0.051905471831560135, -0.00943763367831707, -0.004971782676875591, -0.009436622262001038, 0.0825728252530098, 0.032727036625146866, -0.028423231095075607, 0.027015095576643944, 0.009920050390064716, -0.01898672804236412, 0.04774367809295654, -0.0005908228340558708, 0.011327940039336681, -0.014950337819755077, 0.018488597124814987, 0.07417640089988708, 0.03765527158975601, 0.04748402535915375, 0.004578304011374712, 0.021524515002965927, 0.02558997832238674, 0.028425490483641624, 0.010820876806974411, 0.01709369570016861, -0.030475115403532982, 0.03656711429357529, 0.011856977827847004, -0.011555084958672523, -0.048127904534339905, -0.05338418111205101, 0.014319824986159801, -0.04104955494403839, -0.056878045201301575, 0.04286985099315643, -0.0324857272207737, 0.04015670716762543, -0.010496577247977257, -0.00839132908731699, -0.01693359762430191, 0.1047656238079071, 0.0039205169305205345, 0.0025548019912093878, -0.040104690939188004, -0.03569621965289116, 0.052024614065885544, -0.014977698214352131, -0.0841212272644043, -0.022729340940713882, 0.04451599344611168, -0.02484937198460102, 0.020945578813552856, 0.08911164104938507, 0.014690347015857697, -0.052852824330329895, -0.018615471199154854, 0.03028271347284317, 0.03343629464507103, -0.03354808688163757, 0.009445630013942719, -0.01120846252888441, -0.005516933277249336, 0.017168162390589714, 0.023419789969921112, 0.020603714510798454, -0.0164785236120224, 0.04455426707863808, -0.02673516795039177, -0.02321869134902954, 0.01023862138390541, -0.014867274090647697, -0.0707395076751709, 0.06809286773204803, -0.001986067509278655, -0.0018059539142996073, -0.013668867759406567, -0.01008065976202488, 0.05995844304561615, 0.0472872294485569, -0.05617557093501091, 0.01644187979400158, -0.04160257428884506, -0.008063845336437225, -0.03877782076597214, -0.029049690812826157, -0.024408234283328056, -0.0008305714000016451, 0.0344022698700428, -0.04009134694933891, 0.07518515735864639, -0.021082479506731033, -0.02887013927102089, 0.02681078016757965, -0.019156944006681442, -0.015932559967041016, 0.009298508055508137, -0.04334985092282295, 0.012407956644892693, -0.016271885484457016, -0.013186659663915634, -0.008372511714696884, 0.0011391411535441875, -0.02997017093002796, 0.0075765918008983135, -0.012626967392861843, 0.0013066161191090941, 0.037597574293613434, -0.026206400245428085, 0.0021467653568834066, -0.031680215150117874, 0.04618087410926819, -0.0268905907869339, -0.34416550397872925, -0.023572448641061783, -0.028813617303967476, 0.01823895238339901, -0.006287998985499144, -0.05028034374117851, 0.035976383835077286, 0.010028745047748089, 0.06583373993635178, 0.08573488891124725, -0.017500117421150208, -0.014756007120013237, -0.03224087134003639, -0.004601964261382818, 0.001819346914999187, 0.04684894531965256, 0.023987306281924248, -0.003973380662500858, 0.007216352038085461, 0.03761720657348633, 0.006440387573093176, 0.02610505186021328, -0.044675227254629135, -0.0010945516405627131, 0.014254307374358177, -0.0025629133451730013, 0.06690745055675507, 0.10977701097726822, -0.045400287955999374, -0.027308892458677292, -0.017415709793567657, 0.022730752825737, -0.056188877671957016, -0.07107993215322495, 0.03551942855119705, 0.01245616190135479, -0.004515406675636768, -0.05434156209230423, 0.015435906127095222, 0.003365042619407177, 0.023160647600889206, -0.021156106144189835, -0.011780488304793835, -0.033473242074251175, -0.01347918901592493, -0.06517916172742844, 0.03511243686079979, 0.04086712375283241, -0.013268415816128254, 0.05666977912187576, -0.0014363433001562953, 0.07775606960058212, 0.06839379668235779, 0.042762573808431625, -0.0011642660247161984, -0.039912015199661255, -0.03892998769879341, -0.020119842141866684, -0.04057910293340683, -0.013489896431565285, 0.024182675406336784, 0.04607253894209862, 0.026349931955337524, -0.042709678411483765, 0.019469674676656723, 0.02508760616183281, -0.05863465741276741, -0.023474669083952904, 0.047410812228918076, 0.059741612523794174, -0.031024251133203506, 0.12857529520988464, 0.0015859678387641907, -0.025134872645139694, 0.047680504620075226, 0.058608558028936386, 0.009301822632551193, -0.07487740367650986, -0.04797239229083061, -0.00405853008851409, 0.04231465607881546, 0.04758001118898392, 0.029333775863051414, -0.009090605191886425, -0.014849197119474411, -0.035379912704229355, -0.006922165863215923, -0.03433334827423096, 0.03510762006044388, -0.001715196529403329, 0.019123578444123268, -0.016185104846954346, -0.007910883985459805, -0.04366406798362732, 0.03922508656978607, 0.000539312488399446, -0.2421550452709198, -0.02417592518031597, 0.01866067945957184, 0.05396493524312973, 0.01570640690624714, -0.01014130562543869, 0.045943960547447205, -0.026941468939185143, 0.003456374630331993, 0.023255841806530952, -0.033494964241981506, 0.027640782296657562, -0.009661906398832798, -0.017344217747449875, -0.026052651926875114, -0.009488255716860294, -0.014692116528749466, -0.009820984676480293, 0.07723595201969147, 0.02155543491244316, -0.032341718673706055, -0.04314812272787094, 0.14978191256523132, 0.01661570742726326, -0.06603787839412689, 0.00297392881475389, 0.013383575715124607, -0.02283085137605667, -0.021933818235993385, 0.022867966443300247, -0.043192315846681595, -0.008240151219069958, 0.014006909914314747, 0.01589788682758808, -0.04603312537074089, -0.0016604175325483084, -0.05530233681201935, 0.013369498774409294, -0.030167538672685623, -0.04404858127236366, -0.032037295401096344, 0.04192836582660675, -0.044015172868967056, -0.019834673032164574, 0.011950811371207237, -0.006441598758101463, -0.002102041617035866, -0.05956793949007988, 0.030392026528716087, -0.026104064658284187, -0.009129864163696766, -0.020967604592442513, -0.012141246348619461, -0.0011071589542552829, 0.02496393583714962, 0.0265524722635746, 0.012671254575252533, -0.01409868523478508, -0.04126768931746483, -0.03388196974992752, -0.040610335767269135, -0.022779153659939766, 0.028054894879460335, 0.01972278580069542, -0.012011031620204449], metadata={'page_label': '10', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='a2db6b71-67ad-45d1-ba9f-d797826c194b', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '10', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='d1fb493a0d33d7cd741e8585d7e74ae21e0ac19d9d006119f054baac051b9d3e')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='[17] A. Tretiakov, “noticias falsas en español 2020.” https://kaggle.com/arseniitretiakov/\\nnoticias-falsas-en-espaol , 2020. [Online; accessed 09-Sep-2021].\\n10', mimetype='text/plain', start_char_idx=0, end_char_idx=159, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nodes), len(nodes), nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbbee847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes[0].embedding) # Embeddings dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c66cab8",
   "metadata": {},
   "source": [
    "#### Storing and Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650e68f3",
   "metadata": {},
   "source": [
    "#### Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a7e8ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 21:22:50,090 - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "2025-09-07 21:22:52,362 - INFO - 1 prompt is loaded, with the key: query\n"
     ]
    }
   ],
   "source": [
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\") # Must be the same used in training for query-match consistency\n",
    "index = VectorStoreIndex.from_vector_store(vector_store, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56b60c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "hf_token = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee94cf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()  # This is needed to run the query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "784c741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceInferenceAPI(\n",
    "    model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000,\n",
    "    token=hf_token,\n",
    "    provider=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42354372",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    response_mode=\"tree_summarize\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdd76b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Hello! How can I assist you today based on the provided information?', source_nodes=[NodeWithScore(node=TextNode(id_='94b2caa9-bf7a-474b-8c6c-34d6641ef012', embedding=None, metadata={'page_label': '10', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='a2db6b71-67ad-45d1-ba9f-d797826c194b', node_type='4', metadata={'page_label': '10', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='d1fb493a0d33d7cd741e8585d7e74ae21e0ac19d9d006119f054baac051b9d3e')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='[17] A. Tretiakov, “noticias falsas en español 2020.” https://kaggle.com/arseniitretiakov/\\nnoticias-falsas-en-espaol , 2020. [Online; accessed 09-Sep-2021].\\n10', mimetype='text/plain', start_char_idx=0, end_char_idx=159, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.42561685400738125), NodeWithScore(node=TextNode(id_='a6e03e5f-90b9-4634-8c3f-228020d9629e', embedding=None, metadata={'page_label': '6', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='3ab62d6b-fff4-42d2-b6cf-c6a66012bec3', node_type='4', metadata={'page_label': '6', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='c11dbe766b605dbe782c443824743f71236063dfddbed5ee59b530a29feeef6d')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='The source code used to carry out the experiments can be found in a publicly accessible repository at GitHub 3.\\n4.3 Results\\nTable 1 shows the best results for each of the models considered during the experiments of the ﬁrst scheme, which\\nwas described in subsection 4.2. It also shows the conﬁguration of pre-processing steps that achieved the best results.\\nMoreover, the hyperparameter values selected for each model were the following:\\n• (SVM) kernel RBF; ’C’: 1e3; kernel coefﬁcient ’gamma’: 1\\n• (RF and GBT) number of trees: 500; maximum number of features: 50\\n• (MLP) hidden layers: 1; neurons: 10; epochs: 1500\\nTable 1: Baseline results for the dataset in Spanish\\nModel Vocab Size Stemming Remove StopWords Text Representation test_acc\\nSVM 10000 NO YES tf-idf 0.798\\nRF 40000 NO YES tf-idf 0.802\\nGBT 40000 YES NO BoW 0.783\\nMLP 10000 YES NO tf-idf 0.794\\nAccording to the baseline results, RF in combination with a tf-idf text representation showed the highest accuracy.\\nSubsequently, we performed the experiments with the DL models (LSTM, CNN) in combination with the different types\\nof Word Embeddings; hence, we followed the second, third, and fourth schemes. From this point on, we permanently\\nremoved Stop Words and did not apply Stemming anymore regarding data pre-processing.\\nInitially, we ran some experiments using a trainable embedding layer; the results are summarized in Table 2, where the\\nhyperparameter values selected for each model were:\\n• LSTM (Spanish) 16 units; KR and KK equals 1; D equals 0\\n• LSTM (English) 4 units; KR and KK equals 0.01; D equals 0\\n• CNN (Spanish) F equals 16; KS equals 10; 4 units; KR equals 0.01\\n• CNN (English) F equals 16; KS equals 10; 12 units; KR equals 0\\nThe LSTM and CNN models trained with the English dataset, whose results are shown in Table 2, were also validated\\nwith the whole translated dataset, yielding accuracies of 56.7% and 53.2% respectively.\\nTable 2: Results for DL models with trainable embedding layer; the column dev_acc shows the accuracy in the\\ndevelopment set; std is the standard deviation, and test_acc shows the accuracy in the test set.\\nModel Dataset Language dev_acc std test_acc\\nLSTM Spanish 0.714 0.026 0.761\\nLSTM English 0.95 0.02 0.931\\nCNN Spanish 0.73 0.021 0.685\\nCNN English 0.984 0.002 0.982\\nNext, we performed the experiments using a Transfer Learning approach, with the pre-trained 300-feature GloVe\\nembedding layer presented in subsection 3.2; this time, the embedding values were left ﬁxed during the training process,\\nand only the added hidden layers were ﬁne-tuned. Since the GloVe vectors utilized were trained on a corpus in English,\\nthese experiments correspond to the third and fourth schemes. The results are summarized in Table 3; moreover, the\\nhyperparameter values chosen for each model were the following:\\n• (LSTM) 8 units; KR and KK equals 0; D equals 0.5\\n• (CNN) F equals 16; KS equals 10; 4 units; KR equals 0\\nThen, when validating the former models using the translated dataset (fourth scheme), we got accuracy values of 54%\\nand 53.8% for LSTM and CNN layers, respectively.\\n3https://github.com/kevinmaiden7/Spanish_FakeNewsDetection\\n6', mimetype='text/plain', start_char_idx=0, end_char_idx=3138, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.3830079809904734)], metadata={'94b2caa9-bf7a-474b-8c6c-34d6641ef012': {'page_label': '10', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, 'a6e03e5f-90b9-4634-8c3f-228020d9629e': {'page_label': '6', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_engine.query(\"Hello!\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8f3c218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response=\"Kevin Martinez's main contribution to NLP, as detailed in the provided information, involves developing and experimenting with various models for detecting fake news in Spanish. His work includes preprocessing text data through normalization, stop-word removal, stemming, tokenization, and padding. Additionally, he compared different text representation techniques such as Bag of Words, TF-IDF, and word embeddings. Martinez also implemented and evaluated both classical machine learning models (SVM, Random Forest, Gradient Boosting Tree, and MLP) and deep learning models (LSTM-RNN and CNN) for this task. His research includes using both trainable and fixed embedding layers, including a Transfer Learning approach with pre-trained GloVe embeddings. The experiments were conducted on Spanish datasets and also involved validating models with a translated English dataset.\", source_nodes=[NodeWithScore(node=TextNode(id_='c7da3fe9-da44-4066-9869-ee57e9b1a4aa', embedding=None, metadata={'page_label': '3', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='b51881e0-a7b5-40eb-be92-7d99bde1a4e7', node_type='4', metadata={'page_label': '3', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='f44390a7ec43c149fcccfa1aa3bbf0547cebe9b0994a80650269561966e23fc0')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='3 Methods\\n3.1 Preprocessing steps\\nIn order to obtain consistent results, a data standardization process known as Text Normalization was performed, which,\\nin addition to eliminating non-alphanumeric characters in the text, includes some of the most commonly used techniques\\nin NLP:\\n• Stop Words:we removed words there is an agreement they do not contribute to the models learning process in\\nthe context of the problem addressed; for instance, articles and prepositions.\\n• Stemming: this technique was used to reduce words to their root.\\n• Tokenization and Padding:as usual in text processing tasks, we performed tokenization and padding, when\\nrequired, for words and sentences representation.\\nSubsequently, we decided to compare some of the most common techniques regarding text representation: BoW, which\\nprovides the number of occurrences of each word in the text corpus; term frequency-inverse document frequency(tf-idf),\\nwhich provides a weighted measure of the importance of each term within the text (according to its frequency of\\noccurrence in sentences); and pre-trained Word Embeddings, where words and the semantic relationships among them\\nare represented as a vector. It is worth clarifying that, we call Word Embeddings to both pre-trained vectors such as\\nword2vec or GloVe, and embeddings obtained from pre-trained models such as ELMo or BERT (presented in subsection\\n3.2).\\n3.2 Models\\nClassical ML models, and DL models based on artiﬁcial neural networks were used. We employed ML models intending\\nto create a baseline for comparison purposes; hence, we selected the following: Support Vector Machine (SVM),\\nRandom Forest (RF), Gradient Boosting Tree (GBT), and Multi-Layer Perceptron (MLP). For the case of DL classiﬁers,\\nbesides word embeddings, two types of layers were used: Long Short-Term Memory Recurrent Neural Network\\n(LSTM-RNN) using a many-to-one architecture, and Convolutional Neural Network (CNN). LSTM-RNN processes\\nthe input data as sequences of dependent observations, while CNNs can process n-grams through the application of\\nconvolutional ﬁlters. A schematic of the DL classiﬁers in combination with a embedding layer is illustrated in Figure 1;\\nthis ﬁgure shows the arrangement of the aforementioned layers, and the different word embeddings we used which are\\npresented next.\\nFigure 1: Schematic of DL classiﬁers in combination with Embedding Layer\\n3', mimetype='text/plain', start_char_idx=0, end_char_idx=2382, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.47635674798756056), NodeWithScore(node=TextNode(id_='a6e03e5f-90b9-4634-8c3f-228020d9629e', embedding=None, metadata={'page_label': '6', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='3ab62d6b-fff4-42d2-b6cf-c6a66012bec3', node_type='4', metadata={'page_label': '6', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='c11dbe766b605dbe782c443824743f71236063dfddbed5ee59b530a29feeef6d')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='The source code used to carry out the experiments can be found in a publicly accessible repository at GitHub 3.\\n4.3 Results\\nTable 1 shows the best results for each of the models considered during the experiments of the ﬁrst scheme, which\\nwas described in subsection 4.2. It also shows the conﬁguration of pre-processing steps that achieved the best results.\\nMoreover, the hyperparameter values selected for each model were the following:\\n• (SVM) kernel RBF; ’C’: 1e3; kernel coefﬁcient ’gamma’: 1\\n• (RF and GBT) number of trees: 500; maximum number of features: 50\\n• (MLP) hidden layers: 1; neurons: 10; epochs: 1500\\nTable 1: Baseline results for the dataset in Spanish\\nModel Vocab Size Stemming Remove StopWords Text Representation test_acc\\nSVM 10000 NO YES tf-idf 0.798\\nRF 40000 NO YES tf-idf 0.802\\nGBT 40000 YES NO BoW 0.783\\nMLP 10000 YES NO tf-idf 0.794\\nAccording to the baseline results, RF in combination with a tf-idf text representation showed the highest accuracy.\\nSubsequently, we performed the experiments with the DL models (LSTM, CNN) in combination with the different types\\nof Word Embeddings; hence, we followed the second, third, and fourth schemes. From this point on, we permanently\\nremoved Stop Words and did not apply Stemming anymore regarding data pre-processing.\\nInitially, we ran some experiments using a trainable embedding layer; the results are summarized in Table 2, where the\\nhyperparameter values selected for each model were:\\n• LSTM (Spanish) 16 units; KR and KK equals 1; D equals 0\\n• LSTM (English) 4 units; KR and KK equals 0.01; D equals 0\\n• CNN (Spanish) F equals 16; KS equals 10; 4 units; KR equals 0.01\\n• CNN (English) F equals 16; KS equals 10; 12 units; KR equals 0\\nThe LSTM and CNN models trained with the English dataset, whose results are shown in Table 2, were also validated\\nwith the whole translated dataset, yielding accuracies of 56.7% and 53.2% respectively.\\nTable 2: Results for DL models with trainable embedding layer; the column dev_acc shows the accuracy in the\\ndevelopment set; std is the standard deviation, and test_acc shows the accuracy in the test set.\\nModel Dataset Language dev_acc std test_acc\\nLSTM Spanish 0.714 0.026 0.761\\nLSTM English 0.95 0.02 0.931\\nCNN Spanish 0.73 0.021 0.685\\nCNN English 0.984 0.002 0.982\\nNext, we performed the experiments using a Transfer Learning approach, with the pre-trained 300-feature GloVe\\nembedding layer presented in subsection 3.2; this time, the embedding values were left ﬁxed during the training process,\\nand only the added hidden layers were ﬁne-tuned. Since the GloVe vectors utilized were trained on a corpus in English,\\nthese experiments correspond to the third and fourth schemes. The results are summarized in Table 3; moreover, the\\nhyperparameter values chosen for each model were the following:\\n• (LSTM) 8 units; KR and KK equals 0; D equals 0.5\\n• (CNN) F equals 16; KS equals 10; 4 units; KR equals 0\\nThen, when validating the former models using the translated dataset (fourth scheme), we got accuracy values of 54%\\nand 53.8% for LSTM and CNN layers, respectively.\\n3https://github.com/kevinmaiden7/Spanish_FakeNewsDetection\\n6', mimetype='text/plain', start_char_idx=0, end_char_idx=3138, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.46875538337781664)], metadata={'c7da3fe9-da44-4066-9869-ee57e9b1a4aa': {'page_label': '3', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, 'a6e03e5f-90b9-4634-8c3f-228020d9629e': {'page_label': '6', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the main contribution of Kevin Martinez to NLP?\"\n",
    "response = query_engine.query(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1ba980c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Kevin Martinez's main contribution to NLP, as detailed in the provided information, involves developing and experimenting with various models for detecting fake news in Spanish. His work includes preprocessing text data through normalization, stop-word removal, stemming, tokenization, and padding. Additionally, he compared different text representation techniques such as Bag of Words, TF-IDF, and word embeddings. Martinez also implemented and evaluated both classical machine learning models (SVM, Random Forest, Gradient Boosting Tree, and MLP) and deep learning models (LSTM-RNN and CNN) for this task. His research includes using both trainable and fixed embedding layers, including a Transfer Learning approach with pre-trained GloVe embeddings. The experiments were conducted on Spanish datasets and also involved validating models with a translated English dataset.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e85f789f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c7da3fe9-da44-4066-9869-ee57e9b1a4aa': {'page_label': '3',\n",
       "  'file_name': 'fake_news_detection_spanish_DL.pdf',\n",
       "  'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf',\n",
       "  'file_type': 'application/pdf',\n",
       "  'file_size': 247472,\n",
       "  'creation_date': '2025-09-08',\n",
       "  'last_modified_date': '2025-09-08'},\n",
       " 'a6e03e5f-90b9-4634-8c3f-228020d9629e': {'page_label': '6',\n",
       "  'file_name': 'fake_news_detection_spanish_DL.pdf',\n",
       "  'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf',\n",
       "  'file_type': 'application/pdf',\n",
       "  'file_size': 247472,\n",
       "  'creation_date': '2025-09-08',\n",
       "  'last_modified_date': '2025-09-08'}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae666d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='c7da3fe9-da44-4066-9869-ee57e9b1a4aa', embedding=None, metadata={'page_label': '3', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='b51881e0-a7b5-40eb-be92-7d99bde1a4e7', node_type='4', metadata={'page_label': '3', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='f44390a7ec43c149fcccfa1aa3bbf0547cebe9b0994a80650269561966e23fc0')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='3 Methods\\n3.1 Preprocessing steps\\nIn order to obtain consistent results, a data standardization process known as Text Normalization was performed, which,\\nin addition to eliminating non-alphanumeric characters in the text, includes some of the most commonly used techniques\\nin NLP:\\n• Stop Words:we removed words there is an agreement they do not contribute to the models learning process in\\nthe context of the problem addressed; for instance, articles and prepositions.\\n• Stemming: this technique was used to reduce words to their root.\\n• Tokenization and Padding:as usual in text processing tasks, we performed tokenization and padding, when\\nrequired, for words and sentences representation.\\nSubsequently, we decided to compare some of the most common techniques regarding text representation: BoW, which\\nprovides the number of occurrences of each word in the text corpus; term frequency-inverse document frequency(tf-idf),\\nwhich provides a weighted measure of the importance of each term within the text (according to its frequency of\\noccurrence in sentences); and pre-trained Word Embeddings, where words and the semantic relationships among them\\nare represented as a vector. It is worth clarifying that, we call Word Embeddings to both pre-trained vectors such as\\nword2vec or GloVe, and embeddings obtained from pre-trained models such as ELMo or BERT (presented in subsection\\n3.2).\\n3.2 Models\\nClassical ML models, and DL models based on artiﬁcial neural networks were used. We employed ML models intending\\nto create a baseline for comparison purposes; hence, we selected the following: Support Vector Machine (SVM),\\nRandom Forest (RF), Gradient Boosting Tree (GBT), and Multi-Layer Perceptron (MLP). For the case of DL classiﬁers,\\nbesides word embeddings, two types of layers were used: Long Short-Term Memory Recurrent Neural Network\\n(LSTM-RNN) using a many-to-one architecture, and Convolutional Neural Network (CNN). LSTM-RNN processes\\nthe input data as sequences of dependent observations, while CNNs can process n-grams through the application of\\nconvolutional ﬁlters. A schematic of the DL classiﬁers in combination with a embedding layer is illustrated in Figure 1;\\nthis ﬁgure shows the arrangement of the aforementioned layers, and the different word embeddings we used which are\\npresented next.\\nFigure 1: Schematic of DL classiﬁers in combination with Embedding Layer\\n3', mimetype='text/plain', start_char_idx=0, end_char_idx=2382, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.47635674798756056),\n",
       " NodeWithScore(node=TextNode(id_='a6e03e5f-90b9-4634-8c3f-228020d9629e', embedding=None, metadata={'page_label': '6', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='3ab62d6b-fff4-42d2-b6cf-c6a66012bec3', node_type='4', metadata={'page_label': '6', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='c11dbe766b605dbe782c443824743f71236063dfddbed5ee59b530a29feeef6d')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='The source code used to carry out the experiments can be found in a publicly accessible repository at GitHub 3.\\n4.3 Results\\nTable 1 shows the best results for each of the models considered during the experiments of the ﬁrst scheme, which\\nwas described in subsection 4.2. It also shows the conﬁguration of pre-processing steps that achieved the best results.\\nMoreover, the hyperparameter values selected for each model were the following:\\n• (SVM) kernel RBF; ’C’: 1e3; kernel coefﬁcient ’gamma’: 1\\n• (RF and GBT) number of trees: 500; maximum number of features: 50\\n• (MLP) hidden layers: 1; neurons: 10; epochs: 1500\\nTable 1: Baseline results for the dataset in Spanish\\nModel Vocab Size Stemming Remove StopWords Text Representation test_acc\\nSVM 10000 NO YES tf-idf 0.798\\nRF 40000 NO YES tf-idf 0.802\\nGBT 40000 YES NO BoW 0.783\\nMLP 10000 YES NO tf-idf 0.794\\nAccording to the baseline results, RF in combination with a tf-idf text representation showed the highest accuracy.\\nSubsequently, we performed the experiments with the DL models (LSTM, CNN) in combination with the different types\\nof Word Embeddings; hence, we followed the second, third, and fourth schemes. From this point on, we permanently\\nremoved Stop Words and did not apply Stemming anymore regarding data pre-processing.\\nInitially, we ran some experiments using a trainable embedding layer; the results are summarized in Table 2, where the\\nhyperparameter values selected for each model were:\\n• LSTM (Spanish) 16 units; KR and KK equals 1; D equals 0\\n• LSTM (English) 4 units; KR and KK equals 0.01; D equals 0\\n• CNN (Spanish) F equals 16; KS equals 10; 4 units; KR equals 0.01\\n• CNN (English) F equals 16; KS equals 10; 12 units; KR equals 0\\nThe LSTM and CNN models trained with the English dataset, whose results are shown in Table 2, were also validated\\nwith the whole translated dataset, yielding accuracies of 56.7% and 53.2% respectively.\\nTable 2: Results for DL models with trainable embedding layer; the column dev_acc shows the accuracy in the\\ndevelopment set; std is the standard deviation, and test_acc shows the accuracy in the test set.\\nModel Dataset Language dev_acc std test_acc\\nLSTM Spanish 0.714 0.026 0.761\\nLSTM English 0.95 0.02 0.931\\nCNN Spanish 0.73 0.021 0.685\\nCNN English 0.984 0.002 0.982\\nNext, we performed the experiments using a Transfer Learning approach, with the pre-trained 300-feature GloVe\\nembedding layer presented in subsection 3.2; this time, the embedding values were left ﬁxed during the training process,\\nand only the added hidden layers were ﬁne-tuned. Since the GloVe vectors utilized were trained on a corpus in English,\\nthese experiments correspond to the third and fourth schemes. The results are summarized in Table 3; moreover, the\\nhyperparameter values chosen for each model were the following:\\n• (LSTM) 8 units; KR and KK equals 0; D equals 0.5\\n• (CNN) F equals 16; KS equals 10; 4 units; KR equals 0\\nThen, when validating the former models using the translated dataset (fourth scheme), we got accuracy values of 54%\\nand 53.8% for LSTM and CNN layers, respectively.\\n3https://github.com/kevinmaiden7/Spanish_FakeNewsDetection\\n6', mimetype='text/plain', start_char_idx=0, end_char_idx=3138, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.46875538337781664)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.source_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fc2334",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc269b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "faithfulness_evaluator = FaithfulnessEvaluator(llm=llm)\n",
    "relevancy_evaluator = AnswerRelevancyEvaluator(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6128d64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationResult(query=None, contexts=['3 Methods\\n3.1 Preprocessing steps\\nIn order to obtain consistent results, a data standardization process known as Text Normalization was performed, which,\\nin addition to eliminating non-alphanumeric characters in the text, includes some of the most commonly used techniques\\nin NLP:\\n• Stop Words:we removed words there is an agreement they do not contribute to the models learning process in\\nthe context of the problem addressed; for instance, articles and prepositions.\\n• Stemming: this technique was used to reduce words to their root.\\n• Tokenization and Padding:as usual in text processing tasks, we performed tokenization and padding, when\\nrequired, for words and sentences representation.\\nSubsequently, we decided to compare some of the most common techniques regarding text representation: BoW, which\\nprovides the number of occurrences of each word in the text corpus; term frequency-inverse document frequency(tf-idf),\\nwhich provides a weighted measure of the importance of each term within the text (according to its frequency of\\noccurrence in sentences); and pre-trained Word Embeddings, where words and the semantic relationships among them\\nare represented as a vector. It is worth clarifying that, we call Word Embeddings to both pre-trained vectors such as\\nword2vec or GloVe, and embeddings obtained from pre-trained models such as ELMo or BERT (presented in subsection\\n3.2).\\n3.2 Models\\nClassical ML models, and DL models based on artiﬁcial neural networks were used. We employed ML models intending\\nto create a baseline for comparison purposes; hence, we selected the following: Support Vector Machine (SVM),\\nRandom Forest (RF), Gradient Boosting Tree (GBT), and Multi-Layer Perceptron (MLP). For the case of DL classiﬁers,\\nbesides word embeddings, two types of layers were used: Long Short-Term Memory Recurrent Neural Network\\n(LSTM-RNN) using a many-to-one architecture, and Convolutional Neural Network (CNN). LSTM-RNN processes\\nthe input data as sequences of dependent observations, while CNNs can process n-grams through the application of\\nconvolutional ﬁlters. A schematic of the DL classiﬁers in combination with a embedding layer is illustrated in Figure 1;\\nthis ﬁgure shows the arrangement of the aforementioned layers, and the different word embeddings we used which are\\npresented next.\\nFigure 1: Schematic of DL classiﬁers in combination with Embedding Layer\\n3', 'The source code used to carry out the experiments can be found in a publicly accessible repository at GitHub 3.\\n4.3 Results\\nTable 1 shows the best results for each of the models considered during the experiments of the ﬁrst scheme, which\\nwas described in subsection 4.2. It also shows the conﬁguration of pre-processing steps that achieved the best results.\\nMoreover, the hyperparameter values selected for each model were the following:\\n• (SVM) kernel RBF; ’C’: 1e3; kernel coefﬁcient ’gamma’: 1\\n• (RF and GBT) number of trees: 500; maximum number of features: 50\\n• (MLP) hidden layers: 1; neurons: 10; epochs: 1500\\nTable 1: Baseline results for the dataset in Spanish\\nModel Vocab Size Stemming Remove StopWords Text Representation test_acc\\nSVM 10000 NO YES tf-idf 0.798\\nRF 40000 NO YES tf-idf 0.802\\nGBT 40000 YES NO BoW 0.783\\nMLP 10000 YES NO tf-idf 0.794\\nAccording to the baseline results, RF in combination with a tf-idf text representation showed the highest accuracy.\\nSubsequently, we performed the experiments with the DL models (LSTM, CNN) in combination with the different types\\nof Word Embeddings; hence, we followed the second, third, and fourth schemes. From this point on, we permanently\\nremoved Stop Words and did not apply Stemming anymore regarding data pre-processing.\\nInitially, we ran some experiments using a trainable embedding layer; the results are summarized in Table 2, where the\\nhyperparameter values selected for each model were:\\n• LSTM (Spanish) 16 units; KR and KK equals 1; D equals 0\\n• LSTM (English) 4 units; KR and KK equals 0.01; D equals 0\\n• CNN (Spanish) F equals 16; KS equals 10; 4 units; KR equals 0.01\\n• CNN (English) F equals 16; KS equals 10; 12 units; KR equals 0\\nThe LSTM and CNN models trained with the English dataset, whose results are shown in Table 2, were also validated\\nwith the whole translated dataset, yielding accuracies of 56.7% and 53.2% respectively.\\nTable 2: Results for DL models with trainable embedding layer; the column dev_acc shows the accuracy in the\\ndevelopment set; std is the standard deviation, and test_acc shows the accuracy in the test set.\\nModel Dataset Language dev_acc std test_acc\\nLSTM Spanish 0.714 0.026 0.761\\nLSTM English 0.95 0.02 0.931\\nCNN Spanish 0.73 0.021 0.685\\nCNN English 0.984 0.002 0.982\\nNext, we performed the experiments using a Transfer Learning approach, with the pre-trained 300-feature GloVe\\nembedding layer presented in subsection 3.2; this time, the embedding values were left ﬁxed during the training process,\\nand only the added hidden layers were ﬁne-tuned. Since the GloVe vectors utilized were trained on a corpus in English,\\nthese experiments correspond to the third and fourth schemes. The results are summarized in Table 3; moreover, the\\nhyperparameter values chosen for each model were the following:\\n• (LSTM) 8 units; KR and KK equals 0; D equals 0.5\\n• (CNN) F equals 16; KS equals 10; 4 units; KR equals 0\\nThen, when validating the former models using the translated dataset (fourth scheme), we got accuracy values of 54%\\nand 53.8% for LSTM and CNN layers, respectively.\\n3https://github.com/kevinmaiden7/Spanish_FakeNewsDetection\\n6'], response=\"Kevin Martinez's main contribution to NLP, as presented in the document, involves developing and testing various models for fake news detection in Spanish. The work includes preprocessing text data through normalization, removing stop words, stemming, tokenization, and padding, as well as comparing different text representation techniques such as Bag of Words, term frequency-inverse document frequency (tf-idf), and word embeddings. Martinez also experiments with a range of models, from classical machine learning techniques like SVM, Random Forest, and Gradient Boosting Tree, to deep learning approaches such as LSTM and CNN, using both trainable and pre-trained embeddings. The study provides baseline results and explores the effectiveness of these models in the context of fake news detection in Spanish, contributing to the understanding and improvement of NLP techniques for this specific application.\", passing=True, feedback='YES', score=1.0, pairwise_source=None, invalid_result=False, invalid_reason=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faithfulness_eval = faithfulness_evaluator.evaluate_response(response=response)\n",
    "faithfulness_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f1ae861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 1.0,\n",
       " ['3 Methods\\n3.1 Preprocessing steps\\nIn order to obtain consistent results, a data standardization process known as Text Normalization was performed, which,\\nin addition to eliminating non-alphanumeric characters in the text, includes some of the most commonly used techniques\\nin NLP:\\n• Stop Words:we removed words there is an agreement they do not contribute to the models learning process in\\nthe context of the problem addressed; for instance, articles and prepositions.\\n• Stemming: this technique was used to reduce words to their root.\\n• Tokenization and Padding:as usual in text processing tasks, we performed tokenization and padding, when\\nrequired, for words and sentences representation.\\nSubsequently, we decided to compare some of the most common techniques regarding text representation: BoW, which\\nprovides the number of occurrences of each word in the text corpus; term frequency-inverse document frequency(tf-idf),\\nwhich provides a weighted measure of the importance of each term within the text (according to its frequency of\\noccurrence in sentences); and pre-trained Word Embeddings, where words and the semantic relationships among them\\nare represented as a vector. It is worth clarifying that, we call Word Embeddings to both pre-trained vectors such as\\nword2vec or GloVe, and embeddings obtained from pre-trained models such as ELMo or BERT (presented in subsection\\n3.2).\\n3.2 Models\\nClassical ML models, and DL models based on artiﬁcial neural networks were used. We employed ML models intending\\nto create a baseline for comparison purposes; hence, we selected the following: Support Vector Machine (SVM),\\nRandom Forest (RF), Gradient Boosting Tree (GBT), and Multi-Layer Perceptron (MLP). For the case of DL classiﬁers,\\nbesides word embeddings, two types of layers were used: Long Short-Term Memory Recurrent Neural Network\\n(LSTM-RNN) using a many-to-one architecture, and Convolutional Neural Network (CNN). LSTM-RNN processes\\nthe input data as sequences of dependent observations, while CNNs can process n-grams through the application of\\nconvolutional ﬁlters. A schematic of the DL classiﬁers in combination with a embedding layer is illustrated in Figure 1;\\nthis ﬁgure shows the arrangement of the aforementioned layers, and the different word embeddings we used which are\\npresented next.\\nFigure 1: Schematic of DL classiﬁers in combination with Embedding Layer\\n3',\n",
       "  'The source code used to carry out the experiments can be found in a publicly accessible repository at GitHub 3.\\n4.3 Results\\nTable 1 shows the best results for each of the models considered during the experiments of the ﬁrst scheme, which\\nwas described in subsection 4.2. It also shows the conﬁguration of pre-processing steps that achieved the best results.\\nMoreover, the hyperparameter values selected for each model were the following:\\n• (SVM) kernel RBF; ’C’: 1e3; kernel coefﬁcient ’gamma’: 1\\n• (RF and GBT) number of trees: 500; maximum number of features: 50\\n• (MLP) hidden layers: 1; neurons: 10; epochs: 1500\\nTable 1: Baseline results for the dataset in Spanish\\nModel Vocab Size Stemming Remove StopWords Text Representation test_acc\\nSVM 10000 NO YES tf-idf 0.798\\nRF 40000 NO YES tf-idf 0.802\\nGBT 40000 YES NO BoW 0.783\\nMLP 10000 YES NO tf-idf 0.794\\nAccording to the baseline results, RF in combination with a tf-idf text representation showed the highest accuracy.\\nSubsequently, we performed the experiments with the DL models (LSTM, CNN) in combination with the different types\\nof Word Embeddings; hence, we followed the second, third, and fourth schemes. From this point on, we permanently\\nremoved Stop Words and did not apply Stemming anymore regarding data pre-processing.\\nInitially, we ran some experiments using a trainable embedding layer; the results are summarized in Table 2, where the\\nhyperparameter values selected for each model were:\\n• LSTM (Spanish) 16 units; KR and KK equals 1; D equals 0\\n• LSTM (English) 4 units; KR and KK equals 0.01; D equals 0\\n• CNN (Spanish) F equals 16; KS equals 10; 4 units; KR equals 0.01\\n• CNN (English) F equals 16; KS equals 10; 12 units; KR equals 0\\nThe LSTM and CNN models trained with the English dataset, whose results are shown in Table 2, were also validated\\nwith the whole translated dataset, yielding accuracies of 56.7% and 53.2% respectively.\\nTable 2: Results for DL models with trainable embedding layer; the column dev_acc shows the accuracy in the\\ndevelopment set; std is the standard deviation, and test_acc shows the accuracy in the test set.\\nModel Dataset Language dev_acc std test_acc\\nLSTM Spanish 0.714 0.026 0.761\\nLSTM English 0.95 0.02 0.931\\nCNN Spanish 0.73 0.021 0.685\\nCNN English 0.984 0.002 0.982\\nNext, we performed the experiments using a Transfer Learning approach, with the pre-trained 300-feature GloVe\\nembedding layer presented in subsection 3.2; this time, the embedding values were left ﬁxed during the training process,\\nand only the added hidden layers were ﬁne-tuned. Since the GloVe vectors utilized were trained on a corpus in English,\\nthese experiments correspond to the third and fourth schemes. The results are summarized in Table 3; moreover, the\\nhyperparameter values chosen for each model were the following:\\n• (LSTM) 8 units; KR and KK equals 0; D equals 0.5\\n• (CNN) F equals 16; KS equals 10; 4 units; KR equals 0\\nThen, when validating the former models using the translated dataset (fourth scheme), we got accuracy values of 54%\\nand 53.8% for LSTM and CNN layers, respectively.\\n3https://github.com/kevinmaiden7/Spanish_FakeNewsDetection\\n6'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faithfulness_eval.passing, faithfulness_eval.score, faithfulness_eval.contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b335c915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationResult(query='What is the main contribution of Kevin Martinez to NLP?', contexts=None, response=\"Kevin Martinez's main contribution to NLP, as detailed in the provided information, involves developing and experimenting with various models for detecting fake news in Spanish. His work includes preprocessing text data through normalization, stop-word removal, stemming, tokenization, and padding. Additionally, he compared different text representation techniques such as Bag of Words, TF-IDF, and word embeddings. Martinez also implemented and evaluated both classical machine learning models (SVM, Random Forest, Gradient Boosting Tree, and MLP) and deep learning models (LSTM-RNN and CNN) for this task. His research includes using both trainable and fixed embedding layers, including a Transfer Learning approach with pre-trained GloVe embeddings. The experiments were conducted on Spanish datasets and also involved validating models with a translated English dataset.\", passing=None, feedback=\"1. Does the provided response match the subject matter of the user's query?\\n   - The response does match the subject matter of the user's query. It specifically focuses on Kevin Martinez's contributions to Natural Language Processing (NLP) by detailing his work on detecting fake news in Spanish, which is a relevant and specific area within NLP.\\n\\n2. Does the provided response attempt to address the focus or perspective on the subject matter taken on by the user's query?\\n   - The response attempts to address the focus of the user's query by providing detailed information about Kevin Martinez's research methods, the models he used, the datasets he experimented with, and the techniques he applied. This gives a comprehensive view of his contributions to the field of NLP, specifically in the context of fake news detection.\\n\\nFeedback: The response is detailed and relevant, providing specific information about Kevin Martinez's contributions to NLP, particularly in the area of fake news detection in Spanish. It addresses the query by detailing his methodologies, models, and experiments, thus covering both the subject matter and the focus of the user's question.\\n\\n[RESULT] 2\", score=1.0, pairwise_source=None, invalid_result=False, invalid_reason=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevancy_eval = relevancy_evaluator.evaluate_response(query=query, response=response)\n",
    "relevancy_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ae2a9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " \"1. Does the provided response match the subject matter of the user's query?\\n   - The response does match the subject matter of the user's query. It specifically focuses on Kevin Martinez's contributions to Natural Language Processing (NLP) by detailing his work on detecting fake news in Spanish, which is a relevant and specific area within NLP.\\n\\n2. Does the provided response attempt to address the focus or perspective on the subject matter taken on by the user's query?\\n   - The response attempts to address the focus of the user's query by providing detailed information about Kevin Martinez's research methods, the models he used, the datasets he experimented with, and the techniques he applied. This gives a comprehensive view of his contributions to the field of NLP, specifically in the context of fake news detection.\\n\\nFeedback: The response is detailed and relevant, providing specific information about Kevin Martinez's contributions to NLP, particularly in the area of fake news detection in Spanish. It addresses the query by detailing his methodologies, models, and experiments, thus covering both the subject matter and the focus of the user's question.\\n\\n[RESULT] 2\")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevancy_eval.score, relevancy_eval.feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e10529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_mcp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
