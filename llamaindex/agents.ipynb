{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b60fa7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kevin\\miniconda3\\envs\\agents_mcp_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "from llama_index.core.agent.workflow import AgentWorkflow\n",
    "from llama_index.core.tools import FunctionTool\n",
    "import os, chromadb\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from llama_index.core.workflow import Context\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe10b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "hf_token = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b89273d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50312492",
   "metadata": {},
   "source": [
    "#### Initialising Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662d27b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sample Tool -- type annotations, function names, and docstrings, are all included in parsed schemas!\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies two integers and returns the resulting integer\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "246696a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize llm\n",
    "llm = HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\", temperature=0.7, max_tokens=1000, \n",
    "                              token=hf_token, provider=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43c0bb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.agent.workflow.multi_agent_workflow.AgentWorkflow at 0x24f93d96210>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize agent\n",
    "agent = AgentWorkflow.from_tools_or_functions(\n",
    "    tools_or_functions = [FunctionTool.from_defaults(multiply)],\n",
    "    llm = llm\n",
    ")\n",
    "agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fbf756",
   "metadata": {},
   "source": [
    "#### Stateless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df21ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_1 = await agent.run(\"What is 2 times 2?\")\n",
    "response_2 = await agent.run(\"What is the result again?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aab5dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: 2 times 2 is 4.\n",
      "[ToolCallResult(tool_name='multiply', tool_kwargs={'a': 2, 'b': 2}, tool_id='5d228ecb-ad5d-4202-830d-21d811ab099f', tool_output=ToolOutput(blocks=[TextBlock(block_type='text', text='4')], tool_name='multiply', raw_input={'args': (), 'kwargs': {'a': 2, 'b': 2}}, raw_output=4, is_error=False), return_direct=False)]\n",
      "assistant: I cannot answer the question with the provided tools.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(response_1.response)\n",
    "print(response_1.tool_calls)\n",
    "print(response_2.response)\n",
    "print(response_2.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182540c8",
   "metadata": {},
   "source": [
    "#### Remembering State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b12de035",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = Context(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bb2771",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_3 = await agent.run(\"What is 2 times 27?\", ctx=ctx)\n",
    "response_4 = await agent.run(\"What is the result again?\", ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44ad0c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: 2 times 27 is 54.\n",
      "[ToolCallResult(tool_name='multiply', tool_kwargs={'a': 2, 'b': 27}, tool_id='42e23c6e-a392-40f2-bc4b-7157586700f7', tool_output=ToolOutput(blocks=[TextBlock(block_type='text', text='54')], tool_name='multiply', raw_input={'args': (), 'kwargs': {'a': 2, 'b': 27}}, raw_output=54, is_error=False), return_direct=False)]\n",
      "assistant: The result of 2 times 27 is 54.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(response_3.response)\n",
    "print(response_3.tool_calls)\n",
    "print(response_4.response)\n",
    "print(response_4.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce969e18",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0050da53",
   "metadata": {},
   "source": [
    "#### RAG Agents with QueryEngineTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d1705b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = HuggingFaceEmbedding(\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(\"nlp_papers\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(vector_store, embed_model=embed_model)\n",
    "\n",
    "llm = HuggingFaceInferenceAPI(\n",
    "    model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000,\n",
    "    token=hf_token,\n",
    "    provider=\"auto\"\n",
    ")\n",
    "query_engine = index.as_query_engine(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a86d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_tool = QueryEngineTool.from_defaults(query_engine, name=\"my_nlp_research_tool\", \n",
    "                                                  description=\"Useful for getting information about Kevin's NLP research\", \n",
    "                                                  return_direct=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "213602de",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_agent = AgentWorkflow.from_tools_or_functions(\n",
    "    tools_or_functions=[query_engine_tool],\n",
    "    llm=llm,\n",
    "    system_prompt=\"You are a helpful assistant that has access to a database containing NLP research results for Kevin. \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95356b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Kevin Martinez's main contribution to NLP is his work on developing and evaluating methods for detecting fake news in Spanish. This includes preprocessing text data, comparing various text representation techniques, and assessing the performance of different machine learning and deep learning models for this specific task.\n",
      "[ToolCallResult(tool_name='my_nlp_research_tool', tool_kwargs={'input': 'What is the main contribution of Kevin Martinez to NLP?'}, tool_id='4521015d-24cf-442f-8509-656eb2fbd698', tool_output=ToolOutput(blocks=[TextBlock(block_type='text', text=\"Kevin Martinez's main contribution, as detailed in the provided context, pertains to the development and evaluation of methods for detecting fake news in Spanish. Specifically, the work involves preprocessing text data through normalization, stop-word removal, stemming, tokenization, and padding, as well as comparing different text representation techniques such as Bag of Words (BoW), Term Frequency-Inverse Document Frequency (tf-idf), and pre-trained word embeddings. The study also includes the comparison of classical machine learning models (SVM, Random Forest, Gradient Boosting Tree, and MLP) and deep learning models (LSTM-RNN and CNN) for fake news detection. Additionally, the experiments explore the use of both trainable and pre-trained embeddings, including a transfer learning approach using GloVe embeddings. The results provide insights into the effectiveness of these models and techniques for the specific task of detecting fake news in Spanish.\")], tool_name='my_nlp_research_tool', raw_input={'input': 'What is the main contribution of Kevin Martinez to NLP?'}, raw_output=Response(response=\"Kevin Martinez's main contribution, as detailed in the provided context, pertains to the development and evaluation of methods for detecting fake news in Spanish. Specifically, the work involves preprocessing text data through normalization, stop-word removal, stemming, tokenization, and padding, as well as comparing different text representation techniques such as Bag of Words (BoW), Term Frequency-Inverse Document Frequency (tf-idf), and pre-trained word embeddings. The study also includes the comparison of classical machine learning models (SVM, Random Forest, Gradient Boosting Tree, and MLP) and deep learning models (LSTM-RNN and CNN) for fake news detection. Additionally, the experiments explore the use of both trainable and pre-trained embeddings, including a transfer learning approach using GloVe embeddings. The results provide insights into the effectiveness of these models and techniques for the specific task of detecting fake news in Spanish.\", source_nodes=[NodeWithScore(node=TextNode(id_='c7da3fe9-da44-4066-9869-ee57e9b1a4aa', embedding=None, metadata={'page_label': '3', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='b51881e0-a7b5-40eb-be92-7d99bde1a4e7', node_type='4', metadata={'page_label': '3', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='f44390a7ec43c149fcccfa1aa3bbf0547cebe9b0994a80650269561966e23fc0')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='3 Methods\\n3.1 Preprocessing steps\\nIn order to obtain consistent results, a data standardization process known as Text Normalization was performed, which,\\nin addition to eliminating non-alphanumeric characters in the text, includes some of the most commonly used techniques\\nin NLP:\\n• Stop Words:we removed words there is an agreement they do not contribute to the models learning process in\\nthe context of the problem addressed; for instance, articles and prepositions.\\n• Stemming: this technique was used to reduce words to their root.\\n• Tokenization and Padding:as usual in text processing tasks, we performed tokenization and padding, when\\nrequired, for words and sentences representation.\\nSubsequently, we decided to compare some of the most common techniques regarding text representation: BoW, which\\nprovides the number of occurrences of each word in the text corpus; term frequency-inverse document frequency(tf-idf),\\nwhich provides a weighted measure of the importance of each term within the text (according to its frequency of\\noccurrence in sentences); and pre-trained Word Embeddings, where words and the semantic relationships among them\\nare represented as a vector. It is worth clarifying that, we call Word Embeddings to both pre-trained vectors such as\\nword2vec or GloVe, and embeddings obtained from pre-trained models such as ELMo or BERT (presented in subsection\\n3.2).\\n3.2 Models\\nClassical ML models, and DL models based on artiﬁcial neural networks were used. We employed ML models intending\\nto create a baseline for comparison purposes; hence, we selected the following: Support Vector Machine (SVM),\\nRandom Forest (RF), Gradient Boosting Tree (GBT), and Multi-Layer Perceptron (MLP). For the case of DL classiﬁers,\\nbesides word embeddings, two types of layers were used: Long Short-Term Memory Recurrent Neural Network\\n(LSTM-RNN) using a many-to-one architecture, and Convolutional Neural Network (CNN). LSTM-RNN processes\\nthe input data as sequences of dependent observations, while CNNs can process n-grams through the application of\\nconvolutional ﬁlters. A schematic of the DL classiﬁers in combination with a embedding layer is illustrated in Figure 1;\\nthis ﬁgure shows the arrangement of the aforementioned layers, and the different word embeddings we used which are\\npresented next.\\nFigure 1: Schematic of DL classiﬁers in combination with Embedding Layer\\n3', mimetype='text/plain', start_char_idx=0, end_char_idx=2382, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.47635674798756056), NodeWithScore(node=TextNode(id_='a6e03e5f-90b9-4634-8c3f-228020d9629e', embedding=None, metadata={'page_label': '6', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='3ab62d6b-fff4-42d2-b6cf-c6a66012bec3', node_type='4', metadata={'page_label': '6', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='c11dbe766b605dbe782c443824743f71236063dfddbed5ee59b530a29feeef6d')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='The source code used to carry out the experiments can be found in a publicly accessible repository at GitHub 3.\\n4.3 Results\\nTable 1 shows the best results for each of the models considered during the experiments of the ﬁrst scheme, which\\nwas described in subsection 4.2. It also shows the conﬁguration of pre-processing steps that achieved the best results.\\nMoreover, the hyperparameter values selected for each model were the following:\\n• (SVM) kernel RBF; ’C’: 1e3; kernel coefﬁcient ’gamma’: 1\\n• (RF and GBT) number of trees: 500; maximum number of features: 50\\n• (MLP) hidden layers: 1; neurons: 10; epochs: 1500\\nTable 1: Baseline results for the dataset in Spanish\\nModel Vocab Size Stemming Remove StopWords Text Representation test_acc\\nSVM 10000 NO YES tf-idf 0.798\\nRF 40000 NO YES tf-idf 0.802\\nGBT 40000 YES NO BoW 0.783\\nMLP 10000 YES NO tf-idf 0.794\\nAccording to the baseline results, RF in combination with a tf-idf text representation showed the highest accuracy.\\nSubsequently, we performed the experiments with the DL models (LSTM, CNN) in combination with the different types\\nof Word Embeddings; hence, we followed the second, third, and fourth schemes. From this point on, we permanently\\nremoved Stop Words and did not apply Stemming anymore regarding data pre-processing.\\nInitially, we ran some experiments using a trainable embedding layer; the results are summarized in Table 2, where the\\nhyperparameter values selected for each model were:\\n• LSTM (Spanish) 16 units; KR and KK equals 1; D equals 0\\n• LSTM (English) 4 units; KR and KK equals 0.01; D equals 0\\n• CNN (Spanish) F equals 16; KS equals 10; 4 units; KR equals 0.01\\n• CNN (English) F equals 16; KS equals 10; 12 units; KR equals 0\\nThe LSTM and CNN models trained with the English dataset, whose results are shown in Table 2, were also validated\\nwith the whole translated dataset, yielding accuracies of 56.7% and 53.2% respectively.\\nTable 2: Results for DL models with trainable embedding layer; the column dev_acc shows the accuracy in the\\ndevelopment set; std is the standard deviation, and test_acc shows the accuracy in the test set.\\nModel Dataset Language dev_acc std test_acc\\nLSTM Spanish 0.714 0.026 0.761\\nLSTM English 0.95 0.02 0.931\\nCNN Spanish 0.73 0.021 0.685\\nCNN English 0.984 0.002 0.982\\nNext, we performed the experiments using a Transfer Learning approach, with the pre-trained 300-feature GloVe\\nembedding layer presented in subsection 3.2; this time, the embedding values were left ﬁxed during the training process,\\nand only the added hidden layers were ﬁne-tuned. Since the GloVe vectors utilized were trained on a corpus in English,\\nthese experiments correspond to the third and fourth schemes. The results are summarized in Table 3; moreover, the\\nhyperparameter values chosen for each model were the following:\\n• (LSTM) 8 units; KR and KK equals 0; D equals 0.5\\n• (CNN) F equals 16; KS equals 10; 4 units; KR equals 0\\nThen, when validating the former models using the translated dataset (fourth scheme), we got accuracy values of 54%\\nand 53.8% for LSTM and CNN layers, respectively.\\n3https://github.com/kevinmaiden7/Spanish_FakeNewsDetection\\n6', mimetype='text/plain', start_char_idx=0, end_char_idx=3138, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.46875538337781664)], metadata={'c7da3fe9-da44-4066-9869-ee57e9b1a4aa': {'page_label': '3', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, 'a6e03e5f-90b9-4634-8c3f-228020d9629e': {'page_label': '6', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}}), is_error=False), return_direct=False)]\n"
     ]
    }
   ],
   "source": [
    "response = await query_engine_agent.run(\"What is the main contribution of Kevin Martinez to NLP?\")\n",
    "print(response.response)\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08db8b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Geoffrey Hinton is well-known for his work on artificial neural networks, backpropagation, and deep learning. His contributions to the development of deep neural networks have been instrumental, including the revival of interest in backpropagation and the creation of models like Boltzmann machines and recurrent neural networks. While his most famous work might not be directly in NLP, his advancements in neural networks have significantly impacted NLP, enabling more effective language models and natural language processing systems.\n",
      "[ToolCallResult(tool_name='my_nlp_research_tool', tool_kwargs={'input': 'What is the main contribution of Geoffrey Hinton to NLP?'}, tool_id='e983b33a-a5dc-45fc-ace1-75376e953f9b', tool_output=ToolOutput(blocks=[TextBlock(block_type='text', text=\"The provided context does not contain any information about Geoffrey Hinton's contributions to NLP. Therefore, based solely on the given information, it is not possible to answer the query regarding Geoffrey Hinton's main contribution to NLP.\")], tool_name='my_nlp_research_tool', raw_input={'input': 'What is the main contribution of Geoffrey Hinton to NLP?'}, raw_output=Response(response=\"The provided context does not contain any information about Geoffrey Hinton's contributions to NLP. Therefore, based solely on the given information, it is not possible to answer the query regarding Geoffrey Hinton's main contribution to NLP.\", source_nodes=[NodeWithScore(node=TextNode(id_='5bdf2d2e-034e-458b-96ee-7125ea904575', embedding=None, metadata={'page_label': '8', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='9a54ae6c-8980-4ccb-9a05-9598fc2bbc00', node_type='4', metadata={'page_label': '8', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='2e1cfbf22b1c267fa93cef7359e9c931d84292c4d954f23e5e121bfa7facefc1')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Concerning BETO embedding, the experiments with this model were framed in the second scheme (training and\\nvalidating with the dataset in Spanish) since BETO itself is a model trained over a corpus in this language; in this case,\\nwe used both LSTM and CNN layers. Table 4 shows the results for this experiment, where it is possible to observe that\\nthe LSTM model trained with 25 epochs achieved results of up to 80% in accuracy for the test set; this is the best result\\nwe reached with DL models for the dataset in Spanish. Thus, Figure 4 shows the confusion matrix associated with this\\narchitecture for the test set; it is worth highlighting that we used the early stopping strategy, although it did not yield a\\nsigniﬁcant improvement in comparison to the previous results.\\nFigure 4: (BETO) normalized confusion matrix for LSTM with the dataset in Spanish\\n5 Discussion and Conclusions\\nRegarding the proposed baseline for datasets in Spanish (ﬁrst scheme), RF showed the best performance getting an\\naccuracy of 80%, and using the tf-idf text representation; however, this performance was not statistically different from\\nthat obtained with SVM, where a smaller vocabulary size was used. This model outperformed the best result reported in\\n[2], where The Spanish Fake News Corpusdataset was also utilized. Furthermore, we noticed that for this scheme, there\\nwere no signiﬁcant differences in the performance of the models when applying Stemming or removing StopWords, or\\neven when varying the text representation strategy or the vocabulary size.\\nIt is worth highlighting the gap between the number of samples in the resulting datasets for English and Spanish,\\nas it was shown in Figure 2. Since the models we used in this research follow a phenomenological approach, they\\nhighly depend on the amount of experimental data they are trained on. The above was evidenced by the prominent\\ndifference on accuracy we obtained in the third and fourth schemes, using GloVe, ELMo, and BERT embeddings.\\nAlso, concerning the second scheme, we noticed that the models exhibited a trend of overﬁtting due to the small\\nnumber of samples available for training; moreover, we observed that the regularization strategies we employed did not\\nsigniﬁcantly improve the performance.\\nIn regard to the fourth scheme, it is important to underline that the vocabulary present in the translated dataset\\ncorresponded to just 60% of that present in the dataset in English; this situation negatively affected the results we\\nobtained for the translation strategy. For this scheme, despite the excellent performance of the models trained and\\nvalidated with the dataset in English (third scheme), when we validated with the translated dataset, the values of\\naccuracy were drastically reduced. Consequently, the results of the implemented learning curve indicated a performance\\nimprovement (although in different ratios) as more samples were added from the translated dataset to the training\\nset (as it was shown in Figure 3); this pattern was noticed regardless of the combination between a model and the\\nembedding layer utilized.\\nConcerning the different embeddings we used, similar results were obtained for the third and fourth schemes when\\nusing GloVe, ELMo or BERT, in each of them; in fact, it is noteworthy that, in combination with these different\\nembeddings, the LSTM and CNN layers showed similar results. Furthermore, taking into account these pre-trained\\nmodels corresponded to the state-of-the-art in NLP, we were expecting to obtain salient results by mixing portions of\\nthe translated dataset to the dataset in English for training; however, due to the small number of samples available in the\\n8', mimetype='text/plain', start_char_idx=0, end_char_idx=3674, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.43739622532778283), NodeWithScore(node=TextNode(id_='b5286c1f-2a1c-43bb-84e6-6633df2e3a74', embedding=None, metadata={'page_label': '7', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='7ea003dc-9156-4d7a-8e01-5b0f44258668', node_type='4', metadata={'page_label': '7', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='8e91bb0d125b651448374d14e4a1c7ec0e3632c89356b752cbb1680cb23dae1b')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Table 3: Results for DL models using GloVe embedding with the dataset in English. The column dev_acc shows the\\naccuracy in the development set; std is the standard deviation, and test_acc shows the accuracy in the test set.\\nModel dev_acc std test_acc\\nLSTM 0.962 0.006 0.924\\nCNN 0.974 0.002 0.973\\nAt this point, we decided to implement a learning curve in order to evaluate the effect of including data from the\\ntranslated dataset, into a training dataset composed of the original news in English. The models evaluated included\\nLSTM and CNN layers as well as trainable Embeddings and GloVe. Five experiments were run for each case, adding\\n500, 1000, 1500, 2000 and 2500 samples from the translated dataset to the training set, and then validating with the total\\namount of remaining samples of the translated dataset. Figure 3 shows the results for the CNN model with trainable\\nEmbedding, which was the best combination found in terms of accuracy, when applying this strategy.\\nFigure 3: Learning curve results for CNN with trainable embedding\\nBased on the previous results obtained with GloVe, and to simplify the experimental phase, the best hyperparameters of\\nLSTM and CNN layers found using this embedding, were left ﬁxed for the subsequent experiments applying ELMo and\\nBERT-type embeddings.\\nTable 4: Results for ELMo, BERT and BETO Embeddings\\nEmbedding Model scheme Epochs test_acc\\nELMo LSTM Third 7 0.973\\nELMo CNN Third 5 0.957\\nELMo CNN Fourth 7 0.525\\nBERT CNN Third 7 0.957\\nBERT CNN Fourth 7 0.53\\nBETO LSTM Second 25 0.80\\nRegarding the results with ELMo embedding, we got high accuracy outcomes for both LSTM and CNN models\\nconcerning the third scheme, as it is shown in Table 4; however, when it comes to the fourth scheme, the results show a\\ndegradation in performance. Additionally, taking into account the trend identiﬁed in the aforementioned learning curve\\napproach, we added 2500 samples from the translated dataset to the training set, ﬁtted the CNN layer in combination\\nwith ELMo embedding on this set, and validated with the remaining 71 samples of the translated dataset: we reached an\\naccuracy value of 70%.\\nFor the models built on top of BERT embedding, experiments were only carried out with the CNN layers; with this in\\nmind, as it is described in Table 4, we obtained a high accuracy result for the third scheme again, whereas not such a\\ngood level was achieved for the fourth scheme. Similarly to the procedure followed with ELMo embedding, 2500\\nsamples were added from the translated dataset to the training set, for then validating with the remaining 71 samples: in\\nthis case we got an accuracy level of 63.4%.\\n7', mimetype='text/plain', start_char_idx=0, end_char_idx=2636, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.42900814135972765)], metadata={'5bdf2d2e-034e-458b-96ee-7125ea904575': {'page_label': '8', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, 'b5286c1f-2a1c-43bb-84e6-6633df2e3a74': {'page_label': '7', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}}), is_error=False), return_direct=False), ToolCallResult(tool_name='my_nlp_research_tool', tool_kwargs={'input': 'What are some well-known contributions of Geoffrey Hinton to the field of machine learning and neural networks?'}, tool_id='631808c8-6f68-4267-a4b7-de6d6fa73722', tool_output=ToolOutput(blocks=[TextBlock(block_type='text', text='The context provided does not contain any information about Geoffrey Hinton or his contributions to machine learning and neural networks. Therefore, based solely on the given context, no specific contributions of Geoffrey Hinton can be mentioned.')], tool_name='my_nlp_research_tool', raw_input={'input': 'What are some well-known contributions of Geoffrey Hinton to the field of machine learning and neural networks?'}, raw_output=Response(response='The context provided does not contain any information about Geoffrey Hinton or his contributions to machine learning and neural networks. Therefore, based solely on the given context, no specific contributions of Geoffrey Hinton can be mentioned.', source_nodes=[NodeWithScore(node=TextNode(id_='b5286c1f-2a1c-43bb-84e6-6633df2e3a74', embedding=None, metadata={'page_label': '7', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='7ea003dc-9156-4d7a-8e01-5b0f44258668', node_type='4', metadata={'page_label': '7', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='8e91bb0d125b651448374d14e4a1c7ec0e3632c89356b752cbb1680cb23dae1b')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Table 3: Results for DL models using GloVe embedding with the dataset in English. The column dev_acc shows the\\naccuracy in the development set; std is the standard deviation, and test_acc shows the accuracy in the test set.\\nModel dev_acc std test_acc\\nLSTM 0.962 0.006 0.924\\nCNN 0.974 0.002 0.973\\nAt this point, we decided to implement a learning curve in order to evaluate the effect of including data from the\\ntranslated dataset, into a training dataset composed of the original news in English. The models evaluated included\\nLSTM and CNN layers as well as trainable Embeddings and GloVe. Five experiments were run for each case, adding\\n500, 1000, 1500, 2000 and 2500 samples from the translated dataset to the training set, and then validating with the total\\namount of remaining samples of the translated dataset. Figure 3 shows the results for the CNN model with trainable\\nEmbedding, which was the best combination found in terms of accuracy, when applying this strategy.\\nFigure 3: Learning curve results for CNN with trainable embedding\\nBased on the previous results obtained with GloVe, and to simplify the experimental phase, the best hyperparameters of\\nLSTM and CNN layers found using this embedding, were left ﬁxed for the subsequent experiments applying ELMo and\\nBERT-type embeddings.\\nTable 4: Results for ELMo, BERT and BETO Embeddings\\nEmbedding Model scheme Epochs test_acc\\nELMo LSTM Third 7 0.973\\nELMo CNN Third 5 0.957\\nELMo CNN Fourth 7 0.525\\nBERT CNN Third 7 0.957\\nBERT CNN Fourth 7 0.53\\nBETO LSTM Second 25 0.80\\nRegarding the results with ELMo embedding, we got high accuracy outcomes for both LSTM and CNN models\\nconcerning the third scheme, as it is shown in Table 4; however, when it comes to the fourth scheme, the results show a\\ndegradation in performance. Additionally, taking into account the trend identiﬁed in the aforementioned learning curve\\napproach, we added 2500 samples from the translated dataset to the training set, ﬁtted the CNN layer in combination\\nwith ELMo embedding on this set, and validated with the remaining 71 samples of the translated dataset: we reached an\\naccuracy value of 70%.\\nFor the models built on top of BERT embedding, experiments were only carried out with the CNN layers; with this in\\nmind, as it is described in Table 4, we obtained a high accuracy result for the third scheme again, whereas not such a\\ngood level was achieved for the fourth scheme. Similarly to the procedure followed with ELMo embedding, 2500\\nsamples were added from the translated dataset to the training set, for then validating with the remaining 71 samples: in\\nthis case we got an accuracy level of 63.4%.\\n7', mimetype='text/plain', start_char_idx=0, end_char_idx=2636, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.4425519553530519), NodeWithScore(node=TextNode(id_='5bdf2d2e-034e-458b-96ee-7125ea904575', embedding=None, metadata={'page_label': '8', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='9a54ae6c-8980-4ccb-9a05-9598fc2bbc00', node_type='4', metadata={'page_label': '8', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, hash='2e1cfbf22b1c267fa93cef7359e9c931d84292c4d954f23e5e121bfa7facefc1')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Concerning BETO embedding, the experiments with this model were framed in the second scheme (training and\\nvalidating with the dataset in Spanish) since BETO itself is a model trained over a corpus in this language; in this case,\\nwe used both LSTM and CNN layers. Table 4 shows the results for this experiment, where it is possible to observe that\\nthe LSTM model trained with 25 epochs achieved results of up to 80% in accuracy for the test set; this is the best result\\nwe reached with DL models for the dataset in Spanish. Thus, Figure 4 shows the confusion matrix associated with this\\narchitecture for the test set; it is worth highlighting that we used the early stopping strategy, although it did not yield a\\nsigniﬁcant improvement in comparison to the previous results.\\nFigure 4: (BETO) normalized confusion matrix for LSTM with the dataset in Spanish\\n5 Discussion and Conclusions\\nRegarding the proposed baseline for datasets in Spanish (ﬁrst scheme), RF showed the best performance getting an\\naccuracy of 80%, and using the tf-idf text representation; however, this performance was not statistically different from\\nthat obtained with SVM, where a smaller vocabulary size was used. This model outperformed the best result reported in\\n[2], where The Spanish Fake News Corpusdataset was also utilized. Furthermore, we noticed that for this scheme, there\\nwere no signiﬁcant differences in the performance of the models when applying Stemming or removing StopWords, or\\neven when varying the text representation strategy or the vocabulary size.\\nIt is worth highlighting the gap between the number of samples in the resulting datasets for English and Spanish,\\nas it was shown in Figure 2. Since the models we used in this research follow a phenomenological approach, they\\nhighly depend on the amount of experimental data they are trained on. The above was evidenced by the prominent\\ndifference on accuracy we obtained in the third and fourth schemes, using GloVe, ELMo, and BERT embeddings.\\nAlso, concerning the second scheme, we noticed that the models exhibited a trend of overﬁtting due to the small\\nnumber of samples available for training; moreover, we observed that the regularization strategies we employed did not\\nsigniﬁcantly improve the performance.\\nIn regard to the fourth scheme, it is important to underline that the vocabulary present in the translated dataset\\ncorresponded to just 60% of that present in the dataset in English; this situation negatively affected the results we\\nobtained for the translation strategy. For this scheme, despite the excellent performance of the models trained and\\nvalidated with the dataset in English (third scheme), when we validated with the translated dataset, the values of\\naccuracy were drastically reduced. Consequently, the results of the implemented learning curve indicated a performance\\nimprovement (although in different ratios) as more samples were added from the translated dataset to the training\\nset (as it was shown in Figure 3); this pattern was noticed regardless of the combination between a model and the\\nembedding layer utilized.\\nConcerning the different embeddings we used, similar results were obtained for the third and fourth schemes when\\nusing GloVe, ELMo or BERT, in each of them; in fact, it is noteworthy that, in combination with these different\\nembeddings, the LSTM and CNN layers showed similar results. Furthermore, taking into account these pre-trained\\nmodels corresponded to the state-of-the-art in NLP, we were expecting to obtain salient results by mixing portions of\\nthe translated dataset to the dataset in English for training; however, due to the small number of samples available in the\\n8', mimetype='text/plain', start_char_idx=0, end_char_idx=3674, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.4207239894195216)], metadata={'b5286c1f-2a1c-43bb-84e6-6633df2e3a74': {'page_label': '7', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}, '5bdf2d2e-034e-458b-96ee-7125ea904575': {'page_label': '8', 'file_name': 'fake_news_detection_spanish_DL.pdf', 'file_path': 'c:\\\\Users\\\\kevin\\\\Documents\\\\Agents_MCP_dojo\\\\llamaindex\\\\data\\\\fake_news_detection_spanish_DL.pdf', 'file_type': 'application/pdf', 'file_size': 247472, 'creation_date': '2025-09-08', 'last_modified_date': '2025-09-08'}}), is_error=False), return_direct=False)]\n"
     ]
    }
   ],
   "source": [
    "response = await query_engine_agent.run(\"What is the main contribution of Geoffrey Hinton to NLP?\")\n",
    "print(response.response)\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31018b1f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe7a22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_mcp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
